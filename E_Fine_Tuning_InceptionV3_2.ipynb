{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Entreno de un ConvNet InceptionV3 preentrenado con Imagenet y\n",
    "entrenando conjunto de datos pequeño y FINE TUNING\n",
    "Conjunto de datos de 4 clases\n",
    "Utilizaremos un conjunto de datos reducido:\n",
    "- Conjunto de entrenamiento: 1.000 muestras x clase \n",
    "- Conjunto de validación: 300 muestras x clase\n",
    "- Conjunto de test: 300 muestras x clase\n",
    "El conjunto de datos: balanced_dataset\n",
    "contiene tres carpetas, train, validation y test, cada una con 4 clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import argparse\n",
    "import os, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import walk, getcwd\n",
    "from keras import __version__\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
    "nb_epoch = 1\n",
    "batch_size = 32\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 249\n",
    "nb_classes = 4        # 4 clases\n",
    "nb_train = 4000       # 1000 x clase\n",
    "nb_validation = 1200  # 500 x clase\n",
    "nb_tes = 1200         # 500 x clase\n",
    "\n",
    "#Asociamos a dataset y carpetas, traim, validation y test\n",
    "base_dir = 'balanced_dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "loss_mode = 'binary_crossentropy'\n",
    "output_model_file = 'InceptionV4_FE_model_2.h5'\n",
    "class_mode= 'categorical'\n",
    "\n",
    "#inceptionv3_weights = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "# Retorna todos los archivos de un directorio dado\n",
    "def ls(ruta):  \n",
    "    return next(walk(ruta))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "#Load Pretrained model\n",
    "conv_base = InceptionV3(include_top=False, \n",
    "                     weights='imagenet', \n",
    "                     input_shape = (IM_WIDTH, IM_HEIGHT, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_to_transfer_learn(model, base_model):\n",
    "    \n",
    "  #Freeze all layers and compile the model\"\"\"\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss=loss_mode, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_new_last_layer(base_model, nb_classes):\n",
    "#\"\"\"\n",
    "#Add last layer to the convnet\n",
    "#Args:\n",
    "#  base_model: keras model excluding top\n",
    "#  nb_classes: # of classes\n",
    "#Returns:\n",
    "#  new keras model with last layer\n",
    "#\"\"\"\n",
    "    FC_SIZE =1001\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(FC_SIZE, activation='relu')(x) #new FC layer, random init\n",
    "    \n",
    "    if class_mode == \"binary\":\n",
    "        predictions = Dense(1, activation='sigmoid')(x) #new softmax layer\n",
    "    else:\n",
    "        predictions = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
    "        \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_to_finetune(model):\n",
    "#\"\"\"Freeze the bottom NB_IV3_LAYERS and retrain the remaining top layers.\n",
    "#note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in the inceptionv3 arch\n",
    "#Args:\n",
    "#model: keras model\n",
    "#\"\"\"\n",
    "    for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    #model.compile(optimizer=\"rmsprop\", loss=loss_mode, metrics=['accuracy'])\n",
    "    #default values rmsprop\n",
    "    #rmsprop  keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Graficas loss y accuracy\n",
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r.')\n",
    "    plt.plot(epochs, val_loss, 'r-')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 4 classes.\n",
      "Found 1200 images belonging to 4 classes.\n",
      "Found 1200 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#PREPROCESSING - \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,              #Normalizamos el valor de pixel\n",
    "    rotation_range = 40,          #rotamos imagne 40 grados\n",
    "    width_shift_range =0.2,       #aplica una fracción del ancho de la imagen orig\n",
    "    height_shift_range =0.2,      #aplica una fracción del alto de la imagen orig\n",
    "    shear_range = 0.2,            #aplica al azar operaciones de corte\n",
    "    zoom_range = 0.2,             #aplica zoom aleatorio dentro de las imagenes\n",
    "    horizontal_flip = True,       #invierte aleatoriamente la mitad de las imágenes\n",
    "    fill_mode = 'nearest'\n",
    ") \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,              #Normalizamos el valor de pixel\n",
    "    rotation_range = 40,          #rotamos imagne 40 grados\n",
    "    width_shift_range =0.2,       #aplica una fracción del ancho de la imagen orig\n",
    "    height_shift_range =0.2,      #aplica una fracción del alto de la imagen orig\n",
    "    shear_range = 0.2,            #aplica al azar operaciones de corte\n",
    "    zoom_range = 0.2,             #aplica zoom aleatorio dentro de las imagenes\n",
    "    horizontal_flip = True,       #invierte aleatoriamente la mitad de las imágenes\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode #'categorical'\n",
    "  )\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode\n",
    "  )\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "    batch_size = batch_size, \n",
    "    class_mode = class_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#base_model = InceptionV3(weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
    "\n",
    "model = add_new_last_layer(conv_base, nb_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 35, 35, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 17, 17, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 17, 17, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 17, 17, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 17, 17, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 17, 17, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1001)         2051049     global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            4008        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,857,841\n",
      "Trainable params: 23,823,409\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "125/125 [==============================] - 98s 787ms/step - loss: 0.9804 - acc: 0.7163 - val_loss: 0.6512 - val_acc: 0.7321\n"
     ]
    }
   ],
   "source": [
    "#TRANSFERENCIA DE APRENDIZAJE\n",
    "\n",
    "nb_epoch = 1\n",
    "setup_to_transfer_learn(model, conv_base)\n",
    "#model.summary()\n",
    "\n",
    "history_tl = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=nb_epoch,\n",
    "    steps_per_epoch=nb_train//batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps= nb_validation//batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FINE TUNNING\n",
    "#NB_IV3_LAYERS_TO_FREEZE=249\n",
    "#NB_IV3_LAYERS_TO_FREEZE=172\n",
    "NB_IV3_LAYERS_TO_FREEZE=0\n",
    "#NB_IV3_LAYERS_TO_FREEZE=-4\n",
    "setup_to_finetune(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 97s 775ms/step - loss: 0.9294 - acc: 0.6595 - val_loss: 0.7318 - val_acc: 0.7804\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 89s 716ms/step - loss: 0.7060 - acc: 0.7728 - val_loss: 0.5742 - val_acc: 0.8252\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 89s 713ms/step - loss: 0.5913 - acc: 0.8107 - val_loss: 0.4774 - val_acc: 0.8666\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 89s 709ms/step - loss: 0.5072 - acc: 0.8245 - val_loss: 0.3940 - val_acc: 0.8818\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 89s 713ms/step - loss: 0.4336 - acc: 0.8535 - val_loss: 0.3362 - val_acc: 0.8995\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 89s 713ms/step - loss: 0.3870 - acc: 0.8662 - val_loss: 0.2931 - val_acc: 0.9122\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 89s 711ms/step - loss: 0.3411 - acc: 0.8845 - val_loss: 0.2577 - val_acc: 0.9181\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 89s 710ms/step - loss: 0.3171 - acc: 0.8898 - val_loss: 0.2368 - val_acc: 0.9215\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 89s 713ms/step - loss: 0.3039 - acc: 0.8910 - val_loss: 0.2149 - val_acc: 0.9333\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 90s 718ms/step - loss: 0.2682 - acc: 0.9093 - val_loss: 0.1923 - val_acc: 0.9383\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 89s 710ms/step - loss: 0.2539 - acc: 0.9130 - val_loss: 0.1801 - val_acc: 0.9443\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 90s 716ms/step - loss: 0.2370 - acc: 0.9147 - val_loss: 0.1868 - val_acc: 0.9409\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 89s 713ms/step - loss: 0.2217 - acc: 0.9240 - val_loss: 0.1654 - val_acc: 0.9502\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 89s 711ms/step - loss: 0.2193 - acc: 0.9253 - val_loss: 0.1533 - val_acc: 0.9485\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.2000 - acc: 0.9270 - val_loss: 0.1502 - val_acc: 0.9519\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.1894 - acc: 0.9310 - val_loss: 0.1415 - val_acc: 0.9535\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 89s 715ms/step - loss: 0.1958 - acc: 0.9320 - val_loss: 0.1370 - val_acc: 0.9527\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 89s 713ms/step - loss: 0.1772 - acc: 0.9360 - val_loss: 0.1317 - val_acc: 0.9527\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 88s 708ms/step - loss: 0.1680 - acc: 0.9410 - val_loss: 0.1335 - val_acc: 0.9527\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 89s 714ms/step - loss: 0.1701 - acc: 0.9377 - val_loss: 0.1283 - val_acc: 0.9544\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 89s 713ms/step - loss: 0.1579 - acc: 0.9442 - val_loss: 0.1222 - val_acc: 0.9569\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 90s 717ms/step - loss: 0.1546 - acc: 0.9423 - val_loss: 0.1222 - val_acc: 0.9595\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 89s 713ms/step - loss: 0.1498 - acc: 0.9475 - val_loss: 0.1315 - val_acc: 0.9502\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.1564 - acc: 0.9450 - val_loss: 0.1158 - val_acc: 0.9603\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 88s 708ms/step - loss: 0.1474 - acc: 0.9477 - val_loss: 0.1153 - val_acc: 0.9603\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 90s 718ms/step - loss: 0.1506 - acc: 0.9457 - val_loss: 0.1115 - val_acc: 0.9603\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 90s 720ms/step - loss: 0.1466 - acc: 0.9480 - val_loss: 0.1158 - val_acc: 0.9611\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 90s 719ms/step - loss: 0.1318 - acc: 0.9543 - val_loss: 0.1183 - val_acc: 0.9552\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 89s 715ms/step - loss: 0.1349 - acc: 0.9500 - val_loss: 0.1123 - val_acc: 0.9620\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 91s 726ms/step - loss: 0.1262 - acc: 0.9557 - val_loss: 0.1629 - val_acc: 0.9299\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 89s 711ms/step - loss: 0.1221 - acc: 0.9565 - val_loss: 0.1194 - val_acc: 0.9578\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 90s 719ms/step - loss: 0.1195 - acc: 0.9577 - val_loss: 0.1026 - val_acc: 0.9645\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.1107 - acc: 0.9640 - val_loss: 0.1011 - val_acc: 0.9620\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 89s 710ms/step - loss: 0.1164 - acc: 0.9600 - val_loss: 0.1001 - val_acc: 0.9628\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 89s 710ms/step - loss: 0.1191 - acc: 0.9600 - val_loss: 0.1032 - val_acc: 0.9620\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 89s 714ms/step - loss: 0.1108 - acc: 0.9603 - val_loss: 0.1136 - val_acc: 0.9620\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.1049 - acc: 0.9655 - val_loss: 0.1273 - val_acc: 0.9519\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 89s 711ms/step - loss: 0.0974 - acc: 0.9682 - val_loss: 0.1066 - val_acc: 0.9611\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 90s 719ms/step - loss: 0.1038 - acc: 0.9635 - val_loss: 0.1112 - val_acc: 0.9603\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.0954 - acc: 0.9665 - val_loss: 0.1169 - val_acc: 0.9595\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 89s 714ms/step - loss: 0.0977 - acc: 0.9680 - val_loss: 0.0980 - val_acc: 0.9628\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.1007 - acc: 0.9667 - val_loss: 0.1019 - val_acc: 0.9611\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 89s 711ms/step - loss: 0.0911 - acc: 0.9715 - val_loss: 0.1059 - val_acc: 0.9595\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 89s 710ms/step - loss: 0.0978 - acc: 0.9652 - val_loss: 0.0874 - val_acc: 0.9679\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 88s 704ms/step - loss: 0.0911 - acc: 0.9677 - val_loss: 0.1126 - val_acc: 0.9569\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 88s 707ms/step - loss: 0.0869 - acc: 0.9698 - val_loss: 0.0931 - val_acc: 0.9654\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 89s 716ms/step - loss: 0.0817 - acc: 0.9718 - val_loss: 0.1026 - val_acc: 0.9603\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 90s 716ms/step - loss: 0.0790 - acc: 0.9738 - val_loss: 0.0996 - val_acc: 0.9637\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 90s 718ms/step - loss: 0.0851 - acc: 0.9732 - val_loss: 0.0905 - val_acc: 0.9671\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 89s 712ms/step - loss: 0.0791 - acc: 0.9740 - val_loss: 0.1323 - val_acc: 0.9459\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 50 #+2 antes\n",
    "history_ft = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train//batch_size,\n",
    "    epochs=nb_epoch,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation//batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(output_model_file)\n",
    "model.save('InceptionV3_FT_model_1.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Ejecutar desde inicio hasta transfer learning y luego fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8VPW9//HXBwRZZY1LQQjtRZGdkIIWUCwuaCsoUgvirVuNWuVaW6+lxp8oltpW69KW9kq97lEuV7RipfVaRcFWFJBNoCwiakBl1YJBMeHz++M7gSGZSWaSCZPMvJ+Px3nMnDPfc+Z7Jslnvvmu5u6IiEh2aJTuDIiIyKGjoC8ikkUU9EVEsoiCvohIFlHQFxHJIgr6IiJZREFfRCSLKOiLiGQRBX0RkSxyWLozUFHHjh09Nzc33dkQEWlQFi9evM3dc6pLV++Cfm5uLosWLUp3NkREGhQzey+RdKreERHJIgr6IiJZREFfRCSLKOiLiGQRBX0RkSyioC8ikmJFRZCbC40ahceiotSmr41612VTRKQhKyqCggIoKQn7770X9ssVFsL770OXLjB1ajgWL/2ECanPn0r6IpKR6rr0HO/6hYUHAni5khK47roQzN97D9wPBPfrroudvrAwtfktp5K+iGScqkrbyZaei4qSK52//37s62zfXvlYSUnlgF8u3nVqSyV9EakTqSxpJ3uteKXtqkrPsd6j/MsjmdJ5ly7J318sqbpOJe5er7aBAwe6iDRsjz/u3qKFewiVYWvRIhyv7ryuXd3NwuPjj1d9rVjp3cN+dPryzSy5/HboEPs68Taz5K/VoUPNPquKgEWeQIxNe5CvuCnoizQssQJv166xA1zXrlVfJ1XBsqr3f+AB9yOOOLBfVfpkt/L7S9WXVzIU9EUkJcGkuuvHCmRVlYTj5SuVgTdevr73PfdGjRLPb7wt2dL51q3u99/v3rNn5XymioK+SJZ5/XX3n//cfe5c9z17al7Fkox4gbpx4+QDcioCflVfLD//efx8xTveoYN78+YHH2vePLHS+SefuD/8sPvIke6HHRbOPe4498GD3Zs2dd+8OXU/B3cFfZGssWeP+403HlyP3axZ2GIFsqOOcn/mGffLLnNv2zYc69jR/aab3N9+2/33v3fv0qVyMIsV5OLVnccK5NVVvSQbeNu3j//FUtHzz7u3alX1l0Ws/N5zj3vnzpWPT53qvmtX5ffZtcv9iSfcR48OgR3cc3Pdf/IT9yVL3Pftc1+/Pvy38ZOfpPb3QEFf5BAoKXHfuNH9zTfd//xn94cecn/uufDHXZ19+0L67t3d33ijZu//1lvuvXqFv+TyoJaTE0qXqSo5w4GSasXgF6++vfxL4dhjD3ypTJrkvnx5coH38MPdhwyJ/QXWqlXlqpryUni03/0upBswwL1Tp9jv27Sp+/TpB3+p3Xab+5FHhi/Gl1468Hmfc86Be7rzTvft291nzXL/zncOfDl95SvuP/yh+4IFsX8Xvvvd0K7wySc1+7nHoqAvWemLL9znzQsl1kT9/e/uPXq4H3NM4tvRR1ddcjz55BDg4vnoI/dRow6kv/LKxPIaXVJu0yaUjtu2DcEx0YB85JEh/7Feq6rXS7xSeLwS/b/+5T58eOJfLK1bu59//oESfHlAb9fO/fLL3V980f3DD91fftn9t78Nn9lxx1XO29FHu592Wgi6l14ajp1zTiiFx6paOvzw8DmOGBF+f9zd//d/wxdNt27uq1dX/jksWOB+xhkHXycnx/0HP3B/9VX3srKqf45vvRXOueOOxH7uiUg06FtIW3/k5+e7Vs6SRJWWwltvwcsvh+3vfw/9pRs3hkcfhQsvrPr8N9+E00+Hjh1hxIjk3rtVK8jJgSOPPLDl5MBLL8GkSfDppzBxItx6K7Rpc+C8WbPgqqtg1y644w6YPx8WLIDi4tBHHBIbEAThPo84AnburJy/Dh1gz56D07doAdOnw7//ewhVqfD445XzOnIknHVW+Nk88AAMHgxbt8KWLfDnP4f7Ky09cA0zaNkSdu8O+61bw7nnwne/G34+TZvGf3932LQJVq6Et98O28qVYSspgR/+EO66K3xWEPuzLSuDiy+GceOgf//w8zvpJHj22fAzjWf+fJgzJ/zuDB8OhyUx3HXkSFi6FN59F5o3T/y8eMxssbvnV5swkW+GQ7mppC9VKSsLdaN33+3+7W8f6HoH7r17u0+cGP7VHj48lAD/67/iX2vx4lBK/upX3T/4ILX53LYtlETNQom8vNTdsmV4zM93X7UqpH300XCsvIon1X3GYzU2JluvHu94s2ahTSHa5s2hyunww91nz479+cTL19694fyK16yJsjL3nTsTT/+LXxy4r3HjUpOHqsydG97rD39IzfVQ9Y5kgr17QzXJ737nPmbMwY133bu7FxS4z5gRqkuilZS4f+tbId0vf1n5usuWhWt16RLq5OvKlCmV652bNAm9Ospt2xaC6k03hf1U9xmPJd4Xy9VXJ368adMQtM86y/3zz8N1N2wIX6ItWx6oB28o9u0Lvyu/+lX11TOper/Bg8Pn9eWXtb9eSoM+MBJYA6wHJsV4vSvwErAceAXoHPVaGbA0ss2u7r0U9Ou3fftCveqLL7rfe6/7FVeErbDQ/b773J98Mvyxr1jh/u67IaAmuv3zn+5/+pP7z34WSlq9e4cAWR5kunRxv+SSUDJOpGS+d2+4DoSAWt6gtnJlqH/t1Mn9nXfq9OOqdpBSdB19kybV94hJtl69KvFK28kc/+Mfw/uNGhW+SDt1CnXwCxak/KPMSE8/HT6/GTNqf62UBX2gMfAO8FWgKbAM6Fkhzf8CF0eefxN4LOq13YlkpHxT0K9fSkvDv6HXXed+yimVqxg6dAhdACuWZmu75eaG6ptJk9wfeywE50R6xMTKf0FBuOY114RGuaOOCo19a9ak+tOqrKqG0Vil7WbN4lfjtG9f+XqpHNFZU9Omhbw0ahQ+26oasOVgZWXuxx/v3r9/zX6/oyUa9KttyDWzk4Bb3f3MyP5PI20Bd0SlWQmMdPcPzMyAT939iMhru929VbWNCxFqyK17b78Nzz8P3btD797wta8daOQC2LcvNCz+z//AzJnw0Uehoal//5C+fOvVKzRemoVzduwIDXVbtoRGu/JGuUQddhgcfzz07BkaSVPFHc45J9wzhMbSO+6AG2+s+rxYDX5VzdAYK31hYZikq6KuXcNjrNfiNcDecANMmRJe37EjsTwdKtOmwWOPhUbdf/u3dOemYXnoIbjsMvjrX+HMM2t+nZQ15AJjgQei9v8d+F2FNE8A10WejwEc6BDZLwUWAQuAc+O8R0EkzaIuXbrU7utOqvTKK6FrXMXSZf/+7hdd5H7ttaEaBUJD3HnnhX89d+9Od85r7vHHKw/uia7+SMU8KcnWkVdVjROvAfaaa8LP6tNP0/VJSl344otQLTZ8eO2uQwqrdxIJ+l8BngaWAPcBxUDbyGudIo9fBTYCX6vq/VS9U3eefz4EjR493NeudV+4MDQo3nBDGMzTuXOoV/7Wt0K9eX0OLslUZ1RVr56qSb6qG6SUTA+azp0r38PevWEw0AUXpPZzlPrh7rvDz742bSGpDPonAS9E7f8U+GkV6VsBxXFeexgYW9X7KejXjRkzwqjKvDz3LVvipzsUvRZqK9lSeFUl6lT1lIm3xZvKN959gPtVV1VO+/zz4bVnn62jD1XSateu0AB+3nk1v0Yqg/5hwAagGwcacntVSNMRaBR5PhWYEnneDjg8Ks06KjQCV9wU9JOzZIn7ueeGeVT+7/9id/2aPj0En2HDUjvsO1WSbYSMF6hrUgpPtqdMsltV3SYr3nuXLmHcwPnnV0534YUhKJSPGJXMc/fdoedaTRt0Uxb0w7U4G1hL6MVTGDk2BRgVeT42EtDXAg9EBfpvACsiXxQrgMurey8F/cTs3Bnq3xs1Cr06yuvpc3JCPXL5UPC77grHR450/+yzdOe6sprMBJnKLo2p+gJJ1UIYV14Z+rhHDwzavTtcq6CgRh+xZImUBv1DuSnoV62szP3BB0Nwb9QoNO7t2BEGIz39dKjzLW+07NgxPH7nO/W3hJhoP/bazLte1cjUVDXYpqrb5Jw54ZrPP3/gWFFROPbqqzX8kCUrKOhnoMWL3U88MfzUTjopTNoUy+7doQ5/zBj3668PfdXrg2Tr25PtEVNVNU6y+Upl+mR8/nmYyC26VH/22WG2yobQ3iLpo6CfQdasCXW6ZqGE/9BDDS8AJNtLpmvX6nvdJFMKb0jGjg0zeZaVhUb3xo3DfPkiVVHQzwAbNoSpYRs3DsHrxhuTm0CqPkm27ry6/wLiSefI1FR57LFwn2+8cWC067Jl6c6V1HeJBv1G8YdtSboUF4epd487Dp54IkzPu2ED/PKX0LZtunN3QFER5OaGEa65uWE/3vH33499jR07wlS/XbuGkb1du4b9CRPCiNNY4h2HcN7GjWGE8MaN9WO0arLOPjuMkH722fDZ9e4NffumO1eSMRL5ZjiUW7aX9GfODCNhmzQJddfFxenOUWyHor49U6pramL48LD6EqR2oQ3JXKik3/C8+SZ873uQlwdr18Lvfw+dOqU7V7EVFh48NwyE/enTYx+HMH9MtBYtDiwOEsuECfH/C8h0o0fD5s3h+fjx6c2LZBYF/XqiuDj8oR99dPi3Pjc33Tk6IJnqmrKy2MerqsapSiZU19TE6NHhcejQA5OziaSCgn498NlnMGpUeHzuuaqXZ6srVdXPFxSE2SDdw2NBAbRvH/s60bN1RuvSJXsDeE106wa33AK3357unEimSWJFR6kL+/aFKp1ly0LA7927bt8vkbVXywM7xK/Gad48VM9UnP734ovhkUcqH6+qGkdiu+22dOdAMlIiFf+Hcsu2htzCwtBYd/fddf9eNekrn+z0v+Xv09C7TYo0NKRqEZVDLZsWUSkqgosugu9/P9Rvm9Xt++Xmxl60Ix6z8N9AvEVANm5MVc5EpLYSXURFdfpp8MUXYVWqyy+HU04Jqw7VdcCH+I2v8ZRX/yTb60ZE6i8F/UPkyy/hhRfg0kvhqKNg3LhQ8p41C5o2PTR5iDeoqUOH+IE9m7tNimQiBf06tnBhGF17zDEwciQ8/TScey7MmQMrVoSAWxdi9caJV2q/776qA7t63YhkDtXp15GPP4af/CT0ZGnRInTJHDcuLHzcrFndvnd5N8uKPWimTw/Pk1nsW0QahkTr9NVlM8VKS8NI2ltuCUF30iS46SZo3bpu3i9WF8x43SwLC1VSF8l2Cvop9NprcM01sHw5nH46/Pa3cPzxdfd+FUv05f3rKwb8csk25IpI5lGdfgqUloZul8OGwc6d8NRTodE2lQE/Vh19vBJ9VaNiRSS7qaSfAoWF8N//Df/5nzB5MrRsmdrrJ1uiLyuLPVpW3SxFRCX9Wnr6afjVr+DKK8NjqgM+JF+iL+99o26WIlKReu/Uwpo18PWvQ48eMH8+HH543bxPo0Zh8oNYYpXoFeBFso9G5Nax3bthzJgQ6J96qu4CPsSvi1eJXkSSlVDQN7ORZrbGzNab2aQYr3c1s5fMbLmZvWJmnaNeu9jM1kW2i1OZ+XRxDw23//wnzJhR9w2kVU2FoIFTIpKMaoO+mTUGpgFnAT2B8WbWs0Kyu4BH3b0vMAW4I3Jue2AyMBgYBEw2s3apy356/OY3Ye6cn/0MRoyo+/fTVAgikiqJlPQHAevdfYO77wVmAKMrpOkJvBx5Pjfq9TOBF919h7vvBF4ERtY+2+nz2mtwww1hZaOf/OTQva9K9CKSCokE/U7AB1H7xZFj0ZYBYyLPzwNam1mHBM9tMLZuhQsuCP3kH3kkNLCKiDQkqQpbNwCnmNkS4BRgExBntdTKzKzAzBaZ2aKtW7emKEupN3kybNkSZsZs0ybduRERSV4iQX8TcGzUfufIsf3cfbO7j3H3AUBh5NgniZwbSTvd3fPdPT8nHQvEJmD16lCPftVV0LdvunMjIlIziQT9hUB3M+tmZk2BccDs6ARm1tHMyq/1U+DByPMXgDPMrF2kAfeMyLEG58Ybw8CryZPr7j3iLU4uIpIq1QZ9dy8FriUE69XATHdfaWZTzGxUJNlwYI2ZrQWOAqZGzt0B3E744lgITIkca1Befhn+/OcwMjYV/4jECu7lUy28917oElo+1YICv4ikkkbkVqOsDPLzw0Rq//xn7efCjzfXffPmsH175fRai1ZEEqH59FPk8cdh6VJ44onULH4Sbx4dTYcsIoeCOh1WoXzhkUGDwqpXyYpVjVOTxclFRFJFJf0q/PrXsGlTmGrBLLlz402H3L597GqcDh1gzx5NhywidUsl/Tg++gh++cswqdrQocmfH68aB2q2OLmISCqopB/HLbfAF1/AL35Rs/PjVePs2AGPPRZ/cXIFeRGpSwr6Mbz9dlgJa+JE6N69Ztfo0iVU6cQ6PmGCgruIpIeqdyooKwurYLVtC//v/9X8OlVNhywiki4K+hX8/vfwj3/AvfeGxtWa0nTIIlIfaXBWlI0boXdvGDYM5sxJvseOiEi6aLnEJLmHLpVmcP/9CvgikpnUkBvx8MPw4oswbZoGRIlI5lJJH/jwQ/jRj0K1zlVXpTs3IiJ1J+uDvjtcc00YDfvAA1oNS0QyW9aHuFmz4Jln4Lbb4LjjanYNzYMvIg1FVtfp79gRSvl5efDjH9fsGvHm2AF1zxSR+ierS/q33RYC/4MPwmE1/PqLN8dOYWHt8ycikmpZHfTnzIGzz4Z+/Wp+jXhz7GgefBGpj7I26H/0EaxfDyefXLvrxOveqW6fIlIfZW3Qnz8/PA4bVrvraI4dEWlIsjrot2gBAwbU7jqaY0dEGpKs7b0zfz6cdBI0aVL7a2mqZBFpKLKypP/JJ7BsWfL1+eqPLyINXVaW9P/xjzASN5n6fPXHF5FMkFBJ38xGmtkaM1tvZpNivN7FzOaa2RIzW25mZ0eO55rZHjNbGtn+K9U3UBPz54dqncGDEz9H/fFFJBNUW9I3s8bANOB0oBhYaGaz3X1VVLKbgZnu/gcz6wnMAXIjr73j7v1Tm+3amT8fBg6s3OumKuqPLyKZIJGS/iBgvbtvcPe9wAxgdIU0DhwRed4G2Jy6LKbW55/DwoXJd9VUf3wRyQSJBP1OwAdR+8WRY9FuBS4ys2JCKX9i1GvdItU+r5pZzFBrZgVmtsjMFm3dujXx3NfAm2/C3r3JB331xxeRTJCq3jvjgYfdvTNwNvCYmTUCPgS6uPsA4EfAE2Z2RMWT3X26u+e7e35OTk6KshRb+aCsIUOSO0/98UUkEyTSe2cTcGzUfufIsWiXAyMB3P11M2sGdHT3LcAXkeOLzewd4DggPYvgAvPmhXVw27dP/lz1xxeRhi6Rkv5CoLuZdTOzpsA4YHaFNO8DIwDM7ASgGbDVzHIiDcGY2VeB7sCGVGU+WaWlobtmbefbERFpqKot6bt7qZldC7wANAYedPeVZjYFWOTus4EfA380s+sJjbqXuLub2cnAFDP7EtgHXOXuO+rsbqqxbBns3l37+XZERBqqhAZnufscQgNt9LFbop6vAirVkrv7LGBWLfOYMqmaZE1EpKHKqmkY5s+Hbt2gU8W+RyIiWSJrgr57CPoq5YtINsuaoL92LWzdqqAvItkta4L+vHnhUUFfRLJZ1gT9+fPhyCPhuOPSnRMRkfTJqqA/bFgYTSsikq2yIugXF8PGjaraERHJiqCfTP98rY4lIpksK1bOmj8fWreGfv2qTqfVsUQk02VNSf8b34DGjatOp9WxRCTTZXzQ//RTWLkysamUtTqWiGS6jA/6b74ZRuOeeGL1abU6lohkuowP+gsWhG6agwZVn1arY4lIpsv4oP/669CzJ7RpU31arY4lIpkuo3vv7NsXSvrnn5/4OVodS0QyWUaX9Netg5074aST0p0TEZH6IaOD/uuvh8dYjbgahCUi2Sijq3cWLAh1+T16HHxcg7BEJFtlfEl/8OBQmo+mQVgikq0yNujv2gVvvx27Pl+DsEQkW2Vs0F+4MPTeiVWfr0FYIpKtMjboL1gQHgcPrvyaBmGJSLZKKOib2UgzW2Nm681sUozXu5jZXDNbYmbLzezsqNd+GjlvjZmdmcrMV+X110MDbrt2lV/TICwRyVbV9t4xs8bANOB0oBhYaGaz3X1VVLKbgZnu/gcz6wnMAXIjz8cBvYCvAH8zs+PcvSzVNxLNPZT0zzknfhoNwhKRbJRISX8QsN7dN7j7XmAGMLpCGgeOiDxvA2yOPB8NzHD3L9z9XWB95Hp16p13YNu2xCZZExHJJokE/U7AB1H7xZFj0W4FLjKzYkIpf2IS56ZceX2+RuKKiBwsVQ2544GH3b0zcDbwmJklfG0zKzCzRWa2aOvWrbXOzOuvh5Wyevas9aVERDJKIoF5E3Bs1H7nyLFolwMzAdz9daAZ0DHBc3H36e6e7+75OTk5iec+jgULwlTK1a2UJSKSbRIJ+guB7mbWzcyaEhpmZ1dI8z4wAsDMTiAE/a2RdOPM7HAz6wZ0B95MVeZj+ewzWLZM9fkiIrFU23vH3UvN7FrgBaAx8KC7rzSzKcAid58N/Bj4o5ldT2jUvcTdHVhpZjOBVUApcE1d99xZvBjKylSfLyISS0ITrrn7HEIDbfSxW6KerwJirkLr7lOBQzbsqXxmzViDskREsl3GjchdsAC6d4eOHdOdExGR+iejgr57KOmrPl9EJLaMCvrvvQcff6z6fBGReDIq6Fe1UpaIiGRY0F+wIMyW2adPunMiIlI/ZVTQf/11+PrX4bCMXgRSRKTmMibo79kDS5aoPl9EpCoZE/Q//RTGjoXTTkt3TkRE6q+MqQg5+mh48sl050JEpH7LmJJ+PEVFkJsLjRqFx6KidOdIRCR9MqakH0tRERQUQElJ2H/vvbAPWjVLRLJTRpf0CwsPBPxyJSXhuIhINsrooP/++8kdFxHJdBkd9Lt0Se64iEimy+igP3VqGKEbrUWLcFxEJBtldNCfMAGmT4euXcEsPE6frkZcEcleGd17B0KAV5AXEQkyuqQvIiIHU9AXEckiCvoiIllEQV9EJIso6IuIZJGEgr6ZjTSzNWa23swmxXj9HjNbGtnWmtknUa+VRb02O5WZFxGR5FTbZdPMGgPTgNOBYmChmc1291Xladz9+qj0E4EBUZfY4+79U5dlERGpqURK+oOA9e6+wd33AjOA0VWkHw9oZnsRkXookaDfCfggar84cqwSM+sKdANejjrczMwWmdkCMzu3xjkVEZFaS/WI3HHAU+5eFnWsq7tvMrOvAi+b2Qp3fyf6JDMrAAoAumg2NBGROpNISX8TcGzUfufIsVjGUaFqx903RR43AK9wcH1/eZrp7p7v7vk5OTkJZElERGoikaC/EOhuZt3MrCkhsFfqhWNmPYB2wOtRx9qZ2eGR5x2BIcCqiueKiMihUW31jruXmtm1wAtAY+BBd19pZlOARe5e/gUwDpjh7h51+gnA/Wa2j/AF84voXj8iInJo2cExOv3y8/N90aJF6c6GiEiDYmaL3T2/unQakSsikkUU9EVEsoiCvohIFlHQFxHJIgr6IiJZREFfRCSLKOiLiGQRBX0RkSyioC8ikkUU9EVEsoiCvohIFlHQFxHJIgr6IiJZREFfRCSLKOiLiGQRBX0RkSyioC8ikkUU9EVEsoiCvohIFlHQFxHJIgr6IiJZREFfRCSLKOiLiGSRhIK+mY00szVmtt7MJsV4/R4zWxrZ1prZJ1GvXWxm6yLbxanMvIiIJOew6hKYWWNgGnA6UAwsNLPZ7r6qPI27Xx+VfiIwIPK8PTAZyAccWBw5d2dK70JEUuLLL7+kuLiYzz//PN1ZkTiaNWtG586dadKkSY3OrzboA4OA9e6+AcDMZgCjgVVx0o8nBHqAM4EX3X1H5NwXgZHAkzXKrYjUqeLiYlq3bk1ubi5mlu7sSAXuzvbt2ykuLqZbt241ukYi1TudgA+i9osjxyoxs65AN+DlZM41swIzW2Rmi7Zu3ZpIvkWkDnz++ed06NBBAb+eMjM6dOhQq//EUt2QOw54yt3LkjnJ3ae7e7675+fk5KQ4SyKSDAX8+q22P59Egv4m4Nio/c6RY7GM4+Cqm2TOFZEst337dvr370///v05+uij6dSp0/79vXv3JnSNSy+9lDVr1lSZZtq0aRQVFaUiyw2OuXvVCcwOA9YCIwgBeyFwobuvrJCuB/BXoJtHLhppyF0M5EWSvQUMLK/jjyU/P98XLVpUs7sRkVpZvXo1J5xwQsLpi4qgsBDefx+6dIGpU2HChNTk5dZbb6VVq1bccMMNBx13d9ydRo2yt8d5rJ+TmS129/zqzq32U3P3UuBa4AVgNTDT3Vea2RQzGxWVdBwww6O+RSLB/XbCF8VCYEpVAV9EGo6iIigogPfeA/fwWFAQjqfa+vXr6dmzJxMmTKBXr158+OGHFBQUkJ+fT69evZgyZcr+tEOHDmXp0qWUlpbStm1bJk2aRL9+/TjppJPYsmULADfffDP33nvv/vSTJk1i0KBBHH/88fzjH/8A4LPPPuP888+nZ8+ejB07lvz8fJYuXVopb5MnT+brX/86vXv35qqrrqI8BK5du5ZvfvOb9OvXj7y8PDZu3AjAz3/+c/r06UO/fv0oLCxM/YdVnfJvzfqyDRw40EUkPVatWpVw2q5d3UO4P3jr2jU1eZk8ebLfeeed7u6+bt06NzNfuHDh/te3b9/u7u5ffvmlDx061FeuXOnu7kOGDPElS5b4l19+6YDPmTPH3d2vv/56v+OOO9zdvbCw0O+555796W+88UZ3d3/22Wf9zDPPdHf3O+64w3/wgx+4u/vSpUu9UaNGvmTJkkr5LM/Hvn37fNy4cfvfLy8vz2fPnu3u7nv27PHPPvvMZ8+e7UOHDvWSkpKDzk1WrJ8TsMgTiLHZ+/+RiNTK++8nd7y2vva1r5Gff6D24sknnyQvL4+8vDxWr17NqlWVe5E3b96cs846C4CBAwfuL21XNGbMmEppXnvtNcaNGwdAv3796NWrV8xzX3rpJQYNGkS/fv149dVXWbkmNZ60AAALvUlEQVRyJTt37mTbtm2cc845QOhb36JFC/72t79x2WWX0bx5cwDat2+f/AdRS4n00xcRqaRLl1ClE+t4XWjZsuX+5+vWreO+++7jzTffpG3btlx00UUxuzE2bdp0//PGjRtTWloa89qHH354tWliKSkp4dprr+Wtt96iU6dO3HzzzfV+YJtK+iJSI1OnQosWBx9r0SIcr2v/+te/aN26NUcccQQffvghL7zwQsrfY8iQIcycOROAFStWxPxPYs+ePTRq1IiOHTuya9cuZs2aBUC7du3IycnhueeeA8L4h5KSEk4//XQefPBB9uzZA8COHYe+iVMlfRGpkfJeOnXVe6cqeXl59OzZkx49etC1a1eGDBmS8veYOHEi3/ve9+jZs+f+rU2bNgel6dChAxdffDE9e/bkmGOOYfDgwftfKyoq4sorr6SwsJCmTZsya9Ysvv3tb7Ns2TLy8/Np0qQJ55xzDrfffnvK816VartsHmrqsimSPsl22cxkpaWllJaW0qxZM9atW8cZZ5zBunXrOOyw9JeVa9NlM/25FxGph3bv3s2IESMoLS3F3bn//vvrRcCvrYZ/ByIidaBt27YsXrw43dlIOTXkiohkEQV9EZEsoqAvIpJFFPRFRLKIgr6I1BunnnpqpYFW9957L1dffXWV57Vq1QqAzZs3M3bs2Jhphg8fTnXdwe+9915KSkr275999tl88sknVZzR8Cjoi0i9MX78eGbMmHHQsRkzZjB+/PiEzv/KV77CU089VeP3rxj058yZQ9u2bWt8vfpIQV9E6o2xY8fy/PPP718wZePGjWzevJlhw4bt7zefl5dHnz59ePbZZyudv3HjRnr37g2EKRLGjRvHCSecwHnnnbd/6gOAq6++ev+0zJMnhyW9f/Ob37B582ZOPfVUTj31VAByc3PZtm0bAHfffTe9e/emd+/e+6dl3rhxIyeccAJXXHEFvXr14owzzjjofco999xzDB48mAEDBnDaaafx8ccfA2EswKWXXkqfPn3o27fv/mkc/vrXv5KXl0e/fv0YMWJESj7bcuqnLyIx/fCHEGP6+Frp3x8i8TKm9u3bM2jQIP7yl78wevRoZsyYwQUXXICZ0axZM5555hmOOOIItm3bxoknnsioUaPiLh/4hz/8gRYtWrB69WqWL19OXl7e/temTp1K+/btKSsrY8SIESxfvpz/+I//4O6772bu3Ll07NjxoGstXryYhx56iDfeeAN3Z/DgwZxyyim0a9eOdevW8eSTT/LHP/6RCy64gFmzZnHRRRcddP7QoUNZsGABZsYDDzzAr371K379619z++2306ZNG1asWAHAzp072bp1K1dccQXz5s2jW7duKZ+fRyV9EalXoqt4oqt23J2bbrqJvn37ctppp7Fp06b9JeZY5s2btz/49u3bl759++5/bebMmeTl5TFgwABWrlwZczK1aK+99hrnnXceLVu2pFWrVowZM4b58+cD0K1bN/r37w/En765uLiYM888kz59+nDnnXeycmVYePBvf/sb11xzzf507dq1Y8GCBZx88sl069YNSP30yyrpi0hMVZXI69Lo0aO5/vrreeuttygpKWHgwIFAmMBs69atLF68mCZNmpCbm1ujaYzfffdd7rrrLhYuXEi7du245JJLajUdcvm0zBCmZo5VvTNx4kR+9KMfMWrUKF555RVuvfXWGr9fbWVMSb+oCHJzoVGj8Jilax6LNHitWrXi1FNP5bLLLjuoAffTTz/lyCOPpEmTJsydO5f3Yk3mH+Xkk0/miSeeAODtt99m+fLlQJiWuWXLlrRp04aPP/6Yv/zlL/vPad26Nbt27ap0rWHDhvGnP/2JkpISPvvsM5555hmGDRuW8D19+umndOrUCYBHHnlk//HTTz+dadOm7d/fuXMnJ554IvPmzePdd98FUj/9ckYE/UO5VqeI1L3x48ezbNmyg4L+hAkTWLRoEX369OHRRx+lR48eVV7j6quvZvfu3Zxwwgnccsst+/9j6NevHwMGDKBHjx5ceOGFB03LXFBQwMiRI/c35JbLy8vjkksuYdCgQQwePJjvf//7DBgwIOH7ufXWW/nOd77DwIEDD2ovuPnmm9m5cye9e/emX79+zJ07l5ycHKZPn86YMWPo168f3/3udxN+n0RkxNTKubmxV/Dp2hXirI4mIjFoauWGoTZTK2dESf9Qr9UpItJQZUTQj7cmZ12t1Ski0lAlFPTNbKSZrTGz9WY2KU6aC8xslZmtNLMnoo6XmdnSyDY7VRmPls61OkVEGpJqu2yaWWNgGnA6UAwsNLPZ7r4qKk134KfAEHffaWZHRl1ij7v3T3G+D5LOtTpFMo27xx3wJOlX23bYRPrpDwLWu/sGADObAYwGokczXAFMc/edkUxtqVWuamDCBAV5kdpq1qwZ27dvp0OHDgr89ZC7s337dpo1a1bjayQS9DsBH0TtFwODK6Q5DsDM/g40Bm51979GXmtmZouAUuAX7v6nGudWROpU586dKS4uZuvWrenOisTRrFkzOnfuXOPzUzUi9zCgOzAc6AzMM7M+7v4J0NXdN5nZV4GXzWyFu78TfbKZFQAFAF3U+iqSNk2aNNk//F8yUyINuZuAY6P2O0eORSsGZrv7l+7+LrCW8CWAu2+KPG4AXgEqjWhw9+nunu/u+Tk5OUnfhIiIJCaRoL8Q6G5m3cysKTAOqNgL50+EUj5m1pFQ3bPBzNqZ2eFRx4dwcFuAiIgcQtVW77h7qZldC7xAqK9/0N1XmtkUYJG7z468doaZrQLKgP909+1m9g3gfjPbR/iC+UV0rx8RETm06t00DGa2Fah6JiXoCGw7BNmpj7L13nXf2UX3nbyu7l5t/Xi9C/qJMLNFicwxkYmy9d5139lF9113MmIaBhERSYyCvohIFmmoQX96ujOQRtl677rv7KL7riMNsk5fRERqpqGW9EVEpAYaXNBPZJrnTGBmD5rZFjN7O+pYezN70czWRR7bpTOPdcHMjjWzuVHTdF8XOZ7R925mzczsTTNbFrnv2yLHu5nZG5Hf9/+JDJDMOGbW2MyWmNmfI/vZct8bzWxFZOr5RZFjdfq73qCCftQ0z2cBPYHxZtYzvbmqMw8DIyscmwS85O7dgZci+5mmFPixu/cETgSuifyMM/3evwC+6e79gP7ASDM7EfglcI+7/xuwE7g8jXmsS9cBq6P2s+W+AU519/5RXTXr9He9QQV9oqZ5dve9QPk0zxnH3ecBOyocHg08Enn+CHDuIc3UIeDuH7r7W5HnuwiBoBMZfu8e7I7sNolsDnwTeCpyPOPuG8DMOgPfAh6I7BtZcN9VqNPf9YYW9GNN89wpTXlJh6Pc/cPI84+Ao9KZmbpmZrmECfreIAvuPVLFsRTYArwIvAN84u6lkSSZ+vt+L3AjsC+y34HsuG8IX+z/Z2aLI7MNQx3/rqdqamU5xNzdzSxju16ZWStgFvBDd/9X9IIemXrv7l4G9DeztsAzQI80Z6nOmdm3gS3uvtjMhqc7P2kwNDL1/JHAi2b2z+gX6+J3vaGV9BOZ5jmTfWxmxwBEHg/5CmWHgpk1IQT8Ind/OnI4K+4dILIOxVzgJKCtmZUXzjLx930IMMrMNhKqa78J3Efm3zdw0NTzWwhf9IOo49/1hhb0E5nmOZPNBi6OPL8YeDaNeakTkfrc/wZWu/vdUS9l9L2bWU6khI+ZNSesSb2aEPzHRpJl3H27+0/dvbO75xL+nl929wlk+H0DmFlLM2td/hw4A3ibOv5db3CDs8zsbEIdYPk0z1PTnKU6YWZPEtYo6Ah8DEwmrFswE+hCmIn0Anev2NjboJnZUGA+sIIDdbw3Eer1M/bezawvodGuMaEwNtPdp0RWnJsBtAeWABe5+xfpy2ndiVTv3ODu386G+47c4zOR3cOAJ9x9qpl1oA5/1xtc0BcRkZpraNU7IiJSCwr6IiJZREFfRCSLKOiLiGQRBX0RkSyioC8ikkUU9EVEsoiCvohIFvn/erK1VzzqDWkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc714bf3550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc715efecc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Mostramos otros graficos \n",
    "acc = history_ft.history['acc']\n",
    "val_acc = history_ft.history['val_acc']\n",
    "loss = history_ft.history['loss']\n",
    "val_loss = history_ft.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+ 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "#plt.tittle('Trainning and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "#plt.tittle('Trainning and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1568763315677643, 0.9375]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evluamos datos generados del conjunto de datos test\n",
    "#test_generator = testn_datagen.flow_from_directory(\n",
    "#    test_dir,   #debemos indicar el directorio de los datos de test\n",
    "#    target_size = (IM_WIDTH, IM_HEIGHT),\n",
    "#    batch_size = batch_size, #40 x 50 epocas = 2000\n",
    "#    class_mode = 'categorical')\n",
    "\n",
    "model.evaluate_generator(test_generator, steps = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
