{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Entreno de un ConvNet Xception preentrenado con Imagenet y\n",
    "entrenando conjunto de datos pequeño\n",
    "Conjunto de datos de 4 clases\n",
    "Utilizaremos un conjunto de datos reducido:\n",
    "- Conjunto de entrenamiento: 1.000 muestras x clase \n",
    "- Conjunto de validación: 300 muestras x clase\n",
    "- Conjunto de test: 300 muestras x clase\n",
    "El conjunto de datos: balanced_dataset\n",
    "contiene tres carpetas, train, validation y test, cada una con 4 clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from os import walk, getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retorna todos los archivos de un directorio dado\n",
    "def ls(ruta):  \n",
    "    return next(walk(ruta))[2]\n",
    "\n",
    "height_image = 229\n",
    "width_image = 229\n",
    "channels_image = 3\n",
    "nb_clases = 4\n",
    "batch_size = 64\n",
    "class_mode = 'categorical'\n",
    "nb_train = 4000        # 1000 x 4 clases\n",
    "nb_validation = 1200   #  300 x 4 clases\n",
    "nb_test = 1200\n",
    "\n",
    "base_dir = 'balanced_dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import Xception\n",
    "\n",
    "conv_base= Xception(weights='imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (width_image, height_image, channels_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 229, 229, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 114, 114, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 114, 114, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 114, 114, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 112, 112, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 112, 112, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 112, 112, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 112, 112, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 112, 112, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 112, 112, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 112, 112, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 112, 112, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 56, 56, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 56, 56, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 56, 56, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 56, 56, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 56, 56, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 56, 56, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 56, 56, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 56, 56, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 28, 28, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 14, 14, 728)  2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "FEATURE EXTRACTION (Extracción de características)\n",
    "\n",
    "Ahora hay dos formas de proceder:\n",
    "1- Ejecutar la base convolucional sobre el conjunto de datos, registrar la salida en una matriz Numpy en disco, y luego usar esa información como entrada para un clasificador independiente y densamente conectado. Esta solución es rápida y económica computacionalmente, pero no permite utilizar Data Augmentation.\n",
    "La primera parte es la base convolucional de un modelo preentrenado, segundo se entrena la parte convolucional con los nuevos datos de entrenamiento, depués añadimos un nuevo clasificador densamente conectado en la parte superior (final) y volvemos a entrenar. Si el modelo con el que se entrenó el modelo preentrenado es muy difernte del que queremos aplicar, es conveniente no utilizar toda la base convolucional (eliminar las últimas) ya que éstas són cada vez más especificas al conjunto de datos con el que se entrenó.\n",
    "2- Amplicar el modelo que tenemos (conv_base) agregando capas densas en la parte superior y ejecutando todo de punta a punta en los datos de entrada. Esto permite Data Augmentation, porque cada imagen de entrada pasa por la base convolucional. Esta técnica es mucho mas costosa y requiere GPU"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Extracción de características sin Data Augmentation --> CPU\n",
    "\n",
    "Ejecutamos instancias de ImageDataGenerator para extraer imagenes como matrices Numpy y sus etiquetas. Extraeremos características de estas imágenes llamando al método del modelo conv_base\n",
    "\n",
    "- La ultima salida de la capa convolucional es de (7, 7, 2048 )\n",
    "out_x, out_y, conv_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 4 classes.\n",
      "Found 1200 images belonging to 4 classes.\n",
      "Found 1200 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#Extracción de características del modelo Preentrenado y nuestro dataset\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#Tamaño de salida de la última capa convoluciónal del modelo preentrenado\n",
    "#lo vemos en el conv_base.summary()\n",
    "out_x = 7\n",
    "out_y = 7\n",
    "conv_len = 2048\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, out_x, out_x, conv_len))\n",
    "    labels = to_categorical(np.zeros(shape=(sample_count)),nb_clases) #INDICAR NUMERO DE CLASES\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size = (height_image, width_image),\n",
    "        batch_size = batch_size,\n",
    "        #classes = 4,\n",
    "        class_mode = 'categorical')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch) ##Asociamos al modelo preentrenado\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "#Train: 1000 muestras x clase, con 4 clases, 1000 x 4 = 4000\n",
    "train_features, train_labels = extract_features(train_dir, nb_train)\n",
    "#validation 500 muestras x clase con 4 clases, 300 x 4 = 1200\n",
    "validation_features, validation_labels = extract_features(validation_dir, nb_validation) \n",
    "#test 500 muestras x clase con 4 clases, 300 x 4 = 1200\n",
    "test_features, test_labels = extract_features(test_dir, nb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 100352)\n",
      "(1200, 100352)\n",
      "(1200, 100352)\n"
     ]
    }
   ],
   "source": [
    "#Las características extraídas están como muetras en forma (muestra, 4, 4, 512).-->(muestras, out_x, out_y, conv_len)\n",
    "#Debemos aplanarlas (muestras, 8192) para alimentar un clasificador densamente conectado 4x4x512 = 8192 si entrada 150x150\n",
    "#Debemos aplanarlas (muestras, 25088) para alimentar un clasificador densamente conectado 7x7x512 = 25088 si entrada 224x224\n",
    "\n",
    "\n",
    "train_features = np.reshape(train_features, (nb_train, out_x * out_y * conv_len))\n",
    "validation_features = np.reshape(validation_features, (nb_validation, out_x * out_y * conv_len))\n",
    "test_features = np.reshape(test_features, (nb_test, out_x * out_y * conv_len))\n",
    "print(train_features.shape)\n",
    "print(validation_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               25690368  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 25,691,396\n",
      "Trainable params: 25,691,396\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Definimos un clasificador densamente conectado capacitado con los datos y etiquetas obtenidas antes\n",
    "#Aplicamos capa de abandono Dropout y función de activación \"sigmoid\" al final\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "top_model = models.Sequential()\n",
    "top_model.add(layers.Dense(256, activation = 'relu', input_dim = out_x * out_y * conv_len))\n",
    "top_model.add(layers.Dropout(0.5))\n",
    "top_model.add(layers.Dense(nb_clases, activation = 'sigmoid'))  #INDICAR NUMERO DE CLASES\n",
    "\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1200 samples\n",
      "Epoch 1/80\n",
      "4000/4000 [==============================] - 4s 959us/step - loss: 1.1453 - acc: 0.4652 - val_loss: 0.8367 - val_acc: 0.6308\n",
      "Epoch 2/80\n",
      "4000/4000 [==============================] - 3s 850us/step - loss: 0.8335 - acc: 0.6613 - val_loss: 0.7255 - val_acc: 0.6775\n",
      "Epoch 3/80\n",
      "4000/4000 [==============================] - 3s 865us/step - loss: 0.6995 - acc: 0.7215 - val_loss: 0.6411 - val_acc: 0.7467\n",
      "Epoch 4/80\n",
      "4000/4000 [==============================] - 3s 850us/step - loss: 0.6277 - acc: 0.7552 - val_loss: 0.6180 - val_acc: 0.7400\n",
      "Epoch 5/80\n",
      "4000/4000 [==============================] - 3s 847us/step - loss: 0.5710 - acc: 0.7678 - val_loss: 0.5455 - val_acc: 0.7775\n",
      "Epoch 6/80\n",
      "4000/4000 [==============================] - 4s 924us/step - loss: 0.5228 - acc: 0.7955 - val_loss: 0.5003 - val_acc: 0.7967\n",
      "Epoch 7/80\n",
      "4000/4000 [==============================] - 4s 878us/step - loss: 0.4857 - acc: 0.8085 - val_loss: 0.5076 - val_acc: 0.8000\n",
      "Epoch 8/80\n",
      "4000/4000 [==============================] - 4s 924us/step - loss: 0.4559 - acc: 0.8312 - val_loss: 0.6082 - val_acc: 0.7608\n",
      "Epoch 9/80\n",
      "4000/4000 [==============================] - 3s 850us/step - loss: 0.4275 - acc: 0.8353 - val_loss: 0.5499 - val_acc: 0.7767\n",
      "Epoch 10/80\n",
      "4000/4000 [==============================] - 3s 865us/step - loss: 0.3918 - acc: 0.8530 - val_loss: 0.6261 - val_acc: 0.7742\n",
      "Epoch 11/80\n",
      "4000/4000 [==============================] - 3s 826us/step - loss: 0.3706 - acc: 0.8610 - val_loss: 0.5670 - val_acc: 0.7892\n",
      "Epoch 12/80\n",
      "4000/4000 [==============================] - 4s 878us/step - loss: 0.3474 - acc: 0.8725 - val_loss: 0.5254 - val_acc: 0.8008\n",
      "Epoch 13/80\n",
      "4000/4000 [==============================] - 4s 876us/step - loss: 0.3279 - acc: 0.8757 - val_loss: 0.4451 - val_acc: 0.8325\n",
      "Epoch 14/80\n",
      "4000/4000 [==============================] - 3s 829us/step - loss: 0.3157 - acc: 0.8875 - val_loss: 0.4680 - val_acc: 0.8233\n",
      "Epoch 15/80\n",
      "4000/4000 [==============================] - 4s 878us/step - loss: 0.2881 - acc: 0.8982 - val_loss: 0.5011 - val_acc: 0.8092\n",
      "Epoch 16/80\n",
      "4000/4000 [==============================] - 3s 870us/step - loss: 0.2730 - acc: 0.9015 - val_loss: 0.5115 - val_acc: 0.8117\n",
      "Epoch 17/80\n",
      "4000/4000 [==============================] - 3s 865us/step - loss: 0.2601 - acc: 0.9158 - val_loss: 0.5696 - val_acc: 0.8000\n",
      "Epoch 18/80\n",
      "4000/4000 [==============================] - 4s 881us/step - loss: 0.2472 - acc: 0.9158 - val_loss: 0.5321 - val_acc: 0.8058\n",
      "Epoch 19/80\n",
      "4000/4000 [==============================] - 3s 852us/step - loss: 0.2324 - acc: 0.9227 - val_loss: 0.4777 - val_acc: 0.8267\n",
      "Epoch 20/80\n",
      "4000/4000 [==============================] - 3s 826us/step - loss: 0.2188 - acc: 0.9233 - val_loss: 0.5255 - val_acc: 0.8025\n",
      "Epoch 21/80\n",
      "4000/4000 [==============================] - 3s 868us/step - loss: 0.2092 - acc: 0.9310 - val_loss: 0.5237 - val_acc: 0.7975\n",
      "Epoch 22/80\n",
      "4000/4000 [==============================] - 4s 923us/step - loss: 0.1993 - acc: 0.9335 - val_loss: 0.4966 - val_acc: 0.8242\n",
      "Epoch 23/80\n",
      "4000/4000 [==============================] - 3s 848us/step - loss: 0.1948 - acc: 0.9335 - val_loss: 0.4554 - val_acc: 0.8275\n",
      "Epoch 24/80\n",
      "4000/4000 [==============================] - 4s 893us/step - loss: 0.1705 - acc: 0.9450 - val_loss: 0.5848 - val_acc: 0.7933\n",
      "Epoch 25/80\n",
      "4000/4000 [==============================] - 4s 890us/step - loss: 0.1676 - acc: 0.9437 - val_loss: 0.4744 - val_acc: 0.8267\n",
      "Epoch 26/80\n",
      "4000/4000 [==============================] - 3s 865us/step - loss: 0.1625 - acc: 0.9445 - val_loss: 0.5646 - val_acc: 0.8017\n",
      "Epoch 27/80\n",
      "4000/4000 [==============================] - 3s 872us/step - loss: 0.1638 - acc: 0.9427 - val_loss: 0.4771 - val_acc: 0.8317\n",
      "Epoch 28/80\n",
      "4000/4000 [==============================] - 3s 756us/step - loss: 0.1538 - acc: 0.9475 - val_loss: 0.4675 - val_acc: 0.8283\n",
      "Epoch 29/80\n",
      "4000/4000 [==============================] - 3s 804us/step - loss: 0.1393 - acc: 0.9532 - val_loss: 0.4978 - val_acc: 0.8292\n",
      "Epoch 30/80\n",
      "4000/4000 [==============================] - 3s 838us/step - loss: 0.1364 - acc: 0.9573 - val_loss: 0.4813 - val_acc: 0.8275\n",
      "Epoch 31/80\n",
      "4000/4000 [==============================] - 4s 883us/step - loss: 0.1255 - acc: 0.9605 - val_loss: 0.4770 - val_acc: 0.8250\n",
      "Epoch 32/80\n",
      "4000/4000 [==============================] - 3s 847us/step - loss: 0.1212 - acc: 0.9610 - val_loss: 0.5194 - val_acc: 0.8242\n",
      "Epoch 33/80\n",
      "4000/4000 [==============================] - 4s 887us/step - loss: 0.1152 - acc: 0.9647 - val_loss: 0.4919 - val_acc: 0.8283\n",
      "Epoch 34/80\n",
      "4000/4000 [==============================] - 3s 862us/step - loss: 0.1084 - acc: 0.9677 - val_loss: 0.4709 - val_acc: 0.8350\n",
      "Epoch 35/80\n",
      "4000/4000 [==============================] - 4s 893us/step - loss: 0.1039 - acc: 0.9685 - val_loss: 0.5708 - val_acc: 0.8233\n",
      "Epoch 36/80\n",
      "4000/4000 [==============================] - 3s 860us/step - loss: 0.1071 - acc: 0.9657 - val_loss: 0.5230 - val_acc: 0.8242\n",
      "Epoch 37/80\n",
      "4000/4000 [==============================] - 3s 873us/step - loss: 0.1036 - acc: 0.9708 - val_loss: 0.4911 - val_acc: 0.8367\n",
      "Epoch 38/80\n",
      "4000/4000 [==============================] - 4s 891us/step - loss: 0.0900 - acc: 0.9772 - val_loss: 0.6469 - val_acc: 0.8000\n",
      "Epoch 39/80\n",
      "4000/4000 [==============================] - 3s 817us/step - loss: 0.0863 - acc: 0.9755 - val_loss: 0.5146 - val_acc: 0.8300\n",
      "Epoch 40/80\n",
      "4000/4000 [==============================] - 3s 868us/step - loss: 0.0771 - acc: 0.9772 - val_loss: 0.5531 - val_acc: 0.8250\n",
      "Epoch 41/80\n",
      "4000/4000 [==============================] - 3s 798us/step - loss: 0.0843 - acc: 0.9770 - val_loss: 0.6284 - val_acc: 0.7992\n",
      "Epoch 42/80\n",
      "4000/4000 [==============================] - 4s 887us/step - loss: 0.0717 - acc: 0.9802 - val_loss: 0.5472 - val_acc: 0.8333\n",
      "Epoch 43/80\n",
      "4000/4000 [==============================] - 3s 841us/step - loss: 0.0771 - acc: 0.9783 - val_loss: 0.5232 - val_acc: 0.8258\n",
      "Epoch 44/80\n",
      "4000/4000 [==============================] - 4s 882us/step - loss: 0.0725 - acc: 0.9798 - val_loss: 0.5482 - val_acc: 0.8208\n",
      "Epoch 45/80\n",
      "4000/4000 [==============================] - 3s 824us/step - loss: 0.0673 - acc: 0.9855 - val_loss: 0.5213 - val_acc: 0.8367\n",
      "Epoch 46/80\n",
      "4000/4000 [==============================] - 3s 866us/step - loss: 0.0734 - acc: 0.9798 - val_loss: 0.5063 - val_acc: 0.8408\n",
      "Epoch 47/80\n",
      "4000/4000 [==============================] - 4s 877us/step - loss: 0.0629 - acc: 0.9820 - val_loss: 0.5468 - val_acc: 0.8275\n",
      "Epoch 48/80\n",
      "4000/4000 [==============================] - 3s 840us/step - loss: 0.0565 - acc: 0.9868 - val_loss: 0.6101 - val_acc: 0.8075\n",
      "Epoch 49/80\n",
      "4000/4000 [==============================] - 3s 844us/step - loss: 0.0576 - acc: 0.9880 - val_loss: 0.5096 - val_acc: 0.8383\n",
      "Epoch 50/80\n",
      "4000/4000 [==============================] - 3s 864us/step - loss: 0.0575 - acc: 0.9858 - val_loss: 0.5605 - val_acc: 0.8258\n",
      "Epoch 51/80\n",
      "4000/4000 [==============================] - 4s 886us/step - loss: 0.0536 - acc: 0.9860 - val_loss: 0.5692 - val_acc: 0.8217\n",
      "Epoch 52/80\n",
      "4000/4000 [==============================] - 3s 846us/step - loss: 0.0509 - acc: 0.9890 - val_loss: 0.7328 - val_acc: 0.8017\n",
      "Epoch 53/80\n",
      "4000/4000 [==============================] - 4s 897us/step - loss: 0.0463 - acc: 0.9895 - val_loss: 0.5860 - val_acc: 0.8350\n",
      "Epoch 54/80\n",
      "4000/4000 [==============================] - 4s 889us/step - loss: 0.0455 - acc: 0.9905 - val_loss: 0.5462 - val_acc: 0.8325\n",
      "Epoch 55/80\n",
      "4000/4000 [==============================] - 3s 838us/step - loss: 0.0467 - acc: 0.9885 - val_loss: 0.5822 - val_acc: 0.8275\n",
      "Epoch 56/80\n",
      "4000/4000 [==============================] - 4s 900us/step - loss: 0.0436 - acc: 0.9905 - val_loss: 0.6064 - val_acc: 0.8200\n",
      "Epoch 57/80\n",
      "4000/4000 [==============================] - 4s 895us/step - loss: 0.0418 - acc: 0.9890 - val_loss: 0.5651 - val_acc: 0.8308\n",
      "Epoch 58/80\n",
      "4000/4000 [==============================] - 3s 851us/step - loss: 0.0371 - acc: 0.9922 - val_loss: 0.5723 - val_acc: 0.8283\n",
      "Epoch 59/80\n",
      "4000/4000 [==============================] - 3s 834us/step - loss: 0.0448 - acc: 0.9905 - val_loss: 0.6254 - val_acc: 0.8233\n",
      "Epoch 60/80\n",
      "4000/4000 [==============================] - 3s 852us/step - loss: 0.0368 - acc: 0.9922 - val_loss: 0.5662 - val_acc: 0.8375\n",
      "Epoch 61/80\n",
      "4000/4000 [==============================] - 3s 851us/step - loss: 0.0406 - acc: 0.9905 - val_loss: 0.5499 - val_acc: 0.8317\n",
      "Epoch 62/80\n",
      "4000/4000 [==============================] - 3s 834us/step - loss: 0.0331 - acc: 0.9920 - val_loss: 0.5685 - val_acc: 0.8392\n",
      "Epoch 63/80\n",
      "4000/4000 [==============================] - 4s 882us/step - loss: 0.0344 - acc: 0.9922 - val_loss: 0.5772 - val_acc: 0.8342\n",
      "Epoch 64/80\n",
      "4000/4000 [==============================] - 3s 851us/step - loss: 0.0327 - acc: 0.9935 - val_loss: 0.6148 - val_acc: 0.8283\n",
      "Epoch 65/80\n",
      "4000/4000 [==============================] - 3s 869us/step - loss: 0.0362 - acc: 0.9912 - val_loss: 0.5750 - val_acc: 0.8325\n",
      "Epoch 66/80\n",
      "4000/4000 [==============================] - 3s 842us/step - loss: 0.0334 - acc: 0.9930 - val_loss: 0.5941 - val_acc: 0.8325\n",
      "Epoch 67/80\n",
      "4000/4000 [==============================] - 3s 845us/step - loss: 0.0288 - acc: 0.9948 - val_loss: 0.5754 - val_acc: 0.8358\n",
      "Epoch 68/80\n",
      "4000/4000 [==============================] - 3s 749us/step - loss: 0.0326 - acc: 0.9920 - val_loss: 0.7134 - val_acc: 0.8200\n",
      "Epoch 69/80\n",
      "4000/4000 [==============================] - 3s 861us/step - loss: 0.0296 - acc: 0.9945 - val_loss: 0.5883 - val_acc: 0.8342\n",
      "Epoch 70/80\n",
      "4000/4000 [==============================] - 3s 836us/step - loss: 0.0271 - acc: 0.9942 - val_loss: 0.6251 - val_acc: 0.8367\n",
      "Epoch 71/80\n",
      "4000/4000 [==============================] - 3s 870us/step - loss: 0.0294 - acc: 0.9933 - val_loss: 0.5888 - val_acc: 0.8375\n",
      "Epoch 72/80\n",
      "4000/4000 [==============================] - 3s 819us/step - loss: 0.0241 - acc: 0.9940 - val_loss: 0.6807 - val_acc: 0.8092\n",
      "Epoch 73/80\n",
      "4000/4000 [==============================] - 3s 866us/step - loss: 0.0247 - acc: 0.9950 - val_loss: 0.6296 - val_acc: 0.8350\n",
      "Epoch 74/80\n",
      "4000/4000 [==============================] - 3s 800us/step - loss: 0.0244 - acc: 0.9952 - val_loss: 0.6933 - val_acc: 0.8308\n",
      "Epoch 75/80\n",
      "4000/4000 [==============================] - 4s 886us/step - loss: 0.0243 - acc: 0.9950 - val_loss: 0.7034 - val_acc: 0.8225\n",
      "Epoch 76/80\n",
      "4000/4000 [==============================] - 4s 882us/step - loss: 0.0232 - acc: 0.9952 - val_loss: 0.6243 - val_acc: 0.8367\n",
      "Epoch 77/80\n",
      "4000/4000 [==============================] - 3s 861us/step - loss: 0.0227 - acc: 0.9955 - val_loss: 0.6517 - val_acc: 0.8292\n",
      "Epoch 78/80\n",
      "4000/4000 [==============================] - 3s 846us/step - loss: 0.0224 - acc: 0.9963 - val_loss: 0.6291 - val_acc: 0.8258\n",
      "Epoch 79/80\n",
      "4000/4000 [==============================] - 3s 791us/step - loss: 0.0201 - acc: 0.9960 - val_loss: 0.6208 - val_acc: 0.8375\n",
      "Epoch 80/80\n",
      "4000/4000 [==============================] - 3s 823us/step - loss: 0.0214 - acc: 0.9952 - val_loss: 0.6401 - val_acc: 0.8275\n"
     ]
    }
   ],
   "source": [
    "#Para la compilación usaremos el optimizador RMSprop ya que termina la red con una sola\n",
    "#unidad sigmoidea, cómo función de pérdida se utiliza la entropia cruzada binaria\n",
    "\n",
    "top_model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = optimizers.RMSprop(lr=2e-5), \n",
    "              metrics = ['acc'])\n",
    "\n",
    "epochs = 80\n",
    "\n",
    "history = top_model.fit(\n",
    "    train_features,\n",
    "    train_labels,  \n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs, \n",
    "    verbose = 1, \n",
    "    validation_data = (validation_features, validation_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_model.save('Fast_Extraction_Xception_1.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Guardamos el modelo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Graficamos la Exactitud y la pérdida del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fba70a197b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fba70a5b9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Mostramos otros graficos \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+ 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "#plt.tittle('Trainning and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "#plt.tittle('Trainning and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 1s 501us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7873209877808889, 0.7975]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.evaluate(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
