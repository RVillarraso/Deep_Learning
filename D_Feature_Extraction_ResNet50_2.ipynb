{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Entreno de un ConvNet ResNet50 preentrenado con Imagenet y\n",
    "entrenando conjunto de datos pequeño\n",
    "Conjunto de datos de 4 clases\n",
    "Utilizaremos un conjunto de datos reducido:\n",
    "- Conjunto de entrenamiento: 1.000 muestras x clase \n",
    "- Conjunto de validación: 300 muestras x clase\n",
    "- Conjunto de test: 300 muestras x clase\n",
    "El conjunto de datos: balanced_dataset\n",
    "contiene tres carpetas, train, validation y test, cada una con 4 clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from  keras.preprocessing.image  import ImageDataGenerator, img_to_array, load_img \n",
    "from  keras.models  import Sequential\n",
    "from  keras.layers  import Dropout,  Flatten,  Dense\n",
    "from  keras.applications.vgg16 import VGG16 \n",
    "from keras.optimizers import RMSprop\n",
    "from  keras.utils.np_utils import to_categorical \n",
    "import time\n",
    "import os\n",
    "import numpy as np \n",
    "import math\n",
    "import  matplotlib.pyplot  as  plt\n",
    "\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "batch_size = 64 \n",
    "epochs = 500\n",
    "nb_train = 4000\n",
    "nb_validation = 1200\n",
    "nb_test = 1200\n",
    "nb_classes = 4\n",
    "\n",
    "PATH_TO_FE = \"VGG\" \n",
    "train_dir  =  \"balanced_dataset/train\"\n",
    "validation_dir = \"balanced_dataset/validation\" \n",
    "test_dir  =  \"balanced_dataset/test\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "\n",
    "model= ResNet50(weights='imagenet', \n",
    "                 include_top = False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 4 classes.\n",
      "Found 1200 images belonging to 4 classes.\n",
      "Found 1200 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#PREPROCESSING + FEATURE EXTRACTION\n",
    "\n",
    "datagen  =  ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory( \n",
    "    train_dir,\n",
    "    target_size = (img_width, img_height), \n",
    "    batch_size = batch_size,\n",
    "    class_mode  =  None,  \n",
    "    shuffle = False, \n",
    "    interpolation  =  'lanczos')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory( \n",
    "    validation_dir, \n",
    "    target_size=(img_width, img_height), \n",
    "    batch_size=batch_size, \n",
    "    class_mode=None,\n",
    "    shuffle=False, \n",
    "    interpolation  =  'lanczos')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = None,\n",
    "    shuffle=False, \n",
    "    interpolation  =  'lanczos')\n",
    "\n",
    "###########Feature Extraction (FE)#########################\n",
    "#Train\n",
    "max_size_train = int(math.ceil(nb_train / batch_size)) \n",
    "train_features = model.predict_generator(train_generator, max_size_train)\n",
    "np.save('VGG/ResNet50_FE_train_1.npy',  train_features)\n",
    "#Validation\n",
    "max_size_validation = int(math.ceil(nb_validation / batch_size)) \n",
    "validation_features  =  model.predict_generator(validation_generator,  max_size_validation) \n",
    "np.save('VGG/ResNet50_FE_validation_1.npy',  validation_features)\n",
    "#Test\n",
    "max_size_test = int(math.ceil(nb_test / batch_size)) \n",
    "test_features  =  model.predict_generator(test_generator,  max_size_test)\n",
    "\n",
    "#Labels Extraction\n",
    "train_labels  =  train_generator.classes  \n",
    "train_labels = to_categorical(train_labels, num_classes=nb_classes) \n",
    "validation_labels  =  validation_generator.classes  \n",
    "validation_labels  =  to_categorical(validation_labels,  num_classes=nb_classes) \n",
    "test_labels  =  test_generator.classes  \n",
    "test_labels  =  to_categorical(test_labels,  num_classes=nb_classes) \n",
    "\n",
    "#Save Features\n",
    "train_data = np.load('VGG/ResNet50_FE_train_1.npy') \n",
    "validation_data  =  np.load('VGG/ResNet50_FE_validation_1.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Top Model Classificator\n",
    "model = Sequential() \n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256,  activation='relu')) \n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes,  activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compile models\n",
    "model.compile(\n",
    "    optimizer = RMSprop(lr=2e-5),\n",
    "    loss='categorical_crossentropy',  \n",
    "    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1200 samples\n",
      "Epoch 1/500\n",
      "4000/4000 [==============================] - 1s 200us/step - loss: 1.6290 - acc: 0.2477 - val_loss: 1.3877 - val_acc: 0.2500\n",
      "Epoch 2/500\n",
      "4000/4000 [==============================] - 0s 54us/step - loss: 1.5613 - acc: 0.2522 - val_loss: 1.3856 - val_acc: 0.2500\n",
      "Epoch 3/500\n",
      "4000/4000 [==============================] - 0s 48us/step - loss: 1.5309 - acc: 0.2520 - val_loss: 1.3845 - val_acc: 0.2667\n",
      "Epoch 4/500\n",
      "4000/4000 [==============================] - 0s 49us/step - loss: 1.5042 - acc: 0.2495 - val_loss: 1.3846 - val_acc: 0.2492\n",
      "Epoch 5/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.4723 - acc: 0.2540 - val_loss: 1.3834 - val_acc: 0.2467\n",
      "Epoch 6/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.4587 - acc: 0.2605 - val_loss: 1.3832 - val_acc: 0.2317\n",
      "Epoch 7/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.4527 - acc: 0.2422 - val_loss: 1.3822 - val_acc: 0.3125\n",
      "Epoch 8/500\n",
      "4000/4000 [==============================] - 0s 44us/step - loss: 1.4384 - acc: 0.2540 - val_loss: 1.3816 - val_acc: 0.3133\n",
      "Epoch 9/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.4327 - acc: 0.2512 - val_loss: 1.3813 - val_acc: 0.2775\n",
      "Epoch 10/500\n",
      "4000/4000 [==============================] - 0s 44us/step - loss: 1.4251 - acc: 0.2525 - val_loss: 1.3812 - val_acc: 0.2775\n",
      "Epoch 11/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.4155 - acc: 0.2505 - val_loss: 1.3799 - val_acc: 0.3683\n",
      "Epoch 12/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.4053 - acc: 0.2545 - val_loss: 1.3790 - val_acc: 0.4242\n",
      "Epoch 13/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.4010 - acc: 0.2655 - val_loss: 1.3811 - val_acc: 0.2967\n",
      "Epoch 14/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3977 - acc: 0.2600 - val_loss: 1.3781 - val_acc: 0.3767\n",
      "Epoch 15/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3976 - acc: 0.2665 - val_loss: 1.3780 - val_acc: 0.2575\n",
      "Epoch 16/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3907 - acc: 0.2762 - val_loss: 1.3775 - val_acc: 0.2808\n",
      "Epoch 17/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3879 - acc: 0.2710 - val_loss: 1.3766 - val_acc: 0.3675\n",
      "Epoch 18/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3872 - acc: 0.2792 - val_loss: 1.3762 - val_acc: 0.3750\n",
      "Epoch 19/500\n",
      "4000/4000 [==============================] - 0s 45us/step - loss: 1.3866 - acc: 0.2687 - val_loss: 1.3759 - val_acc: 0.3008\n",
      "Epoch 20/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3830 - acc: 0.2775 - val_loss: 1.3758 - val_acc: 0.2775\n",
      "Epoch 21/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3827 - acc: 0.2702 - val_loss: 1.3745 - val_acc: 0.4100\n",
      "Epoch 22/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3808 - acc: 0.2755 - val_loss: 1.3737 - val_acc: 0.4317\n",
      "Epoch 23/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3797 - acc: 0.2883 - val_loss: 1.3733 - val_acc: 0.3142\n",
      "Epoch 24/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3771 - acc: 0.2908 - val_loss: 1.3730 - val_acc: 0.3317\n",
      "Epoch 25/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3783 - acc: 0.2880 - val_loss: 1.3725 - val_acc: 0.3683\n",
      "Epoch 26/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3780 - acc: 0.2958 - val_loss: 1.3720 - val_acc: 0.3775\n",
      "Epoch 27/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3773 - acc: 0.2923 - val_loss: 1.3713 - val_acc: 0.3850\n",
      "Epoch 28/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3749 - acc: 0.3050 - val_loss: 1.3708 - val_acc: 0.3742\n",
      "Epoch 29/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3761 - acc: 0.3060 - val_loss: 1.3706 - val_acc: 0.4183\n",
      "Epoch 30/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3728 - acc: 0.3070 - val_loss: 1.3699 - val_acc: 0.4242\n",
      "Epoch 31/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3747 - acc: 0.3085 - val_loss: 1.3694 - val_acc: 0.4908\n",
      "Epoch 32/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3741 - acc: 0.3045 - val_loss: 1.3693 - val_acc: 0.4350\n",
      "Epoch 33/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3723 - acc: 0.3212 - val_loss: 1.3690 - val_acc: 0.3558\n",
      "Epoch 34/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3729 - acc: 0.3190 - val_loss: 1.3681 - val_acc: 0.3992\n",
      "Epoch 35/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3720 - acc: 0.3185 - val_loss: 1.3676 - val_acc: 0.4733\n",
      "Epoch 36/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3715 - acc: 0.3260 - val_loss: 1.3672 - val_acc: 0.4550\n",
      "Epoch 37/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3693 - acc: 0.3325 - val_loss: 1.3669 - val_acc: 0.4008\n",
      "Epoch 38/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3696 - acc: 0.3307 - val_loss: 1.3671 - val_acc: 0.3958\n",
      "Epoch 39/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3694 - acc: 0.3330 - val_loss: 1.3668 - val_acc: 0.3967\n",
      "Epoch 40/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3689 - acc: 0.3430 - val_loss: 1.3656 - val_acc: 0.4475\n",
      "Epoch 41/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3684 - acc: 0.3430 - val_loss: 1.3651 - val_acc: 0.4075\n",
      "Epoch 42/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3677 - acc: 0.3443 - val_loss: 1.3644 - val_acc: 0.4550\n",
      "Epoch 43/500\n",
      "4000/4000 [==============================] - 0s 50us/step - loss: 1.3682 - acc: 0.3320 - val_loss: 1.3645 - val_acc: 0.4350\n",
      "Epoch 44/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3676 - acc: 0.3448 - val_loss: 1.3638 - val_acc: 0.4042\n",
      "Epoch 45/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3676 - acc: 0.3450 - val_loss: 1.3636 - val_acc: 0.4000\n",
      "Epoch 46/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3668 - acc: 0.3395 - val_loss: 1.3638 - val_acc: 0.4083\n",
      "Epoch 47/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3651 - acc: 0.3538 - val_loss: 1.3632 - val_acc: 0.3908\n",
      "Epoch 48/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3665 - acc: 0.3580 - val_loss: 1.3619 - val_acc: 0.4458\n",
      "Epoch 49/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3660 - acc: 0.3608 - val_loss: 1.3620 - val_acc: 0.3917\n",
      "Epoch 50/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3645 - acc: 0.3545 - val_loss: 1.3608 - val_acc: 0.4350\n",
      "Epoch 51/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3646 - acc: 0.3525 - val_loss: 1.3608 - val_acc: 0.4400\n",
      "Epoch 52/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3632 - acc: 0.3605 - val_loss: 1.3602 - val_acc: 0.4117\n",
      "Epoch 53/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3635 - acc: 0.3583 - val_loss: 1.3594 - val_acc: 0.4450\n",
      "Epoch 54/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3629 - acc: 0.3645 - val_loss: 1.3589 - val_acc: 0.4775\n",
      "Epoch 55/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3622 - acc: 0.3670 - val_loss: 1.3588 - val_acc: 0.4225\n",
      "Epoch 56/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3617 - acc: 0.3635 - val_loss: 1.3577 - val_acc: 0.4808\n",
      "Epoch 57/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3621 - acc: 0.3570 - val_loss: 1.3579 - val_acc: 0.4158\n",
      "Epoch 58/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3607 - acc: 0.3640 - val_loss: 1.3573 - val_acc: 0.4517\n",
      "Epoch 59/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3602 - acc: 0.3573 - val_loss: 1.3570 - val_acc: 0.4342\n",
      "Epoch 60/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3598 - acc: 0.3753 - val_loss: 1.3564 - val_acc: 0.4533\n",
      "Epoch 61/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3586 - acc: 0.3710 - val_loss: 1.3556 - val_acc: 0.4900\n",
      "Epoch 62/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3574 - acc: 0.3743 - val_loss: 1.3553 - val_acc: 0.4200\n",
      "Epoch 63/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3592 - acc: 0.3720 - val_loss: 1.3544 - val_acc: 0.4858\n",
      "Epoch 64/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3587 - acc: 0.3738 - val_loss: 1.3538 - val_acc: 0.4667\n",
      "Epoch 65/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3583 - acc: 0.3680 - val_loss: 1.3535 - val_acc: 0.4558\n",
      "Epoch 66/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3571 - acc: 0.3710 - val_loss: 1.3533 - val_acc: 0.4475\n",
      "Epoch 67/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3573 - acc: 0.3738 - val_loss: 1.3531 - val_acc: 0.4700\n",
      "Epoch 68/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3557 - acc: 0.3940 - val_loss: 1.3522 - val_acc: 0.4417\n",
      "Epoch 69/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3573 - acc: 0.3765 - val_loss: 1.3515 - val_acc: 0.4325\n",
      "Epoch 70/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3563 - acc: 0.3798 - val_loss: 1.3517 - val_acc: 0.4142\n",
      "Epoch 71/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3561 - acc: 0.3770 - val_loss: 1.3508 - val_acc: 0.4100\n",
      "Epoch 72/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3556 - acc: 0.3873 - val_loss: 1.3501 - val_acc: 0.4333\n",
      "Epoch 73/500\n",
      "4000/4000 [==============================] - 0s 45us/step - loss: 1.3550 - acc: 0.3930 - val_loss: 1.3497 - val_acc: 0.4450\n",
      "Epoch 74/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3532 - acc: 0.3985 - val_loss: 1.3489 - val_acc: 0.4567\n",
      "Epoch 75/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.3526 - acc: 0.3862 - val_loss: 1.3486 - val_acc: 0.4225\n",
      "Epoch 76/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3519 - acc: 0.3910 - val_loss: 1.3485 - val_acc: 0.4467\n",
      "Epoch 77/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3516 - acc: 0.3835 - val_loss: 1.3480 - val_acc: 0.4050\n",
      "Epoch 78/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3530 - acc: 0.3813 - val_loss: 1.3479 - val_acc: 0.4442\n",
      "Epoch 79/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3519 - acc: 0.3888 - val_loss: 1.3465 - val_acc: 0.4525\n",
      "Epoch 80/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3496 - acc: 0.3997 - val_loss: 1.3461 - val_acc: 0.4483\n",
      "Epoch 81/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3511 - acc: 0.3858 - val_loss: 1.3461 - val_acc: 0.4108\n",
      "Epoch 82/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3499 - acc: 0.3962 - val_loss: 1.3448 - val_acc: 0.4592\n",
      "Epoch 83/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3495 - acc: 0.3885 - val_loss: 1.3444 - val_acc: 0.4558\n",
      "Epoch 84/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3489 - acc: 0.3987 - val_loss: 1.3440 - val_acc: 0.4550\n",
      "Epoch 85/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3491 - acc: 0.3965 - val_loss: 1.3431 - val_acc: 0.4808\n",
      "Epoch 86/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3471 - acc: 0.3945 - val_loss: 1.3431 - val_acc: 0.4150\n",
      "Epoch 87/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3459 - acc: 0.4017 - val_loss: 1.3429 - val_acc: 0.4758\n",
      "Epoch 88/500\n",
      "4000/4000 [==============================] - 0s 44us/step - loss: 1.3470 - acc: 0.4095 - val_loss: 1.3416 - val_acc: 0.4525\n",
      "Epoch 89/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3458 - acc: 0.4030 - val_loss: 1.3411 - val_acc: 0.4608\n",
      "Epoch 90/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3458 - acc: 0.3962 - val_loss: 1.3405 - val_acc: 0.4858\n",
      "Epoch 91/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3462 - acc: 0.3962 - val_loss: 1.3401 - val_acc: 0.4783\n",
      "Epoch 92/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3460 - acc: 0.3995 - val_loss: 1.3393 - val_acc: 0.4642\n",
      "Epoch 93/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3450 - acc: 0.4052 - val_loss: 1.3396 - val_acc: 0.4758\n",
      "Epoch 94/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3430 - acc: 0.4057 - val_loss: 1.3384 - val_acc: 0.4858\n",
      "Epoch 95/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3437 - acc: 0.4045 - val_loss: 1.3377 - val_acc: 0.4542\n",
      "Epoch 96/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3432 - acc: 0.3897 - val_loss: 1.3375 - val_acc: 0.4183\n",
      "Epoch 97/500\n",
      "4000/4000 [==============================] - 0s 44us/step - loss: 1.3416 - acc: 0.4068 - val_loss: 1.3371 - val_acc: 0.4717\n",
      "Epoch 98/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3423 - acc: 0.4065 - val_loss: 1.3366 - val_acc: 0.4592\n",
      "Epoch 99/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3413 - acc: 0.4007 - val_loss: 1.3380 - val_acc: 0.4158\n",
      "Epoch 100/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3423 - acc: 0.3990 - val_loss: 1.3353 - val_acc: 0.4833\n",
      "Epoch 101/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3404 - acc: 0.4062 - val_loss: 1.3346 - val_acc: 0.4850\n",
      "Epoch 102/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3396 - acc: 0.4090 - val_loss: 1.3342 - val_acc: 0.4608\n",
      "Epoch 103/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.3391 - acc: 0.3985 - val_loss: 1.3334 - val_acc: 0.4658\n",
      "Epoch 104/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3391 - acc: 0.4123 - val_loss: 1.3334 - val_acc: 0.4858\n",
      "Epoch 105/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3393 - acc: 0.4138 - val_loss: 1.3325 - val_acc: 0.4833\n",
      "Epoch 106/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3364 - acc: 0.4170 - val_loss: 1.3319 - val_acc: 0.4417\n",
      "Epoch 107/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3357 - acc: 0.4050 - val_loss: 1.3325 - val_acc: 0.4258\n",
      "Epoch 108/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3362 - acc: 0.4120 - val_loss: 1.3311 - val_acc: 0.4375\n",
      "Epoch 109/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3366 - acc: 0.4115 - val_loss: 1.3300 - val_acc: 0.4783\n",
      "Epoch 110/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3363 - acc: 0.4133 - val_loss: 1.3292 - val_acc: 0.5000\n",
      "Epoch 111/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3355 - acc: 0.4145 - val_loss: 1.3291 - val_acc: 0.4525\n",
      "Epoch 112/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3372 - acc: 0.4118 - val_loss: 1.3290 - val_acc: 0.4775\n",
      "Epoch 113/500\n",
      "4000/4000 [==============================] - 0s 44us/step - loss: 1.3357 - acc: 0.4190 - val_loss: 1.3287 - val_acc: 0.4783\n",
      "Epoch 114/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3337 - acc: 0.4198 - val_loss: 1.3275 - val_acc: 0.4525\n",
      "Epoch 115/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3317 - acc: 0.4230 - val_loss: 1.3267 - val_acc: 0.4742\n",
      "Epoch 116/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3332 - acc: 0.4057 - val_loss: 1.3260 - val_acc: 0.4650\n",
      "Epoch 117/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3327 - acc: 0.4128 - val_loss: 1.3259 - val_acc: 0.4900\n",
      "Epoch 118/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3313 - acc: 0.4128 - val_loss: 1.3254 - val_acc: 0.4775\n",
      "Epoch 119/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3315 - acc: 0.4155 - val_loss: 1.3244 - val_acc: 0.5008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3286 - acc: 0.4183 - val_loss: 1.3244 - val_acc: 0.4458\n",
      "Epoch 121/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3318 - acc: 0.4093 - val_loss: 1.3242 - val_acc: 0.4600\n",
      "Epoch 122/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3288 - acc: 0.4198 - val_loss: 1.3228 - val_acc: 0.5000\n",
      "Epoch 123/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3320 - acc: 0.4153 - val_loss: 1.3223 - val_acc: 0.4650\n",
      "Epoch 124/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3297 - acc: 0.4222 - val_loss: 1.3218 - val_acc: 0.4700\n",
      "Epoch 125/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3280 - acc: 0.4185 - val_loss: 1.3211 - val_acc: 0.4792\n",
      "Epoch 126/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3266 - acc: 0.4240 - val_loss: 1.3209 - val_acc: 0.4575\n",
      "Epoch 127/500\n",
      "4000/4000 [==============================] - 0s 45us/step - loss: 1.3278 - acc: 0.4170 - val_loss: 1.3202 - val_acc: 0.4908\n",
      "Epoch 128/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3242 - acc: 0.4282 - val_loss: 1.3201 - val_acc: 0.4850\n",
      "Epoch 129/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3265 - acc: 0.4203 - val_loss: 1.3197 - val_acc: 0.4675\n",
      "Epoch 130/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3258 - acc: 0.4140 - val_loss: 1.3182 - val_acc: 0.4750\n",
      "Epoch 131/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3240 - acc: 0.4220 - val_loss: 1.3195 - val_acc: 0.4742\n",
      "Epoch 132/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3241 - acc: 0.4245 - val_loss: 1.3172 - val_acc: 0.4600\n",
      "Epoch 133/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3231 - acc: 0.4163 - val_loss: 1.3169 - val_acc: 0.4992\n",
      "Epoch 134/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3262 - acc: 0.4105 - val_loss: 1.3167 - val_acc: 0.4633\n",
      "Epoch 135/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3226 - acc: 0.4160 - val_loss: 1.3173 - val_acc: 0.4708\n",
      "Epoch 136/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3228 - acc: 0.4250 - val_loss: 1.3151 - val_acc: 0.4792\n",
      "Epoch 137/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3232 - acc: 0.4233 - val_loss: 1.3149 - val_acc: 0.4750\n",
      "Epoch 138/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3216 - acc: 0.4330 - val_loss: 1.3138 - val_acc: 0.4800\n",
      "Epoch 139/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3206 - acc: 0.4230 - val_loss: 1.3131 - val_acc: 0.4917\n",
      "Epoch 140/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3203 - acc: 0.4273 - val_loss: 1.3135 - val_acc: 0.4850\n",
      "Epoch 141/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3214 - acc: 0.4222 - val_loss: 1.3150 - val_acc: 0.4283\n",
      "Epoch 142/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3199 - acc: 0.4265 - val_loss: 1.3119 - val_acc: 0.4942\n",
      "Epoch 143/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.3197 - acc: 0.4288 - val_loss: 1.3111 - val_acc: 0.4775\n",
      "Epoch 144/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3180 - acc: 0.4348 - val_loss: 1.3110 - val_acc: 0.4858\n",
      "Epoch 145/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3167 - acc: 0.4278 - val_loss: 1.3117 - val_acc: 0.4450\n",
      "Epoch 146/500\n",
      "4000/4000 [==============================] - 0s 39us/step - loss: 1.3175 - acc: 0.4183 - val_loss: 1.3095 - val_acc: 0.4867\n",
      "Epoch 147/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3150 - acc: 0.4267 - val_loss: 1.3116 - val_acc: 0.4775\n",
      "Epoch 148/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3159 - acc: 0.4320 - val_loss: 1.3078 - val_acc: 0.4750\n",
      "Epoch 149/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3158 - acc: 0.4363 - val_loss: 1.3088 - val_acc: 0.4550\n",
      "Epoch 150/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3153 - acc: 0.4278 - val_loss: 1.3074 - val_acc: 0.4675\n",
      "Epoch 151/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3123 - acc: 0.4387 - val_loss: 1.3064 - val_acc: 0.4958\n",
      "Epoch 152/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.3136 - acc: 0.4330 - val_loss: 1.3056 - val_acc: 0.4917\n",
      "Epoch 153/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3116 - acc: 0.4382 - val_loss: 1.3054 - val_acc: 0.4700\n",
      "Epoch 154/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3118 - acc: 0.4267 - val_loss: 1.3047 - val_acc: 0.4833\n",
      "Epoch 155/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3118 - acc: 0.4290 - val_loss: 1.3042 - val_acc: 0.4525\n",
      "Epoch 156/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3129 - acc: 0.4353 - val_loss: 1.3032 - val_acc: 0.4633\n",
      "Epoch 157/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3133 - acc: 0.4295 - val_loss: 1.3034 - val_acc: 0.4650\n",
      "Epoch 158/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3109 - acc: 0.4408 - val_loss: 1.3034 - val_acc: 0.4708\n",
      "Epoch 159/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3095 - acc: 0.4370 - val_loss: 1.3022 - val_acc: 0.4742\n",
      "Epoch 160/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3112 - acc: 0.4240 - val_loss: 1.3031 - val_acc: 0.4725\n",
      "Epoch 161/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3103 - acc: 0.4273 - val_loss: 1.3005 - val_acc: 0.4967\n",
      "Epoch 162/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3091 - acc: 0.4372 - val_loss: 1.3003 - val_acc: 0.4975\n",
      "Epoch 163/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3098 - acc: 0.4335 - val_loss: 1.3013 - val_acc: 0.4567\n",
      "Epoch 164/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3091 - acc: 0.4400 - val_loss: 1.2998 - val_acc: 0.4950\n",
      "Epoch 165/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3060 - acc: 0.4440 - val_loss: 1.2989 - val_acc: 0.4883\n",
      "Epoch 166/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3079 - acc: 0.4320 - val_loss: 1.2984 - val_acc: 0.4725\n",
      "Epoch 167/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3061 - acc: 0.4310 - val_loss: 1.2974 - val_acc: 0.4742\n",
      "Epoch 168/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3073 - acc: 0.4345 - val_loss: 1.2974 - val_acc: 0.4467\n",
      "Epoch 169/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3057 - acc: 0.4415 - val_loss: 1.2961 - val_acc: 0.4767\n",
      "Epoch 170/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3049 - acc: 0.4372 - val_loss: 1.2961 - val_acc: 0.4667\n",
      "Epoch 171/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3046 - acc: 0.4400 - val_loss: 1.2948 - val_acc: 0.4867\n",
      "Epoch 172/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3019 - acc: 0.4263 - val_loss: 1.2953 - val_acc: 0.4967\n",
      "Epoch 173/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.3013 - acc: 0.4470 - val_loss: 1.2943 - val_acc: 0.4858\n",
      "Epoch 174/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3066 - acc: 0.4342 - val_loss: 1.2938 - val_acc: 0.4742\n",
      "Epoch 175/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3024 - acc: 0.4387 - val_loss: 1.2926 - val_acc: 0.4842\n",
      "Epoch 176/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.3012 - acc: 0.4412 - val_loss: 1.2933 - val_acc: 0.4592\n",
      "Epoch 177/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3026 - acc: 0.4370 - val_loss: 1.2916 - val_acc: 0.5058\n",
      "Epoch 178/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3015 - acc: 0.4410 - val_loss: 1.2912 - val_acc: 0.5092\n",
      "Epoch 179/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2992 - acc: 0.4455 - val_loss: 1.2912 - val_acc: 0.5017\n",
      "Epoch 180/500\n",
      "4000/4000 [==============================] - 0s 39us/step - loss: 1.2981 - acc: 0.4425 - val_loss: 1.2910 - val_acc: 0.4533\n",
      "Epoch 181/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2989 - acc: 0.4360 - val_loss: 1.2910 - val_acc: 0.4975\n",
      "Epoch 182/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2976 - acc: 0.4438 - val_loss: 1.2892 - val_acc: 0.4883\n",
      "Epoch 183/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.3005 - acc: 0.4412 - val_loss: 1.2895 - val_acc: 0.4683\n",
      "Epoch 184/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2992 - acc: 0.4323 - val_loss: 1.2880 - val_acc: 0.4983\n",
      "Epoch 185/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2964 - acc: 0.4498 - val_loss: 1.2885 - val_acc: 0.4783\n",
      "Epoch 186/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2973 - acc: 0.4500 - val_loss: 1.2882 - val_acc: 0.4925\n",
      "Epoch 187/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2963 - acc: 0.4447 - val_loss: 1.2860 - val_acc: 0.4967\n",
      "Epoch 188/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2974 - acc: 0.4382 - val_loss: 1.2853 - val_acc: 0.4792\n",
      "Epoch 189/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2929 - acc: 0.4423 - val_loss: 1.2852 - val_acc: 0.4983\n",
      "Epoch 190/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2947 - acc: 0.4490 - val_loss: 1.2840 - val_acc: 0.4850\n",
      "Epoch 191/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2915 - acc: 0.4487 - val_loss: 1.2836 - val_acc: 0.5042\n",
      "Epoch 192/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2962 - acc: 0.4537 - val_loss: 1.2830 - val_acc: 0.4858\n",
      "Epoch 193/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2927 - acc: 0.4430 - val_loss: 1.2845 - val_acc: 0.4792\n",
      "Epoch 194/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2922 - acc: 0.4472 - val_loss: 1.2827 - val_acc: 0.4967\n",
      "Epoch 195/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2922 - acc: 0.4410 - val_loss: 1.2812 - val_acc: 0.4900\n",
      "Epoch 196/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2907 - acc: 0.4440 - val_loss: 1.2813 - val_acc: 0.4700\n",
      "Epoch 197/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2896 - acc: 0.4465 - val_loss: 1.2803 - val_acc: 0.5008\n",
      "Epoch 198/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2878 - acc: 0.4432 - val_loss: 1.2808 - val_acc: 0.5008\n",
      "Epoch 199/500\n",
      "4000/4000 [==============================] - 0s 45us/step - loss: 1.2894 - acc: 0.4450 - val_loss: 1.2796 - val_acc: 0.4775\n",
      "Epoch 200/500\n",
      "4000/4000 [==============================] - 0s 48us/step - loss: 1.2903 - acc: 0.4410 - val_loss: 1.2793 - val_acc: 0.4650\n",
      "Epoch 201/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2902 - acc: 0.4427 - val_loss: 1.2800 - val_acc: 0.4967\n",
      "Epoch 202/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2878 - acc: 0.4455 - val_loss: 1.2778 - val_acc: 0.4967\n",
      "Epoch 203/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2880 - acc: 0.4405 - val_loss: 1.2773 - val_acc: 0.4883\n",
      "Epoch 204/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2898 - acc: 0.4405 - val_loss: 1.2769 - val_acc: 0.4917\n",
      "Epoch 205/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2873 - acc: 0.4468 - val_loss: 1.2763 - val_acc: 0.4933\n",
      "Epoch 206/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2883 - acc: 0.4447 - val_loss: 1.2760 - val_acc: 0.4917\n",
      "Epoch 207/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2835 - acc: 0.4640 - val_loss: 1.2760 - val_acc: 0.5033\n",
      "Epoch 208/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2845 - acc: 0.4400 - val_loss: 1.2747 - val_acc: 0.4783\n",
      "Epoch 209/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2865 - acc: 0.4500 - val_loss: 1.2738 - val_acc: 0.4942\n",
      "Epoch 210/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2835 - acc: 0.4430 - val_loss: 1.2734 - val_acc: 0.5050\n",
      "Epoch 211/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2814 - acc: 0.4498 - val_loss: 1.2741 - val_acc: 0.4792\n",
      "Epoch 212/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2822 - acc: 0.4477 - val_loss: 1.2724 - val_acc: 0.4808\n",
      "Epoch 213/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2831 - acc: 0.4490 - val_loss: 1.2712 - val_acc: 0.4783\n",
      "Epoch 214/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2829 - acc: 0.4457 - val_loss: 1.2711 - val_acc: 0.4992\n",
      "Epoch 215/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2850 - acc: 0.4513 - val_loss: 1.2708 - val_acc: 0.4733\n",
      "Epoch 216/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2825 - acc: 0.4495 - val_loss: 1.2699 - val_acc: 0.5042\n",
      "Epoch 217/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2780 - acc: 0.4547 - val_loss: 1.2691 - val_acc: 0.5017\n",
      "Epoch 218/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2809 - acc: 0.4457 - val_loss: 1.2694 - val_acc: 0.5058\n",
      "Epoch 219/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2810 - acc: 0.4477 - val_loss: 1.2686 - val_acc: 0.5067\n",
      "Epoch 220/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2799 - acc: 0.4587 - val_loss: 1.2687 - val_acc: 0.4792\n",
      "Epoch 221/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2779 - acc: 0.4495 - val_loss: 1.2676 - val_acc: 0.5158\n",
      "Epoch 222/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2803 - acc: 0.4490 - val_loss: 1.2687 - val_acc: 0.4783\n",
      "Epoch 223/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2768 - acc: 0.4582 - val_loss: 1.2673 - val_acc: 0.4992\n",
      "Epoch 224/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2767 - acc: 0.4627 - val_loss: 1.2659 - val_acc: 0.4950\n",
      "Epoch 225/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2773 - acc: 0.4457 - val_loss: 1.2660 - val_acc: 0.5108\n",
      "Epoch 226/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2794 - acc: 0.4485 - val_loss: 1.2647 - val_acc: 0.5100\n",
      "Epoch 227/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2754 - acc: 0.4515 - val_loss: 1.2646 - val_acc: 0.4933\n",
      "Epoch 228/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2752 - acc: 0.4550 - val_loss: 1.2635 - val_acc: 0.4883\n",
      "Epoch 229/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2746 - acc: 0.4562 - val_loss: 1.2628 - val_acc: 0.5033\n",
      "Epoch 230/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2757 - acc: 0.4525 - val_loss: 1.2633 - val_acc: 0.5058\n",
      "Epoch 231/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2747 - acc: 0.4513 - val_loss: 1.2662 - val_acc: 0.4975\n",
      "Epoch 232/500\n",
      "4000/4000 [==============================] - 0s 44us/step - loss: 1.2746 - acc: 0.4635 - val_loss: 1.2634 - val_acc: 0.4842\n",
      "Epoch 233/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2754 - acc: 0.4585 - val_loss: 1.2612 - val_acc: 0.4950\n",
      "Epoch 234/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2691 - acc: 0.4637 - val_loss: 1.2633 - val_acc: 0.4950\n",
      "Epoch 235/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2710 - acc: 0.4615 - val_loss: 1.2601 - val_acc: 0.4975\n",
      "Epoch 236/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2715 - acc: 0.4530 - val_loss: 1.2593 - val_acc: 0.4950\n",
      "Epoch 237/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2682 - acc: 0.4625 - val_loss: 1.2598 - val_acc: 0.4942\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2702 - acc: 0.4535 - val_loss: 1.2598 - val_acc: 0.5050\n",
      "Epoch 239/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2701 - acc: 0.4525 - val_loss: 1.2579 - val_acc: 0.4942\n",
      "Epoch 240/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2651 - acc: 0.4572 - val_loss: 1.2598 - val_acc: 0.4842\n",
      "Epoch 241/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2683 - acc: 0.4567 - val_loss: 1.2562 - val_acc: 0.4992\n",
      "Epoch 242/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2705 - acc: 0.4595 - val_loss: 1.2572 - val_acc: 0.5108\n",
      "Epoch 243/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2696 - acc: 0.4570 - val_loss: 1.2560 - val_acc: 0.4958\n",
      "Epoch 244/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2691 - acc: 0.4513 - val_loss: 1.2556 - val_acc: 0.5167\n",
      "Epoch 245/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2677 - acc: 0.4590 - val_loss: 1.2552 - val_acc: 0.5050\n",
      "Epoch 246/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2665 - acc: 0.4650 - val_loss: 1.2559 - val_acc: 0.4975\n",
      "Epoch 247/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2689 - acc: 0.4540 - val_loss: 1.2576 - val_acc: 0.4900\n",
      "Epoch 248/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2682 - acc: 0.4640 - val_loss: 1.2533 - val_acc: 0.5050\n",
      "Epoch 249/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2620 - acc: 0.4590 - val_loss: 1.2531 - val_acc: 0.4725\n",
      "Epoch 250/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2658 - acc: 0.4575 - val_loss: 1.2525 - val_acc: 0.5050\n",
      "Epoch 251/500\n",
      "4000/4000 [==============================] - 0s 45us/step - loss: 1.2645 - acc: 0.4550 - val_loss: 1.2515 - val_acc: 0.4917\n",
      "Epoch 252/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2621 - acc: 0.4570 - val_loss: 1.2507 - val_acc: 0.4942\n",
      "Epoch 253/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2653 - acc: 0.4513 - val_loss: 1.2517 - val_acc: 0.5183\n",
      "Epoch 254/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2619 - acc: 0.4605 - val_loss: 1.2512 - val_acc: 0.4950\n",
      "Epoch 255/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2636 - acc: 0.4622 - val_loss: 1.2505 - val_acc: 0.5075\n",
      "Epoch 256/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2618 - acc: 0.4612 - val_loss: 1.2501 - val_acc: 0.5167\n",
      "Epoch 257/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2599 - acc: 0.4627 - val_loss: 1.2487 - val_acc: 0.4925\n",
      "Epoch 258/500\n",
      "4000/4000 [==============================] - 0s 50us/step - loss: 1.2621 - acc: 0.4615 - val_loss: 1.2484 - val_acc: 0.4883\n",
      "Epoch 259/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2553 - acc: 0.4733 - val_loss: 1.2483 - val_acc: 0.4858\n",
      "Epoch 260/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2599 - acc: 0.4595 - val_loss: 1.2474 - val_acc: 0.5008\n",
      "Epoch 261/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2585 - acc: 0.4600 - val_loss: 1.2476 - val_acc: 0.5158\n",
      "Epoch 262/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2613 - acc: 0.4632 - val_loss: 1.2469 - val_acc: 0.5150\n",
      "Epoch 263/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2590 - acc: 0.4627 - val_loss: 1.2463 - val_acc: 0.5067\n",
      "Epoch 264/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2577 - acc: 0.4682 - val_loss: 1.2446 - val_acc: 0.5133\n",
      "Epoch 265/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2580 - acc: 0.4672 - val_loss: 1.2456 - val_acc: 0.5075\n",
      "Epoch 266/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2554 - acc: 0.4637 - val_loss: 1.2440 - val_acc: 0.4883\n",
      "Epoch 267/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2600 - acc: 0.4585 - val_loss: 1.2456 - val_acc: 0.4817\n",
      "Epoch 268/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2557 - acc: 0.4602 - val_loss: 1.2429 - val_acc: 0.5200\n",
      "Epoch 269/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2576 - acc: 0.4655 - val_loss: 1.2428 - val_acc: 0.4917\n",
      "Epoch 270/500\n",
      "4000/4000 [==============================] - 0s 46us/step - loss: 1.2565 - acc: 0.4640 - val_loss: 1.2433 - val_acc: 0.5125\n",
      "Epoch 271/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2533 - acc: 0.4642 - val_loss: 1.2414 - val_acc: 0.4950\n",
      "Epoch 272/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2582 - acc: 0.4620 - val_loss: 1.2423 - val_acc: 0.4825\n",
      "Epoch 273/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2522 - acc: 0.4695 - val_loss: 1.2416 - val_acc: 0.4900\n",
      "Epoch 274/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2553 - acc: 0.4590 - val_loss: 1.2432 - val_acc: 0.5017\n",
      "Epoch 275/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2526 - acc: 0.4775 - val_loss: 1.2396 - val_acc: 0.5117\n",
      "Epoch 276/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2528 - acc: 0.4592 - val_loss: 1.2389 - val_acc: 0.5092\n",
      "Epoch 277/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2496 - acc: 0.4735 - val_loss: 1.2401 - val_acc: 0.4933\n",
      "Epoch 278/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2513 - acc: 0.4647 - val_loss: 1.2399 - val_acc: 0.5167\n",
      "Epoch 279/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2554 - acc: 0.4657 - val_loss: 1.2381 - val_acc: 0.4958\n",
      "Epoch 280/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2495 - acc: 0.4713 - val_loss: 1.2371 - val_acc: 0.5158\n",
      "Epoch 281/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2518 - acc: 0.4640 - val_loss: 1.2368 - val_acc: 0.5042\n",
      "Epoch 282/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2516 - acc: 0.4642 - val_loss: 1.2368 - val_acc: 0.5025\n",
      "Epoch 283/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2487 - acc: 0.4718 - val_loss: 1.2358 - val_acc: 0.4983\n",
      "Epoch 284/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2502 - acc: 0.4698 - val_loss: 1.2360 - val_acc: 0.4950\n",
      "Epoch 285/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2463 - acc: 0.4657 - val_loss: 1.2341 - val_acc: 0.5067\n",
      "Epoch 286/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2462 - acc: 0.4660 - val_loss: 1.2336 - val_acc: 0.5108\n",
      "Epoch 287/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2457 - acc: 0.4828 - val_loss: 1.2344 - val_acc: 0.4867\n",
      "Epoch 288/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2478 - acc: 0.4630 - val_loss: 1.2328 - val_acc: 0.5025\n",
      "Epoch 289/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2459 - acc: 0.4640 - val_loss: 1.2343 - val_acc: 0.5033\n",
      "Epoch 290/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2490 - acc: 0.4525 - val_loss: 1.2322 - val_acc: 0.5117\n",
      "Epoch 291/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2482 - acc: 0.4720 - val_loss: 1.2328 - val_acc: 0.4792\n",
      "Epoch 292/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2480 - acc: 0.4585 - val_loss: 1.2322 - val_acc: 0.4975\n",
      "Epoch 293/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2443 - acc: 0.4670 - val_loss: 1.2305 - val_acc: 0.4975\n",
      "Epoch 294/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2419 - acc: 0.4788 - val_loss: 1.2301 - val_acc: 0.5150\n",
      "Epoch 295/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2495 - acc: 0.4680 - val_loss: 1.2314 - val_acc: 0.5033\n",
      "Epoch 296/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2447 - acc: 0.4670 - val_loss: 1.2305 - val_acc: 0.5092\n",
      "Epoch 297/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2424 - acc: 0.4698 - val_loss: 1.2287 - val_acc: 0.5008\n",
      "Epoch 298/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2421 - acc: 0.4708 - val_loss: 1.2321 - val_acc: 0.5017\n",
      "Epoch 299/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2463 - acc: 0.4637 - val_loss: 1.2292 - val_acc: 0.5083\n",
      "Epoch 300/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2429 - acc: 0.4748 - val_loss: 1.2313 - val_acc: 0.5142\n",
      "Epoch 301/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2425 - acc: 0.4715 - val_loss: 1.2275 - val_acc: 0.5033\n",
      "Epoch 302/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2398 - acc: 0.4667 - val_loss: 1.2278 - val_acc: 0.5133\n",
      "Epoch 303/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2423 - acc: 0.4778 - val_loss: 1.2260 - val_acc: 0.4975\n",
      "Epoch 304/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2410 - acc: 0.4688 - val_loss: 1.2252 - val_acc: 0.5133\n",
      "Epoch 305/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2369 - acc: 0.4788 - val_loss: 1.2249 - val_acc: 0.5150\n",
      "Epoch 306/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2376 - acc: 0.4733 - val_loss: 1.2256 - val_acc: 0.5125\n",
      "Epoch 307/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2393 - acc: 0.4662 - val_loss: 1.2267 - val_acc: 0.5092\n",
      "Epoch 308/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2383 - acc: 0.4690 - val_loss: 1.2247 - val_acc: 0.4975\n",
      "Epoch 309/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2428 - acc: 0.4642 - val_loss: 1.2272 - val_acc: 0.5208\n",
      "Epoch 310/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2336 - acc: 0.4723 - val_loss: 1.2222 - val_acc: 0.5133\n",
      "Epoch 311/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2420 - acc: 0.4715 - val_loss: 1.2228 - val_acc: 0.5192\n",
      "Epoch 312/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2359 - acc: 0.4793 - val_loss: 1.2229 - val_acc: 0.5150\n",
      "Epoch 313/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2335 - acc: 0.4815 - val_loss: 1.2206 - val_acc: 0.5108\n",
      "Epoch 314/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2377 - acc: 0.4753 - val_loss: 1.2208 - val_acc: 0.5167\n",
      "Epoch 315/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2361 - acc: 0.4823 - val_loss: 1.2214 - val_acc: 0.5050\n",
      "Epoch 316/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2370 - acc: 0.4760 - val_loss: 1.2217 - val_acc: 0.5050\n",
      "Epoch 317/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2323 - acc: 0.4825 - val_loss: 1.2193 - val_acc: 0.5167\n",
      "Epoch 318/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2356 - acc: 0.4730 - val_loss: 1.2198 - val_acc: 0.5167\n",
      "Epoch 319/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2373 - acc: 0.4730 - val_loss: 1.2202 - val_acc: 0.4958\n",
      "Epoch 320/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2308 - acc: 0.4825 - val_loss: 1.2176 - val_acc: 0.5150\n",
      "Epoch 321/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2315 - acc: 0.4753 - val_loss: 1.2182 - val_acc: 0.5183\n",
      "Epoch 322/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2329 - acc: 0.4725 - val_loss: 1.2173 - val_acc: 0.5167\n",
      "Epoch 323/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2341 - acc: 0.4733 - val_loss: 1.2187 - val_acc: 0.5183\n",
      "Epoch 324/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2323 - acc: 0.4730 - val_loss: 1.2175 - val_acc: 0.5000\n",
      "Epoch 325/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2285 - acc: 0.4763 - val_loss: 1.2171 - val_acc: 0.5008\n",
      "Epoch 326/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2308 - acc: 0.4790 - val_loss: 1.2162 - val_acc: 0.5175\n",
      "Epoch 327/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2334 - acc: 0.4768 - val_loss: 1.2158 - val_acc: 0.4925\n",
      "Epoch 328/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2301 - acc: 0.4765 - val_loss: 1.2161 - val_acc: 0.5242\n",
      "Epoch 329/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2298 - acc: 0.4672 - val_loss: 1.2136 - val_acc: 0.5092\n",
      "Epoch 330/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2332 - acc: 0.4748 - val_loss: 1.2142 - val_acc: 0.5125\n",
      "Epoch 331/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2306 - acc: 0.4773 - val_loss: 1.2137 - val_acc: 0.5275\n",
      "Epoch 332/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2303 - acc: 0.4715 - val_loss: 1.2126 - val_acc: 0.5025\n",
      "Epoch 333/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2301 - acc: 0.4805 - val_loss: 1.2138 - val_acc: 0.5125\n",
      "Epoch 334/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2288 - acc: 0.4723 - val_loss: 1.2121 - val_acc: 0.5200\n",
      "Epoch 335/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2260 - acc: 0.4780 - val_loss: 1.2123 - val_acc: 0.5208\n",
      "Epoch 336/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2275 - acc: 0.4720 - val_loss: 1.2107 - val_acc: 0.5300\n",
      "Epoch 337/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2299 - acc: 0.4635 - val_loss: 1.2148 - val_acc: 0.5217\n",
      "Epoch 338/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2229 - acc: 0.4905 - val_loss: 1.2101 - val_acc: 0.5075\n",
      "Epoch 339/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2287 - acc: 0.4675 - val_loss: 1.2103 - val_acc: 0.5175\n",
      "Epoch 340/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2264 - acc: 0.4820 - val_loss: 1.2096 - val_acc: 0.5258\n",
      "Epoch 341/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2302 - acc: 0.4775 - val_loss: 1.2107 - val_acc: 0.5217\n",
      "Epoch 342/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2240 - acc: 0.4840 - val_loss: 1.2081 - val_acc: 0.5200\n",
      "Epoch 343/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2218 - acc: 0.4823 - val_loss: 1.2080 - val_acc: 0.5100\n",
      "Epoch 344/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2236 - acc: 0.4783 - val_loss: 1.2078 - val_acc: 0.5117\n",
      "Epoch 345/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2260 - acc: 0.4815 - val_loss: 1.2093 - val_acc: 0.5275\n",
      "Epoch 346/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2271 - acc: 0.4818 - val_loss: 1.2107 - val_acc: 0.5200\n",
      "Epoch 347/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2199 - acc: 0.4877 - val_loss: 1.2076 - val_acc: 0.5050\n",
      "Epoch 348/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2224 - acc: 0.4778 - val_loss: 1.2052 - val_acc: 0.5292\n",
      "Epoch 349/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2228 - acc: 0.4858 - val_loss: 1.2053 - val_acc: 0.5075\n",
      "Epoch 350/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2222 - acc: 0.4750 - val_loss: 1.2046 - val_acc: 0.5242\n",
      "Epoch 351/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2203 - acc: 0.4788 - val_loss: 1.2048 - val_acc: 0.5067\n",
      "Epoch 352/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2206 - acc: 0.4765 - val_loss: 1.2056 - val_acc: 0.5200\n",
      "Epoch 353/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2152 - acc: 0.4885 - val_loss: 1.2027 - val_acc: 0.5225\n",
      "Epoch 354/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2191 - acc: 0.4840 - val_loss: 1.2020 - val_acc: 0.5050\n",
      "Epoch 355/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2212 - acc: 0.4753 - val_loss: 1.2016 - val_acc: 0.5208\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2175 - acc: 0.4818 - val_loss: 1.2022 - val_acc: 0.5192\n",
      "Epoch 357/500\n",
      "4000/4000 [==============================] - 0s 52us/step - loss: 1.2154 - acc: 0.4813 - val_loss: 1.2013 - val_acc: 0.5108\n",
      "Epoch 358/500\n",
      "4000/4000 [==============================] - 0s 45us/step - loss: 1.2166 - acc: 0.4805 - val_loss: 1.2015 - val_acc: 0.5142\n",
      "Epoch 359/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2205 - acc: 0.4740 - val_loss: 1.2001 - val_acc: 0.5117\n",
      "Epoch 360/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2175 - acc: 0.4858 - val_loss: 1.1995 - val_acc: 0.5308\n",
      "Epoch 361/500\n",
      "4000/4000 [==============================] - 0s 45us/step - loss: 1.2144 - acc: 0.4910 - val_loss: 1.1993 - val_acc: 0.5233\n",
      "Epoch 362/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2178 - acc: 0.4875 - val_loss: 1.1988 - val_acc: 0.5300\n",
      "Epoch 363/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2168 - acc: 0.4875 - val_loss: 1.2018 - val_acc: 0.5242\n",
      "Epoch 364/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2151 - acc: 0.4915 - val_loss: 1.1992 - val_acc: 0.5358\n",
      "Epoch 365/500\n",
      "4000/4000 [==============================] - 0s 44us/step - loss: 1.2159 - acc: 0.4773 - val_loss: 1.1987 - val_acc: 0.5367\n",
      "Epoch 366/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2160 - acc: 0.4825 - val_loss: 1.1975 - val_acc: 0.5333\n",
      "Epoch 367/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2169 - acc: 0.4788 - val_loss: 1.1972 - val_acc: 0.5258\n",
      "Epoch 368/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2138 - acc: 0.4805 - val_loss: 1.1972 - val_acc: 0.5242\n",
      "Epoch 369/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2110 - acc: 0.4885 - val_loss: 1.1971 - val_acc: 0.5092\n",
      "Epoch 370/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2135 - acc: 0.4913 - val_loss: 1.1953 - val_acc: 0.5308\n",
      "Epoch 371/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2129 - acc: 0.4795 - val_loss: 1.1954 - val_acc: 0.5175\n",
      "Epoch 372/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2153 - acc: 0.4858 - val_loss: 1.1959 - val_acc: 0.5242\n",
      "Epoch 373/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2113 - acc: 0.4958 - val_loss: 1.1980 - val_acc: 0.5200\n",
      "Epoch 374/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2141 - acc: 0.4883 - val_loss: 1.1961 - val_acc: 0.5250\n",
      "Epoch 375/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2136 - acc: 0.4940 - val_loss: 1.1939 - val_acc: 0.5250\n",
      "Epoch 376/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2146 - acc: 0.4862 - val_loss: 1.1943 - val_acc: 0.5267\n",
      "Epoch 377/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2098 - acc: 0.4895 - val_loss: 1.1936 - val_acc: 0.5025\n",
      "Epoch 378/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2108 - acc: 0.4805 - val_loss: 1.1924 - val_acc: 0.5292\n",
      "Epoch 379/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2057 - acc: 0.4993 - val_loss: 1.1917 - val_acc: 0.5325\n",
      "Epoch 380/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2078 - acc: 0.4853 - val_loss: 1.1923 - val_acc: 0.5108\n",
      "Epoch 381/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2091 - acc: 0.4858 - val_loss: 1.1941 - val_acc: 0.5067\n",
      "Epoch 382/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2089 - acc: 0.4865 - val_loss: 1.1897 - val_acc: 0.5250\n",
      "Epoch 383/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2087 - acc: 0.4945 - val_loss: 1.1921 - val_acc: 0.5133\n",
      "Epoch 384/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2100 - acc: 0.4870 - val_loss: 1.1894 - val_acc: 0.5308\n",
      "Epoch 385/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2087 - acc: 0.4833 - val_loss: 1.1894 - val_acc: 0.5167\n",
      "Epoch 386/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2077 - acc: 0.4818 - val_loss: 1.1920 - val_acc: 0.5283\n",
      "Epoch 387/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2057 - acc: 0.4928 - val_loss: 1.1883 - val_acc: 0.5167\n",
      "Epoch 388/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2072 - acc: 0.4825 - val_loss: 1.1902 - val_acc: 0.5283\n",
      "Epoch 389/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2073 - acc: 0.4805 - val_loss: 1.1900 - val_acc: 0.5067\n",
      "Epoch 390/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2107 - acc: 0.4883 - val_loss: 1.1877 - val_acc: 0.5208\n",
      "Epoch 391/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2076 - acc: 0.4877 - val_loss: 1.1894 - val_acc: 0.5342\n",
      "Epoch 392/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2036 - acc: 0.4973 - val_loss: 1.1865 - val_acc: 0.5250\n",
      "Epoch 393/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2080 - acc: 0.4833 - val_loss: 1.1865 - val_acc: 0.5367\n",
      "Epoch 394/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2074 - acc: 0.4877 - val_loss: 1.1861 - val_acc: 0.5283\n",
      "Epoch 395/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.2031 - acc: 0.4910 - val_loss: 1.1873 - val_acc: 0.5350\n",
      "Epoch 396/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2053 - acc: 0.4905 - val_loss: 1.1847 - val_acc: 0.5242\n",
      "Epoch 397/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2023 - acc: 0.4895 - val_loss: 1.1849 - val_acc: 0.5233\n",
      "Epoch 398/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2022 - acc: 0.4910 - val_loss: 1.1851 - val_acc: 0.5275\n",
      "Epoch 399/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2026 - acc: 0.4943 - val_loss: 1.1833 - val_acc: 0.5350\n",
      "Epoch 400/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2023 - acc: 0.4888 - val_loss: 1.1834 - val_acc: 0.5333\n",
      "Epoch 401/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2028 - acc: 0.4907 - val_loss: 1.1845 - val_acc: 0.5292\n",
      "Epoch 402/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.2032 - acc: 0.4873 - val_loss: 1.1823 - val_acc: 0.5233\n",
      "Epoch 403/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2029 - acc: 0.4965 - val_loss: 1.1818 - val_acc: 0.5258\n",
      "Epoch 404/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2019 - acc: 0.4900 - val_loss: 1.1814 - val_acc: 0.5325\n",
      "Epoch 405/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2062 - acc: 0.4885 - val_loss: 1.1814 - val_acc: 0.5483\n",
      "Epoch 406/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.2033 - acc: 0.4850 - val_loss: 1.1824 - val_acc: 0.5225\n",
      "Epoch 407/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.2006 - acc: 0.4862 - val_loss: 1.1812 - val_acc: 0.5233\n",
      "Epoch 408/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.1989 - acc: 0.4920 - val_loss: 1.1819 - val_acc: 0.5267\n",
      "Epoch 409/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.1980 - acc: 0.4982 - val_loss: 1.1848 - val_acc: 0.5358\n",
      "Epoch 410/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1991 - acc: 0.4990 - val_loss: 1.1793 - val_acc: 0.5308\n",
      "Epoch 411/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1961 - acc: 0.5032 - val_loss: 1.1801 - val_acc: 0.5333\n",
      "Epoch 412/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1991 - acc: 0.4933 - val_loss: 1.1778 - val_acc: 0.5383\n",
      "Epoch 413/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1996 - acc: 0.4915 - val_loss: 1.1816 - val_acc: 0.5242\n",
      "Epoch 414/500\n",
      "4000/4000 [==============================] - 0s 44us/step - loss: 1.1979 - acc: 0.4925 - val_loss: 1.1774 - val_acc: 0.5342\n",
      "Epoch 415/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1988 - acc: 0.4975 - val_loss: 1.1789 - val_acc: 0.5300\n",
      "Epoch 416/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1937 - acc: 0.5002 - val_loss: 1.1768 - val_acc: 0.5250\n",
      "Epoch 417/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1964 - acc: 0.4862 - val_loss: 1.1759 - val_acc: 0.5450\n",
      "Epoch 418/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1981 - acc: 0.4885 - val_loss: 1.1766 - val_acc: 0.5375\n",
      "Epoch 419/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1949 - acc: 0.5002 - val_loss: 1.1762 - val_acc: 0.5325\n",
      "Epoch 420/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1966 - acc: 0.4920 - val_loss: 1.1772 - val_acc: 0.5308\n",
      "Epoch 421/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.1955 - acc: 0.4933 - val_loss: 1.1758 - val_acc: 0.5442\n",
      "Epoch 422/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.1928 - acc: 0.5025 - val_loss: 1.1754 - val_acc: 0.5283\n",
      "Epoch 423/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1914 - acc: 0.5010 - val_loss: 1.1745 - val_acc: 0.5192\n",
      "Epoch 424/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1916 - acc: 0.4930 - val_loss: 1.1749 - val_acc: 0.5350\n",
      "Epoch 425/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1929 - acc: 0.4975 - val_loss: 1.1737 - val_acc: 0.5442\n",
      "Epoch 426/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1945 - acc: 0.4933 - val_loss: 1.1734 - val_acc: 0.5275\n",
      "Epoch 427/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1932 - acc: 0.4952 - val_loss: 1.1734 - val_acc: 0.5167\n",
      "Epoch 428/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1922 - acc: 0.5015 - val_loss: 1.1715 - val_acc: 0.5292\n",
      "Epoch 429/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.1929 - acc: 0.4990 - val_loss: 1.1710 - val_acc: 0.5342\n",
      "Epoch 430/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.1922 - acc: 0.5007 - val_loss: 1.1707 - val_acc: 0.5342\n",
      "Epoch 431/500\n",
      "4000/4000 [==============================] - 0s 49us/step - loss: 1.1919 - acc: 0.5002 - val_loss: 1.1714 - val_acc: 0.5542\n",
      "Epoch 432/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1921 - acc: 0.4943 - val_loss: 1.1741 - val_acc: 0.5208\n",
      "Epoch 433/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1901 - acc: 0.4985 - val_loss: 1.1723 - val_acc: 0.5217\n",
      "Epoch 434/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1899 - acc: 0.4995 - val_loss: 1.1691 - val_acc: 0.5433\n",
      "Epoch 435/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.1880 - acc: 0.5000 - val_loss: 1.1689 - val_acc: 0.5458\n",
      "Epoch 436/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1862 - acc: 0.5067 - val_loss: 1.1689 - val_acc: 0.5458\n",
      "Epoch 437/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1891 - acc: 0.4933 - val_loss: 1.1720 - val_acc: 0.5167\n",
      "Epoch 438/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1916 - acc: 0.4928 - val_loss: 1.1683 - val_acc: 0.5217\n",
      "Epoch 439/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1868 - acc: 0.5102 - val_loss: 1.1728 - val_acc: 0.5342\n",
      "Epoch 440/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1915 - acc: 0.4963 - val_loss: 1.1675 - val_acc: 0.5367\n",
      "Epoch 441/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1863 - acc: 0.4963 - val_loss: 1.1666 - val_acc: 0.5383\n",
      "Epoch 442/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1847 - acc: 0.4985 - val_loss: 1.1694 - val_acc: 0.5492\n",
      "Epoch 443/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1881 - acc: 0.4925 - val_loss: 1.1681 - val_acc: 0.5375\n",
      "Epoch 444/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1863 - acc: 0.4985 - val_loss: 1.1674 - val_acc: 0.5208\n",
      "Epoch 445/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.1828 - acc: 0.5010 - val_loss: 1.1655 - val_acc: 0.5375\n",
      "Epoch 446/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1820 - acc: 0.5092 - val_loss: 1.1639 - val_acc: 0.5375\n",
      "Epoch 447/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1816 - acc: 0.5007 - val_loss: 1.1637 - val_acc: 0.5358\n",
      "Epoch 448/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1863 - acc: 0.4978 - val_loss: 1.1644 - val_acc: 0.5275\n",
      "Epoch 449/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1810 - acc: 0.5040 - val_loss: 1.1677 - val_acc: 0.5367\n",
      "Epoch 450/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1843 - acc: 0.4965 - val_loss: 1.1629 - val_acc: 0.5525\n",
      "Epoch 451/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1855 - acc: 0.4960 - val_loss: 1.1636 - val_acc: 0.5433\n",
      "Epoch 452/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.1816 - acc: 0.5108 - val_loss: 1.1659 - val_acc: 0.5392\n",
      "Epoch 453/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1888 - acc: 0.4877 - val_loss: 1.1625 - val_acc: 0.5442\n",
      "Epoch 454/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1841 - acc: 0.4978 - val_loss: 1.1613 - val_acc: 0.5458\n",
      "Epoch 455/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1868 - acc: 0.4937 - val_loss: 1.1645 - val_acc: 0.5192\n",
      "Epoch 456/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1799 - acc: 0.5055 - val_loss: 1.1611 - val_acc: 0.5425\n",
      "Epoch 457/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1788 - acc: 0.5037 - val_loss: 1.1603 - val_acc: 0.5425\n",
      "Epoch 458/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1873 - acc: 0.5007 - val_loss: 1.1616 - val_acc: 0.5392\n",
      "Epoch 459/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1830 - acc: 0.5045 - val_loss: 1.1613 - val_acc: 0.5208\n",
      "Epoch 460/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1802 - acc: 0.5028 - val_loss: 1.1612 - val_acc: 0.5317\n",
      "Epoch 461/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1869 - acc: 0.4985 - val_loss: 1.1610 - val_acc: 0.5658\n",
      "Epoch 462/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1844 - acc: 0.5035 - val_loss: 1.1589 - val_acc: 0.5300\n",
      "Epoch 463/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1785 - acc: 0.5018 - val_loss: 1.1580 - val_acc: 0.5275\n",
      "Epoch 464/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1851 - acc: 0.5012 - val_loss: 1.1589 - val_acc: 0.5300\n",
      "Epoch 465/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1791 - acc: 0.5012 - val_loss: 1.1574 - val_acc: 0.5533\n",
      "Epoch 466/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1771 - acc: 0.5065 - val_loss: 1.1598 - val_acc: 0.5400\n",
      "Epoch 467/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1803 - acc: 0.4973 - val_loss: 1.1607 - val_acc: 0.5358\n",
      "Epoch 468/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1768 - acc: 0.5028 - val_loss: 1.1598 - val_acc: 0.5508\n",
      "Epoch 469/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1809 - acc: 0.5085 - val_loss: 1.1555 - val_acc: 0.5500\n",
      "Epoch 470/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1737 - acc: 0.5130 - val_loss: 1.1550 - val_acc: 0.5458\n",
      "Epoch 471/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1796 - acc: 0.5037 - val_loss: 1.1633 - val_acc: 0.5442\n",
      "Epoch 472/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1787 - acc: 0.5010 - val_loss: 1.1593 - val_acc: 0.5333\n",
      "Epoch 473/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1789 - acc: 0.4965 - val_loss: 1.1548 - val_acc: 0.5525\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1790 - acc: 0.5108 - val_loss: 1.1563 - val_acc: 0.5475\n",
      "Epoch 475/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1770 - acc: 0.5127 - val_loss: 1.1562 - val_acc: 0.5400\n",
      "Epoch 476/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1738 - acc: 0.5085 - val_loss: 1.1537 - val_acc: 0.5408\n",
      "Epoch 477/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1757 - acc: 0.5007 - val_loss: 1.1534 - val_acc: 0.5567\n",
      "Epoch 478/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1758 - acc: 0.5070 - val_loss: 1.1550 - val_acc: 0.5317\n",
      "Epoch 479/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1788 - acc: 0.5040 - val_loss: 1.1533 - val_acc: 0.5258\n",
      "Epoch 480/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.1742 - acc: 0.5100 - val_loss: 1.1521 - val_acc: 0.5433\n",
      "Epoch 481/500\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.1706 - acc: 0.5072 - val_loss: 1.1524 - val_acc: 0.5433\n",
      "Epoch 482/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1742 - acc: 0.5078 - val_loss: 1.1514 - val_acc: 0.5433\n",
      "Epoch 483/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1720 - acc: 0.5138 - val_loss: 1.1525 - val_acc: 0.5433\n",
      "Epoch 484/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1723 - acc: 0.5045 - val_loss: 1.1507 - val_acc: 0.5358\n",
      "Epoch 485/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1710 - acc: 0.5072 - val_loss: 1.1512 - val_acc: 0.5333\n",
      "Epoch 486/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.1738 - acc: 0.5050 - val_loss: 1.1532 - val_acc: 0.5517\n",
      "Epoch 487/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1722 - acc: 0.5012 - val_loss: 1.1499 - val_acc: 0.5483\n",
      "Epoch 488/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1750 - acc: 0.5045 - val_loss: 1.1494 - val_acc: 0.5567\n",
      "Epoch 489/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1724 - acc: 0.5132 - val_loss: 1.1499 - val_acc: 0.5467\n",
      "Epoch 490/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1724 - acc: 0.5067 - val_loss: 1.1526 - val_acc: 0.5275\n",
      "Epoch 491/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1690 - acc: 0.5055 - val_loss: 1.1493 - val_acc: 0.5383\n",
      "Epoch 492/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1685 - acc: 0.5055 - val_loss: 1.1545 - val_acc: 0.5400\n",
      "Epoch 493/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1745 - acc: 0.5035 - val_loss: 1.1488 - val_acc: 0.5533\n",
      "Epoch 494/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1723 - acc: 0.5080 - val_loss: 1.1485 - val_acc: 0.5325\n",
      "Epoch 495/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1721 - acc: 0.4997 - val_loss: 1.1467 - val_acc: 0.5542\n",
      "Epoch 496/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.1726 - acc: 0.5085 - val_loss: 1.1487 - val_acc: 0.5425\n",
      "Epoch 497/500\n",
      "4000/4000 [==============================] - 0s 40us/step - loss: 1.1710 - acc: 0.5132 - val_loss: 1.1480 - val_acc: 0.5375\n",
      "Epoch 498/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1701 - acc: 0.5140 - val_loss: 1.1463 - val_acc: 0.5417\n",
      "Epoch 499/500\n",
      "4000/4000 [==============================] - 0s 42us/step - loss: 1.1694 - acc: 0.5072 - val_loss: 1.1479 - val_acc: 0.5467\n",
      "Epoch 500/500\n",
      "4000/4000 [==============================] - 0s 41us/step - loss: 1.1687 - acc: 0.5060 - val_loss: 1.1455 - val_acc: 0.5600\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "history = model.fit(\n",
    "    train_data, \n",
    "    train_labels,\n",
    "    epochs=epochs,  \n",
    "    batch_size=batch_size, \n",
    "    validation_data=(validation_data, validation_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# h5py \n",
    "model.save_weights('VGG/ResNet50_FE_model_1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_graphics (history):\n",
    "    #Mostramos otro tipo de grafico\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc)+ 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    #plt.tittle('Trainning and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    #plt.tittle('Trainning and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_evaluate_model(model, history):\n",
    "    #Evaluate model\n",
    "    (loss, acc) = model.evaluate(\n",
    "        test_features, test_labels, \n",
    "        batch_size=batch_size, \n",
    "        verbose=0)\n",
    "\n",
    "    print(\"acc: {0:.2f}% - loss: {1:f}\".format(acc * 100, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 45.83% - loss: 1.199027\n"
     ]
    }
   ],
   "source": [
    "print_evaluate_model(model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1d13617f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc1d12cb390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_graphics (history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
