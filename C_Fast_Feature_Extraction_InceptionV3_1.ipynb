{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Entreno de un ConvNet InceptionV3 preentrenado con Imagenet y\n",
    "entrenando conjunto de datos pequeño\n",
    "Conjunto de datos de 4 clases\n",
    "Utilizaremos un conjunto de datos reducido:\n",
    "- Conjunto de entrenamiento: 1.000 muestras x clase \n",
    "- Conjunto de validación: 300 muestras x clase\n",
    "- Conjunto de test: 300 muestras x clase\n",
    "El conjunto de datos: balanced_dataset\n",
    "contiene tres carpetas, train, validation y test, cada una con 4 clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from os import walk, getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retorna todos los archivos de un directorio dado\n",
    "def ls(ruta):  \n",
    "    return next(walk(ruta))[2]\n",
    "\n",
    "height_image = 229\n",
    "width_image = 229\n",
    "channels_image = 3\n",
    "nb_clases = 4\n",
    "batch_size = 64\n",
    "class_mode = 'categorical'\n",
    "nb_train = 4000        # 1000 x 4 clases\n",
    "nb_validation = 1200   #  300 x 4 clases\n",
    "nb_test = 1200\n",
    "\n",
    "base_dir = 'balanced_dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import InceptionV3\n",
    "\n",
    "conv_base= InceptionV3(weights='imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (width_image, height_image, channels_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 229, 229, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 114, 114, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 114, 114, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 114, 114, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 112, 112, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 112, 112, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 112, 112, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 112, 112, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 112, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 112, 112, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 55, 55, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 55, 55, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 53, 53, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 53, 53, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 53, 53, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 26, 26, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 26, 26, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 26, 26, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 26, 26, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 26, 26, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 26, 26, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 26, 26, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 26, 26, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 26, 26, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 26, 26, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 26, 26, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 26, 26, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 26, 26, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 26, 26, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 26, 26, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 26, 26, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 26, 26, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 26, 26, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 26, 26, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 26, 26, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 26, 26, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 26, 26, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 26, 26, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 26, 26, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 26, 26, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 26, 26, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 26, 26, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 26, 26, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 26, 26, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 26, 26, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 26, 26, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 26, 26, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 26, 26, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 26, 26, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 26, 26, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 26, 26, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 26, 26, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 26, 26, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 26, 26, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 26, 26, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 26, 26, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 26, 26, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 26, 26, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 26, 26, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 26, 26, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 26, 26, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 26, 26, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 26, 26, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 26, 26, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 26, 26, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 26, 26, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 26, 26, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 26, 26, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 26, 26, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 26, 26, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 26, 26, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 26, 26, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 26, 26, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 26, 26, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 26, 26, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 26, 26, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 26, 26, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 26, 26, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 26, 26, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 26, 26, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 26, 26, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 26, 26, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 26, 26, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 26, 26, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 26, 26, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 26, 26, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 26, 26, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 26, 26, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 26, 26, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 26, 26, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 26, 26, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "FEATURE EXTRACTION (Extracción de características)\n",
    "\n",
    "Ahora hay dos formas de proceder:\n",
    "1- Ejecutar la base convolucional sobre el conjunto de datos, registrar la salida en una matriz Numpy en disco, y luego usar esa información como entrada para un clasificador independiente y densamente conectado. Esta solución es rápida y económica computacionalmente, pero no permite utilizar Data Augmentation.\n",
    "La primera parte es la base convolucional de un modelo preentrenado, segundo se entrena la parte convolucional con los nuevos datos de entrenamiento, depués añadimos un nuevo clasificador densamente conectado en la parte superior (final) y volvemos a entrenar. Si el modelo con el que se entrenó el modelo preentrenado es muy difernte del que queremos aplicar, es conveniente no utilizar toda la base convolucional (eliminar las últimas) ya que éstas són cada vez más especificas al conjunto de datos con el que se entrenó.\n",
    "2- Amplicar el modelo que tenemos (conv_base) agregando capas densas en la parte superior y ejecutando todo de punta a punta en los datos de entrada. Esto permite Data Augmentation, porque cada imagen de entrada pasa por la base convolucional. Esta técnica es mucho mas costosa y requiere GPU"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Extracción de características sin Data Augmentation --> CPU\n",
    "\n",
    "Ejecutamos instancias de ImageDataGenerator para extraer imagenes como matrices Numpy y sus etiquetas. Extraeremos características de estas imágenes llamando al método del modelo conv_base\n",
    "\n",
    "- La ultima salida de la capa convolucional es de (1, 1, 2048 )\n",
    "out_x, out_y, conv_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 4 classes.\n",
      "Found 1200 images belonging to 4 classes.\n",
      "Found 1200 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#Extracción de características del modelo Preentrenado y nuestro dataset\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#Tamaño de salida de la última capa convoluciónal del modelo preentrenado\n",
    "#lo vemos en el conv_base.summary()\n",
    "out_x = 5\n",
    "out_y = 5\n",
    "conv_len = 2048\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, out_x, out_x, conv_len))\n",
    "    labels = to_categorical(np.zeros(shape=(sample_count)),nb_clases) #INDICAR NUMERO DE CLASES\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size = (height_image, width_image),\n",
    "        batch_size = batch_size,\n",
    "        #classes = 4,\n",
    "        class_mode = 'categorical')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch) ##Asociamos al modelo preentrenado\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "#Train: 1000 muestras x clase, con 4 clases, 1000 x 4 = 4000\n",
    "train_features, train_labels = extract_features(train_dir, nb_train)\n",
    "#validation 500 muestras x clase con 4 clases, 300 x 4 = 1200\n",
    "validation_features, validation_labels = extract_features(validation_dir, nb_validation) \n",
    "#test 500 muestras x clase con 4 clases, 300 x 4 = 1200\n",
    "test_features, test_labels = extract_features(test_dir, nb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 51200)\n",
      "(1200, 51200)\n",
      "(1200, 51200)\n"
     ]
    }
   ],
   "source": [
    "#Las características extraídas están como muetras en forma (muestra, 4, 4, 512).-->(muestras, out_x, out_y, conv_len)\n",
    "#Debemos aplanarlas (muestras, 8192) para alimentar un clasificador densamente conectado 4x4x512 = 8192 si entrada 150x150\n",
    "#Debemos aplanarlas (muestras, 25088) para alimentar un clasificador densamente conectado 7x7x512 = 25088 si entrada 224x224\n",
    "\n",
    "\n",
    "train_features = np.reshape(train_features, (nb_train, out_x * out_y * conv_len))\n",
    "validation_features = np.reshape(validation_features, (nb_validation, out_x * out_y * conv_len))\n",
    "test_features = np.reshape(test_features, (nb_test, out_x * out_y * conv_len))\n",
    "print(train_features.shape)\n",
    "print(validation_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               13107456  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 13,108,484\n",
      "Trainable params: 13,108,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Definimos un clasificador densamente conectado capacitado con los datos y etiquetas obtenidas antes\n",
    "#Aplicamos capa de abandono Dropout y función de activación \"sigmoid\" al final\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "top_model = models.Sequential()\n",
    "top_model.add(layers.Dense(256, activation = 'relu', input_dim = out_x * out_y * conv_len))\n",
    "top_model.add(layers.Dropout(0.5))\n",
    "top_model.add(layers.Dense(nb_clases, activation = 'sigmoid'))  #INDICAR NUMERO DE CLASES\n",
    "\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1200 samples\n",
      "Epoch 1/80\n",
      "4000/4000 [==============================] - 3s 675us/step - loss: 1.1657 - acc: 0.4860 - val_loss: 0.9254 - val_acc: 0.6225\n",
      "Epoch 2/80\n",
      "4000/4000 [==============================] - 2s 429us/step - loss: 0.9005 - acc: 0.6213 - val_loss: 0.7553 - val_acc: 0.7100\n",
      "Epoch 3/80\n",
      "4000/4000 [==============================] - 2s 425us/step - loss: 0.7690 - acc: 0.6947 - val_loss: 0.7493 - val_acc: 0.7075\n",
      "Epoch 4/80\n",
      "4000/4000 [==============================] - 2s 446us/step - loss: 0.6762 - acc: 0.7182 - val_loss: 0.7082 - val_acc: 0.7267\n",
      "Epoch 5/80\n",
      "4000/4000 [==============================] - 2s 433us/step - loss: 0.6046 - acc: 0.7537 - val_loss: 0.7173 - val_acc: 0.7258\n",
      "Epoch 6/80\n",
      "4000/4000 [==============================] - 2s 453us/step - loss: 0.5599 - acc: 0.7788 - val_loss: 0.7139 - val_acc: 0.7058\n",
      "Epoch 7/80\n",
      "4000/4000 [==============================] - 2s 449us/step - loss: 0.5106 - acc: 0.8025 - val_loss: 0.6233 - val_acc: 0.7617\n",
      "Epoch 8/80\n",
      "4000/4000 [==============================] - 2s 433us/step - loss: 0.4479 - acc: 0.8263 - val_loss: 0.6347 - val_acc: 0.7567\n",
      "Epoch 9/80\n",
      "4000/4000 [==============================] - 2s 430us/step - loss: 0.4121 - acc: 0.8455 - val_loss: 0.7373 - val_acc: 0.7392\n",
      "Epoch 10/80\n",
      "4000/4000 [==============================] - 2s 455us/step - loss: 0.3775 - acc: 0.8528 - val_loss: 0.6924 - val_acc: 0.7408\n",
      "Epoch 11/80\n",
      "4000/4000 [==============================] - 2s 408us/step - loss: 0.3594 - acc: 0.8620 - val_loss: 0.6046 - val_acc: 0.7800\n",
      "Epoch 12/80\n",
      "4000/4000 [==============================] - 2s 452us/step - loss: 0.3126 - acc: 0.8840 - val_loss: 0.5834 - val_acc: 0.7875\n",
      "Epoch 13/80\n",
      "4000/4000 [==============================] - 2s 434us/step - loss: 0.2930 - acc: 0.8925 - val_loss: 0.5897 - val_acc: 0.7800\n",
      "Epoch 14/80\n",
      "4000/4000 [==============================] - 2s 424us/step - loss: 0.2834 - acc: 0.8948 - val_loss: 0.6234 - val_acc: 0.7708\n",
      "Epoch 15/80\n",
      "4000/4000 [==============================] - 2s 453us/step - loss: 0.2524 - acc: 0.9085 - val_loss: 0.6063 - val_acc: 0.7942\n",
      "Epoch 16/80\n",
      "4000/4000 [==============================] - 2s 421us/step - loss: 0.2280 - acc: 0.9193 - val_loss: 0.5751 - val_acc: 0.7942\n",
      "Epoch 17/80\n",
      "4000/4000 [==============================] - 2s 442us/step - loss: 0.2215 - acc: 0.9167 - val_loss: 0.5939 - val_acc: 0.7767\n",
      "Epoch 18/80\n",
      "4000/4000 [==============================] - 2s 438us/step - loss: 0.2032 - acc: 0.9315 - val_loss: 0.9117 - val_acc: 0.7017\n",
      "Epoch 19/80\n",
      "4000/4000 [==============================] - 2s 446us/step - loss: 0.1866 - acc: 0.9340 - val_loss: 0.6732 - val_acc: 0.7600\n",
      "Epoch 20/80\n",
      "4000/4000 [==============================] - 2s 455us/step - loss: 0.1772 - acc: 0.9387 - val_loss: 0.7675 - val_acc: 0.7492\n",
      "Epoch 21/80\n",
      "4000/4000 [==============================] - 2s 419us/step - loss: 0.1683 - acc: 0.9397 - val_loss: 0.6997 - val_acc: 0.7467\n",
      "Epoch 22/80\n",
      "4000/4000 [==============================] - 2s 407us/step - loss: 0.1466 - acc: 0.9543 - val_loss: 0.6986 - val_acc: 0.7742\n",
      "Epoch 23/80\n",
      "4000/4000 [==============================] - 2s 438us/step - loss: 0.1511 - acc: 0.9507 - val_loss: 0.5989 - val_acc: 0.8033\n",
      "Epoch 24/80\n",
      "4000/4000 [==============================] - 2s 447us/step - loss: 0.1301 - acc: 0.9575 - val_loss: 0.5994 - val_acc: 0.7983\n",
      "Epoch 25/80\n",
      "4000/4000 [==============================] - 2s 435us/step - loss: 0.1365 - acc: 0.9570 - val_loss: 0.6154 - val_acc: 0.7917\n",
      "Epoch 26/80\n",
      "4000/4000 [==============================] - 2s 445us/step - loss: 0.1075 - acc: 0.9652 - val_loss: 0.5974 - val_acc: 0.8100\n",
      "Epoch 27/80\n",
      "4000/4000 [==============================] - 2s 452us/step - loss: 0.1066 - acc: 0.9655 - val_loss: 0.6679 - val_acc: 0.7633\n",
      "Epoch 28/80\n",
      "4000/4000 [==============================] - 2s 440us/step - loss: 0.1069 - acc: 0.9647 - val_loss: 0.7120 - val_acc: 0.7700\n",
      "Epoch 29/80\n",
      "4000/4000 [==============================] - 2s 440us/step - loss: 0.0972 - acc: 0.9740 - val_loss: 0.6187 - val_acc: 0.8025\n",
      "Epoch 30/80\n",
      "4000/4000 [==============================] - 2s 437us/step - loss: 0.0885 - acc: 0.9738 - val_loss: 0.6032 - val_acc: 0.7975\n",
      "Epoch 31/80\n",
      "4000/4000 [==============================] - 2s 461us/step - loss: 0.0933 - acc: 0.9725 - val_loss: 0.6542 - val_acc: 0.7917\n",
      "Epoch 32/80\n",
      "4000/4000 [==============================] - 2s 407us/step - loss: 0.0753 - acc: 0.9808 - val_loss: 0.6244 - val_acc: 0.8058\n",
      "Epoch 33/80\n",
      "4000/4000 [==============================] - 2s 425us/step - loss: 0.0785 - acc: 0.9778 - val_loss: 0.7422 - val_acc: 0.7750\n",
      "Epoch 34/80\n",
      "4000/4000 [==============================] - 2s 434us/step - loss: 0.0724 - acc: 0.9810 - val_loss: 0.6906 - val_acc: 0.7850\n",
      "Epoch 35/80\n",
      "4000/4000 [==============================] - 2s 402us/step - loss: 0.0671 - acc: 0.9813 - val_loss: 0.6548 - val_acc: 0.7925\n",
      "Epoch 36/80\n",
      "4000/4000 [==============================] - 2s 414us/step - loss: 0.0608 - acc: 0.9818 - val_loss: 0.6735 - val_acc: 0.7858\n",
      "Epoch 37/80\n",
      "4000/4000 [==============================] - 2s 402us/step - loss: 0.0632 - acc: 0.9828 - val_loss: 0.6856 - val_acc: 0.7958\n",
      "Epoch 38/80\n",
      "4000/4000 [==============================] - 2s 400us/step - loss: 0.0564 - acc: 0.9860 - val_loss: 0.6868 - val_acc: 0.7908\n",
      "Epoch 39/80\n",
      "4000/4000 [==============================] - 2s 437us/step - loss: 0.0538 - acc: 0.9865 - val_loss: 0.7016 - val_acc: 0.7892\n",
      "Epoch 40/80\n",
      "4000/4000 [==============================] - 2s 443us/step - loss: 0.0537 - acc: 0.9860 - val_loss: 0.6871 - val_acc: 0.7917\n",
      "Epoch 41/80\n",
      "4000/4000 [==============================] - 2s 436us/step - loss: 0.0527 - acc: 0.9860 - val_loss: 0.9825 - val_acc: 0.7375\n",
      "Epoch 42/80\n",
      "4000/4000 [==============================] - 2s 460us/step - loss: 0.0496 - acc: 0.9870 - val_loss: 0.6883 - val_acc: 0.7925\n",
      "Epoch 43/80\n",
      "4000/4000 [==============================] - 2s 436us/step - loss: 0.0429 - acc: 0.9910 - val_loss: 0.7248 - val_acc: 0.8000\n",
      "Epoch 44/80\n",
      "4000/4000 [==============================] - 2s 425us/step - loss: 0.0448 - acc: 0.9875 - val_loss: 0.7000 - val_acc: 0.8017\n",
      "Epoch 45/80\n",
      "4000/4000 [==============================] - 2s 427us/step - loss: 0.0411 - acc: 0.9882 - val_loss: 0.9372 - val_acc: 0.7600\n",
      "Epoch 46/80\n",
      "4000/4000 [==============================] - 2s 442us/step - loss: 0.0474 - acc: 0.9878 - val_loss: 0.6933 - val_acc: 0.7917\n",
      "Epoch 47/80\n",
      "4000/4000 [==============================] - 2s 477us/step - loss: 0.0398 - acc: 0.9895 - val_loss: 0.7613 - val_acc: 0.7775\n",
      "Epoch 48/80\n",
      "4000/4000 [==============================] - 2s 433us/step - loss: 0.0371 - acc: 0.9905 - val_loss: 0.9835 - val_acc: 0.7483\n",
      "Epoch 49/80\n",
      "4000/4000 [==============================] - 2s 405us/step - loss: 0.0320 - acc: 0.9920 - val_loss: 0.7764 - val_acc: 0.7942\n",
      "Epoch 50/80\n",
      "4000/4000 [==============================] - 2s 412us/step - loss: 0.0339 - acc: 0.9928 - val_loss: 0.7226 - val_acc: 0.7967\n",
      "Epoch 51/80\n",
      "4000/4000 [==============================] - 2s 423us/step - loss: 0.0327 - acc: 0.9933 - val_loss: 0.7733 - val_acc: 0.7842\n",
      "Epoch 52/80\n",
      "4000/4000 [==============================] - 2s 420us/step - loss: 0.0296 - acc: 0.9935 - val_loss: 0.7695 - val_acc: 0.7900\n",
      "Epoch 53/80\n",
      "4000/4000 [==============================] - 2s 401us/step - loss: 0.0308 - acc: 0.9918 - val_loss: 0.9376 - val_acc: 0.7717\n",
      "Epoch 54/80\n",
      "4000/4000 [==============================] - 2s 419us/step - loss: 0.0247 - acc: 0.9950 - val_loss: 0.9310 - val_acc: 0.7633\n",
      "Epoch 55/80\n",
      "4000/4000 [==============================] - 2s 417us/step - loss: 0.0297 - acc: 0.9922 - val_loss: 0.8565 - val_acc: 0.7817\n",
      "Epoch 56/80\n",
      "4000/4000 [==============================] - 2s 426us/step - loss: 0.0230 - acc: 0.9945 - val_loss: 0.7469 - val_acc: 0.7950\n",
      "Epoch 57/80\n",
      "4000/4000 [==============================] - 2s 409us/step - loss: 0.0278 - acc: 0.9930 - val_loss: 0.8516 - val_acc: 0.7675\n",
      "Epoch 58/80\n",
      "4000/4000 [==============================] - 2s 427us/step - loss: 0.0264 - acc: 0.9938 - val_loss: 0.7874 - val_acc: 0.7975\n",
      "Epoch 59/80\n",
      "4000/4000 [==============================] - 2s 417us/step - loss: 0.0250 - acc: 0.9940 - val_loss: 0.7757 - val_acc: 0.8025\n",
      "Epoch 60/80\n",
      "4000/4000 [==============================] - 2s 435us/step - loss: 0.0227 - acc: 0.9952 - val_loss: 0.7629 - val_acc: 0.8017\n",
      "Epoch 61/80\n",
      "4000/4000 [==============================] - 2s 383us/step - loss: 0.0223 - acc: 0.9960 - val_loss: 0.7936 - val_acc: 0.7875\n",
      "Epoch 62/80\n",
      "4000/4000 [==============================] - 2s 470us/step - loss: 0.0197 - acc: 0.9952 - val_loss: 0.8225 - val_acc: 0.7875\n",
      "Epoch 63/80\n",
      "4000/4000 [==============================] - 2s 439us/step - loss: 0.0185 - acc: 0.9965 - val_loss: 0.8519 - val_acc: 0.7933\n",
      "Epoch 64/80\n",
      "4000/4000 [==============================] - 2s 429us/step - loss: 0.0180 - acc: 0.9968 - val_loss: 0.8364 - val_acc: 0.8000\n",
      "Epoch 65/80\n",
      "4000/4000 [==============================] - 2s 406us/step - loss: 0.0185 - acc: 0.9970 - val_loss: 0.7934 - val_acc: 0.7933\n",
      "Epoch 66/80\n",
      "4000/4000 [==============================] - 2s 386us/step - loss: 0.0195 - acc: 0.9958 - val_loss: 0.7877 - val_acc: 0.7867\n",
      "Epoch 67/80\n",
      "4000/4000 [==============================] - 2s 398us/step - loss: 0.0150 - acc: 0.9968 - val_loss: 0.8381 - val_acc: 0.7817\n",
      "Epoch 68/80\n",
      "4000/4000 [==============================] - 2s 428us/step - loss: 0.0152 - acc: 0.9975 - val_loss: 0.8511 - val_acc: 0.7783\n",
      "Epoch 69/80\n",
      "4000/4000 [==============================] - 2s 381us/step - loss: 0.0158 - acc: 0.9968 - val_loss: 0.8257 - val_acc: 0.7858\n",
      "Epoch 70/80\n",
      "4000/4000 [==============================] - 2s 430us/step - loss: 0.0171 - acc: 0.9958 - val_loss: 0.8112 - val_acc: 0.8000\n",
      "Epoch 71/80\n",
      "4000/4000 [==============================] - 2s 429us/step - loss: 0.0150 - acc: 0.9968 - val_loss: 0.8596 - val_acc: 0.7942\n",
      "Epoch 72/80\n",
      "4000/4000 [==============================] - 2s 444us/step - loss: 0.0148 - acc: 0.9963 - val_loss: 0.8373 - val_acc: 0.7883\n",
      "Epoch 73/80\n",
      "4000/4000 [==============================] - 2s 403us/step - loss: 0.0142 - acc: 0.9970 - val_loss: 0.8899 - val_acc: 0.7792\n",
      "Epoch 74/80\n",
      "4000/4000 [==============================] - 2s 433us/step - loss: 0.0126 - acc: 0.9978 - val_loss: 0.8109 - val_acc: 0.7883\n",
      "Epoch 75/80\n",
      "4000/4000 [==============================] - 2s 445us/step - loss: 0.0127 - acc: 0.9980 - val_loss: 0.8601 - val_acc: 0.7867\n",
      "Epoch 76/80\n",
      "4000/4000 [==============================] - 2s 407us/step - loss: 0.0134 - acc: 0.9975 - val_loss: 0.8796 - val_acc: 0.7858\n",
      "Epoch 77/80\n",
      "4000/4000 [==============================] - 2s 411us/step - loss: 0.0132 - acc: 0.9972 - val_loss: 0.8463 - val_acc: 0.7892\n",
      "Epoch 78/80\n",
      "4000/4000 [==============================] - 2s 414us/step - loss: 0.0157 - acc: 0.9955 - val_loss: 0.8522 - val_acc: 0.7950\n",
      "Epoch 79/80\n",
      "4000/4000 [==============================] - 2s 434us/step - loss: 0.0135 - acc: 0.9965 - val_loss: 0.8246 - val_acc: 0.7983\n",
      "Epoch 80/80\n",
      "4000/4000 [==============================] - 2s 430us/step - loss: 0.0118 - acc: 0.9972 - val_loss: 0.8876 - val_acc: 0.8033\n"
     ]
    }
   ],
   "source": [
    "#Para la compilación usaremos el optimizador RMSprop ya que termina la red con una sola\n",
    "#unidad sigmoidea, cómo función de pérdida se utiliza la entropia cruzada binaria\n",
    "\n",
    "top_model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = optimizers.RMSprop(lr=2e-5), \n",
    "              metrics = ['acc'])\n",
    "\n",
    "epochs = 80\n",
    "\n",
    "history = top_model.fit(\n",
    "    train_features,\n",
    "    train_labels,  \n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs, \n",
    "    verbose = 1, \n",
    "    validation_data = (validation_features, validation_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Guardamos el modelo\n",
    "top_model.save('Fast_Extraction_InceptionV3_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3e02bbbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff3e01c54a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Graficamos la Exactitud y la pérdida del modelo \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+ 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "#plt.tittle('Trainning and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "#plt.tittle('Trainning and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 1s 469us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0613888041178385, 0.74]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.evaluate(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
