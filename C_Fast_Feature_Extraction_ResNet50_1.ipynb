{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Entreno de un ConvNet ResNet50 preentrenado con Imagenet y\n",
    "entrenando conjunto de datos pequeño\n",
    "Conjunto de datos de 4 clases\n",
    "Utilizaremos un conjunto de datos reducido:\n",
    "- Conjunto de entrenamiento: 1.000 muestras x clase \n",
    "- Conjunto de validación: 300 muestras x clase\n",
    "- Conjunto de test: 300 muestras x clase\n",
    "El conjunto de datos: balanced_dataset\n",
    "contiene tres carpetas, train, validation y test, cada una con 4 clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from os import walk, getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retorna todos los archivos de un directorio dado\n",
    "def ls(ruta):  \n",
    "    return next(walk(ruta))[2]\n",
    "\n",
    "height_image = 224\n",
    "width_image = 224\n",
    "channels_image = 3\n",
    "nb_clases = 4\n",
    "batch_size = 64\n",
    "class_mode = 'categorical'\n",
    "nb_train = 4000        # 1000 x 4 clases\n",
    "nb_validation = 1200   #  300 x 4 clases\n",
    "nb_test = 1200\n",
    "\n",
    "base_dir = 'balanced_dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import ResNet50\n",
    "\n",
    "conv_base= ResNet50(weights='imagenet', \n",
    "                 include_top = False, \n",
    "                 input_shape = (width_image, height_image, channels_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "FEATURE EXTRACTION (Extracción de características)\n",
    "\n",
    "Ahora hay dos formas de proceder:\n",
    "1- Ejecutar la base convolucional sobre el conjunto de datos, registrar la salida en una matriz Numpy en disco, y luego usar esa información como entrada para un clasificador independiente y densamente conectado. Esta solución es rápida y económica computacionalmente, pero no permite utilizar Data Augmentation.\n",
    "La primera parte es la base convolucional de un modelo preentrenado, segundo se entrena la parte convolucional con los nuevos datos de entrenamiento, depués añadimos un nuevo clasificador densamente conectado en la parte superior (final) y volvemos a entrenar. Si el modelo con el que se entrenó el modelo preentrenado es muy difernte del que queremos aplicar, es conveniente no utilizar toda la base convolucional (eliminar las últimas) ya que éstas són cada vez más especificas al conjunto de datos con el que se entrenó.\n",
    "2- Amplicar el modelo que tenemos (conv_base) agregando capas densas en la parte superior y ejecutando todo de punta a punta en los datos de entrada. Esto permite Data Augmentation, porque cada imagen de entrada pasa por la base convolucional. Esta técnica es mucho mas costosa y requiere GPU"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Extracción de características sin Data Augmentation --> CPU\n",
    "\n",
    "Ejecutamos instancias de ImageDataGenerator para extraer imagenes como matrices Numpy y sus etiquetas. Extraeremos características de estas imágenes llamando al método del modelo conv_base\n",
    "\n",
    "- La ultima salida de la capa convolucional es de (1, 1, 2048 )\n",
    "out_x, out_y, conv_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 4 classes.\n",
      "Found 1200 images belonging to 4 classes.\n",
      "Found 1200 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#Extracción de características del modelo Preentrenado y nuestro dataset\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#Tamaño de salida de la última capa convoluciónal del modelo preentrenado\n",
    "#lo vemos en el conv_base.summary()\n",
    "out_x = 1\n",
    "out_y = 1\n",
    "conv_len = 2048\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, out_x, out_x, conv_len))\n",
    "    labels = to_categorical(np.zeros(shape=(sample_count)),nb_clases) #INDICAR NUMERO DE CLASES\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size = (height_image, width_image),\n",
    "        batch_size = batch_size,\n",
    "        #classes = 4,\n",
    "        class_mode = 'categorical')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch) ##Asociamos al modelo preentrenado\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "#Train: 1000 muestras x clase, con 4 clases, 1000 x 4 = 4000\n",
    "train_features, train_labels = extract_features(train_dir, nb_train)\n",
    "#validation 500 muestras x clase con 4 clases, 300 x 4 = 1200\n",
    "validation_features, validation_labels = extract_features(validation_dir, nb_validation) \n",
    "#test 500 muestras x clase con 4 clases, 300 x 4 = 1200\n",
    "test_features, test_labels = extract_features(test_dir, nb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 2048)\n",
      "(1200, 2048)\n",
      "(1200, 2048)\n"
     ]
    }
   ],
   "source": [
    "#Las características extraídas están como muetras en forma (muestra, 4, 4, 512).-->(muestras, out_x, out_y, conv_len)\n",
    "#Debemos aplanarlas (muestras, 8192) para alimentar un clasificador densamente conectado 4x4x512 = 8192 si entrada 150x150\n",
    "#Debemos aplanarlas (muestras, 25088) para alimentar un clasificador densamente conectado 7x7x512 = 25088 si entrada 224x224\n",
    "\n",
    "\n",
    "train_features = np.reshape(train_features, (nb_train, out_x * out_y * conv_len))\n",
    "validation_features = np.reshape(validation_features, (nb_validation, out_x * out_y * conv_len))\n",
    "test_features = np.reshape(test_features, (nb_test, out_x * out_y * conv_len))\n",
    "print(train_features.shape)\n",
    "print(validation_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 525,572\n",
      "Trainable params: 525,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Definimos un clasificador densamente conectado capacitado con los datos y etiquetas obtenidas antes\n",
    "#Aplicamos capa de abandono Dropout y función de activación \"sigmoid\" al final\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "top_model = models.Sequential()\n",
    "top_model.add(layers.Dense(256, activation = 'relu', input_dim = out_x * out_y * conv_len))\n",
    "top_model.add(layers.Dropout(0.5))\n",
    "top_model.add(layers.Dense(nb_clases, activation = 'sigmoid'))  #INDICAR NUMERO DE CLASES\n",
    "\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1200 samples\n",
      "Epoch 1/80\n",
      "4000/4000 [==============================] - 1s 173us/step - loss: 1.4111 - acc: 0.2575 - val_loss: 1.3866 - val_acc: 0.2500\n",
      "Epoch 2/80\n",
      "4000/4000 [==============================] - 0s 81us/step - loss: 1.4057 - acc: 0.2377 - val_loss: 1.3861 - val_acc: 0.2508\n",
      "Epoch 3/80\n",
      "4000/4000 [==============================] - 0s 81us/step - loss: 1.3975 - acc: 0.2445 - val_loss: 1.3860 - val_acc: 0.2500\n",
      "Epoch 4/80\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 1.3920 - acc: 0.2587 - val_loss: 1.3860 - val_acc: 0.2517\n",
      "Epoch 5/80\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 1.3904 - acc: 0.2593 - val_loss: 1.3859 - val_acc: 0.2583\n",
      "Epoch 6/80\n",
      "4000/4000 [==============================] - 0s 48us/step - loss: 1.3926 - acc: 0.2462 - val_loss: 1.3859 - val_acc: 0.2583\n",
      "Epoch 7/80\n",
      "4000/4000 [==============================] - 0s 53us/step - loss: 1.3902 - acc: 0.2427 - val_loss: 1.3859 - val_acc: 0.3083\n",
      "Epoch 8/80\n",
      "4000/4000 [==============================] - 0s 50us/step - loss: 1.3873 - acc: 0.2572 - val_loss: 1.3858 - val_acc: 0.2508\n",
      "Epoch 9/80\n",
      "4000/4000 [==============================] - 0s 51us/step - loss: 1.3889 - acc: 0.2507 - val_loss: 1.3858 - val_acc: 0.2692\n",
      "Epoch 10/80\n",
      "4000/4000 [==============================] - 0s 47us/step - loss: 1.3876 - acc: 0.2605 - val_loss: 1.3858 - val_acc: 0.2500\n",
      "Epoch 11/80\n",
      "4000/4000 [==============================] - 0s 53us/step - loss: 1.3863 - acc: 0.2645 - val_loss: 1.3858 - val_acc: 0.3000\n",
      "Epoch 12/80\n",
      "4000/4000 [==============================] - 0s 56us/step - loss: 1.3878 - acc: 0.2572 - val_loss: 1.3857 - val_acc: 0.3275\n",
      "Epoch 13/80\n",
      "4000/4000 [==============================] - 0s 61us/step - loss: 1.3873 - acc: 0.2487 - val_loss: 1.3858 - val_acc: 0.2500\n",
      "Epoch 14/80\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 1.3865 - acc: 0.2575 - val_loss: 1.3858 - val_acc: 0.2500\n",
      "Epoch 15/80\n",
      "4000/4000 [==============================] - 0s 61us/step - loss: 1.3874 - acc: 0.2500 - val_loss: 1.3858 - val_acc: 0.3058\n",
      "Epoch 16/80\n",
      "4000/4000 [==============================] - 0s 48us/step - loss: 1.3864 - acc: 0.2520 - val_loss: 1.3857 - val_acc: 0.3292\n",
      "Epoch 17/80\n",
      "4000/4000 [==============================] - 0s 51us/step - loss: 1.3865 - acc: 0.2563 - val_loss: 1.3857 - val_acc: 0.2850\n",
      "Epoch 18/80\n",
      "4000/4000 [==============================] - 0s 51us/step - loss: 1.3864 - acc: 0.2610 - val_loss: 1.3857 - val_acc: 0.2983\n",
      "Epoch 19/80\n",
      "4000/4000 [==============================] - 0s 54us/step - loss: 1.3866 - acc: 0.2567 - val_loss: 1.3857 - val_acc: 0.2492\n",
      "Epoch 20/80\n",
      "4000/4000 [==============================] - 0s 56us/step - loss: 1.3860 - acc: 0.2542 - val_loss: 1.3857 - val_acc: 0.2508\n",
      "Epoch 21/80\n",
      "4000/4000 [==============================] - 0s 61us/step - loss: 1.3863 - acc: 0.2480 - val_loss: 1.3856 - val_acc: 0.2900\n",
      "Epoch 22/80\n",
      "4000/4000 [==============================] - 0s 56us/step - loss: 1.3853 - acc: 0.2685 - val_loss: 1.3856 - val_acc: 0.2617\n",
      "Epoch 23/80\n",
      "4000/4000 [==============================] - 0s 50us/step - loss: 1.3866 - acc: 0.2530 - val_loss: 1.3856 - val_acc: 0.2500\n",
      "Epoch 24/80\n",
      "4000/4000 [==============================] - 0s 48us/step - loss: 1.3871 - acc: 0.2503 - val_loss: 1.3856 - val_acc: 0.2500\n",
      "Epoch 25/80\n",
      "4000/4000 [==============================] - 0s 47us/step - loss: 1.3851 - acc: 0.2565 - val_loss: 1.3855 - val_acc: 0.2500\n",
      "Epoch 26/80\n",
      "4000/4000 [==============================] - 0s 47us/step - loss: 1.3861 - acc: 0.2540 - val_loss: 1.3855 - val_acc: 0.2850\n",
      "Epoch 27/80\n",
      "4000/4000 [==============================] - 0s 49us/step - loss: 1.3861 - acc: 0.2455 - val_loss: 1.3855 - val_acc: 0.3783\n",
      "Epoch 28/80\n",
      "4000/4000 [==============================] - 0s 55us/step - loss: 1.3873 - acc: 0.2530 - val_loss: 1.3855 - val_acc: 0.2550\n",
      "Epoch 29/80\n",
      "4000/4000 [==============================] - 0s 55us/step - loss: 1.3869 - acc: 0.2505 - val_loss: 1.3855 - val_acc: 0.3258\n",
      "Epoch 30/80\n",
      "4000/4000 [==============================] - 0s 59us/step - loss: 1.3865 - acc: 0.2593 - val_loss: 1.3855 - val_acc: 0.3075\n",
      "Epoch 31/80\n",
      "4000/4000 [==============================] - 0s 54us/step - loss: 1.3865 - acc: 0.2572 - val_loss: 1.3855 - val_acc: 0.3733\n",
      "Epoch 32/80\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 1.3864 - acc: 0.2600 - val_loss: 1.3855 - val_acc: 0.2908\n",
      "Epoch 33/80\n",
      "4000/4000 [==============================] - 0s 78us/step - loss: 1.3876 - acc: 0.2530 - val_loss: 1.3855 - val_acc: 0.3250\n",
      "Epoch 34/80\n",
      "4000/4000 [==============================] - 0s 68us/step - loss: 1.3856 - acc: 0.2457 - val_loss: 1.3855 - val_acc: 0.2658\n",
      "Epoch 35/80\n",
      "4000/4000 [==============================] - 0s 61us/step - loss: 1.3860 - acc: 0.2442 - val_loss: 1.3855 - val_acc: 0.2592\n",
      "Epoch 36/80\n",
      "4000/4000 [==============================] - 0s 58us/step - loss: 1.3872 - acc: 0.2507 - val_loss: 1.3855 - val_acc: 0.3108\n",
      "Epoch 37/80\n",
      "4000/4000 [==============================] - 0s 56us/step - loss: 1.3861 - acc: 0.2593 - val_loss: 1.3854 - val_acc: 0.2667\n",
      "Epoch 38/80\n",
      "4000/4000 [==============================] - 0s 60us/step - loss: 1.3861 - acc: 0.2582 - val_loss: 1.3854 - val_acc: 0.2533\n",
      "Epoch 39/80\n",
      "4000/4000 [==============================] - 0s 56us/step - loss: 1.3852 - acc: 0.2640 - val_loss: 1.3853 - val_acc: 0.2500\n",
      "Epoch 40/80\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 1.3858 - acc: 0.2612 - val_loss: 1.3853 - val_acc: 0.2508\n",
      "Epoch 41/80\n",
      "4000/4000 [==============================] - 0s 74us/step - loss: 1.3853 - acc: 0.2500 - val_loss: 1.3853 - val_acc: 0.2500\n",
      "Epoch 42/80\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 1.3849 - acc: 0.2608 - val_loss: 1.3852 - val_acc: 0.2500\n",
      "Epoch 43/80\n",
      "4000/4000 [==============================] - 0s 50us/step - loss: 1.3848 - acc: 0.2677 - val_loss: 1.3851 - val_acc: 0.2625\n",
      "Epoch 44/80\n",
      "4000/4000 [==============================] - 0s 53us/step - loss: 1.3850 - acc: 0.2623 - val_loss: 1.3850 - val_acc: 0.3842\n",
      "Epoch 45/80\n",
      "4000/4000 [==============================] - 0s 56us/step - loss: 1.3854 - acc: 0.2482 - val_loss: 1.3850 - val_acc: 0.2875\n",
      "Epoch 46/80\n",
      "4000/4000 [==============================] - 0s 60us/step - loss: 1.3867 - acc: 0.2515 - val_loss: 1.3850 - val_acc: 0.3017\n",
      "Epoch 47/80\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 1.3860 - acc: 0.2610 - val_loss: 1.3849 - val_acc: 0.2667\n",
      "Epoch 48/80\n",
      "4000/4000 [==============================] - 0s 58us/step - loss: 1.3869 - acc: 0.2437 - val_loss: 1.3850 - val_acc: 0.2883\n",
      "Epoch 49/80\n",
      "4000/4000 [==============================] - 0s 71us/step - loss: 1.3847 - acc: 0.2682 - val_loss: 1.3849 - val_acc: 0.2850\n",
      "Epoch 50/80\n",
      "4000/4000 [==============================] - 0s 75us/step - loss: 1.3850 - acc: 0.2632 - val_loss: 1.3848 - val_acc: 0.3483\n",
      "Epoch 51/80\n",
      "4000/4000 [==============================] - 0s 73us/step - loss: 1.3859 - acc: 0.2535 - val_loss: 1.3847 - val_acc: 0.3292\n",
      "Epoch 52/80\n",
      "4000/4000 [==============================] - 0s 60us/step - loss: 1.3850 - acc: 0.2735 - val_loss: 1.3846 - val_acc: 0.2808\n",
      "Epoch 53/80\n",
      "4000/4000 [==============================] - 0s 64us/step - loss: 1.3840 - acc: 0.2602 - val_loss: 1.3844 - val_acc: 0.3450\n",
      "Epoch 54/80\n",
      "4000/4000 [==============================] - 0s 54us/step - loss: 1.3860 - acc: 0.2572 - val_loss: 1.3844 - val_acc: 0.3575\n",
      "Epoch 55/80\n",
      "4000/4000 [==============================] - 0s 51us/step - loss: 1.3850 - acc: 0.2657 - val_loss: 1.3843 - val_acc: 0.3092\n",
      "Epoch 56/80\n",
      "4000/4000 [==============================] - 0s 54us/step - loss: 1.3853 - acc: 0.2730 - val_loss: 1.3841 - val_acc: 0.3567\n",
      "Epoch 57/80\n",
      "4000/4000 [==============================] - 0s 49us/step - loss: 1.3849 - acc: 0.2655 - val_loss: 1.3840 - val_acc: 0.2925\n",
      "Epoch 58/80\n",
      "4000/4000 [==============================] - 0s 54us/step - loss: 1.3859 - acc: 0.2623 - val_loss: 1.3839 - val_acc: 0.3617\n",
      "Epoch 59/80\n",
      "4000/4000 [==============================] - 0s 53us/step - loss: 1.3848 - acc: 0.2582 - val_loss: 1.3838 - val_acc: 0.2683\n",
      "Epoch 60/80\n",
      "4000/4000 [==============================] - 0s 51us/step - loss: 1.3844 - acc: 0.2722 - val_loss: 1.3836 - val_acc: 0.2683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80\n",
      "4000/4000 [==============================] - 0s 47us/step - loss: 1.3838 - acc: 0.2712 - val_loss: 1.3833 - val_acc: 0.3933\n",
      "Epoch 62/80\n",
      "4000/4000 [==============================] - 0s 43us/step - loss: 1.3848 - acc: 0.2707 - val_loss: 1.3832 - val_acc: 0.3108\n",
      "Epoch 63/80\n",
      "4000/4000 [==============================] - 0s 44us/step - loss: 1.3845 - acc: 0.2707 - val_loss: 1.3830 - val_acc: 0.2892\n",
      "Epoch 64/80\n",
      "4000/4000 [==============================] - 0s 50us/step - loss: 1.3827 - acc: 0.2787 - val_loss: 1.3826 - val_acc: 0.3542\n",
      "Epoch 65/80\n",
      "4000/4000 [==============================] - 0s 52us/step - loss: 1.3841 - acc: 0.2695 - val_loss: 1.3823 - val_acc: 0.3167\n",
      "Epoch 66/80\n",
      "4000/4000 [==============================] - 0s 54us/step - loss: 1.3839 - acc: 0.2642 - val_loss: 1.3822 - val_acc: 0.3575\n",
      "Epoch 67/80\n",
      "4000/4000 [==============================] - 0s 55us/step - loss: 1.3847 - acc: 0.2545 - val_loss: 1.3820 - val_acc: 0.2692\n",
      "Epoch 68/80\n",
      "4000/4000 [==============================] - 0s 54us/step - loss: 1.3845 - acc: 0.2660 - val_loss: 1.3818 - val_acc: 0.3500\n",
      "Epoch 69/80\n",
      "4000/4000 [==============================] - 0s 52us/step - loss: 1.3866 - acc: 0.2620 - val_loss: 1.3817 - val_acc: 0.3858\n",
      "Epoch 70/80\n",
      "4000/4000 [==============================] - 0s 62us/step - loss: 1.3839 - acc: 0.2700 - val_loss: 1.3813 - val_acc: 0.3617\n",
      "Epoch 71/80\n",
      "4000/4000 [==============================] - 0s 72us/step - loss: 1.3827 - acc: 0.2670 - val_loss: 1.3809 - val_acc: 0.3458\n",
      "Epoch 72/80\n",
      "4000/4000 [==============================] - 0s 52us/step - loss: 1.3830 - acc: 0.2732 - val_loss: 1.3805 - val_acc: 0.3533\n",
      "Epoch 73/80\n",
      "4000/4000 [==============================] - 0s 51us/step - loss: 1.3830 - acc: 0.2770 - val_loss: 1.3801 - val_acc: 0.3317\n",
      "Epoch 74/80\n",
      "4000/4000 [==============================] - 0s 53us/step - loss: 1.3814 - acc: 0.2815 - val_loss: 1.3796 - val_acc: 0.3050\n",
      "Epoch 75/80\n",
      "4000/4000 [==============================] - 0s 50us/step - loss: 1.3822 - acc: 0.2838 - val_loss: 1.3792 - val_acc: 0.3167\n",
      "Epoch 76/80\n",
      "4000/4000 [==============================] - 0s 51us/step - loss: 1.3807 - acc: 0.2760 - val_loss: 1.3786 - val_acc: 0.3267\n",
      "Epoch 77/80\n",
      "4000/4000 [==============================] - 0s 54us/step - loss: 1.3824 - acc: 0.2732 - val_loss: 1.3780 - val_acc: 0.3592\n",
      "Epoch 78/80\n",
      "4000/4000 [==============================] - 0s 56us/step - loss: 1.3801 - acc: 0.2908 - val_loss: 1.3772 - val_acc: 0.3575\n",
      "Epoch 79/80\n",
      "4000/4000 [==============================] - 0s 64us/step - loss: 1.3808 - acc: 0.2770 - val_loss: 1.3766 - val_acc: 0.4008\n",
      "Epoch 80/80\n",
      "4000/4000 [==============================] - 0s 67us/step - loss: 1.3813 - acc: 0.2770 - val_loss: 1.3761 - val_acc: 0.4808\n"
     ]
    }
   ],
   "source": [
    "#Para la compilación usaremos el optimizador RMSprop ya que termina la red con una sola\n",
    "#unidad sigmoidea, cómo función de pérdida se utiliza la entropia cruzada binaria\n",
    "\n",
    "top_model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = optimizers.RMSprop(lr=2e-5), \n",
    "              metrics = ['acc'])\n",
    "\n",
    "epochs = 80\n",
    "\n",
    "history = top_model.fit(\n",
    "    train_features,\n",
    "    train_labels,  \n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs, \n",
    "    verbose = 1, \n",
    "    validation_data = (validation_features, validation_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_model.save('Fast_Extraction_ResNet50_1.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Guardamos el modelo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Graficamos la Exactitud y la pérdida del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd69e0b8f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xl8VfWd//HXhxDAsENwUBCitSOLsoSIIFJAW4tbFUvdQtW6MDpW21rnp61arA7zcBtFraNF69IaoY6OtnXDpSjVWjUoAoIWWgGDKJtsBpXA5/fH99xwicldkpvcm+T9fDzOI/ee7X7ukvM53+V8j7k7IiIibbIdgIiI5AYlBBERAZQQREQkooQgIiKAEoKIiESUEEREBFBCEBGRiBKCiIgASggiIhJpm+0A0lFYWOhFRUXZDkNEpFmZP3/+enfvlWy9ZpUQioqKKC8vz3YYIiLNipmtTGU9VRmJiAighCAiIhElBBERAZpZG4KINK0dO3ZQUVHB559/nu1QJAUdOnSgb9++5Ofn12t7JQQRqVNFRQWdO3emqKgIM8t2OJKAu7NhwwYqKirYf//967WPFl9lVFYGRUXQpk34W1aW7YhEmo/PP/+cnj17Khk0A2ZGz549G1Saa9ElhLIymDoVKivD85Urw3OA0tLsxSXSnCgZNB8N/a5adAnhyit3J4OYysowX0RE9tSiE8KqVenNF5HcsmHDBoYNG8awYcPo3bs3ffr0qX7+5ZdfprSPH/zgB7z//vsJ17nzzjspy1B98hFHHMGCBQsysq+m1qKrjPr1C9VEtc0XkcwrKwsl8FWrwv/Z9OkNq57t2bNn9cH1mmuuoVOnTlx22WV7rOPuuDtt2tR+fnv//fcnfZ2LLrqo/kG2IC26hDB9OhQU7DmvoCDMF5HMirXZrVwJ7rvb7BqjI8fy5csZNGgQpaWlDB48mDVr1jB16lRKSkoYPHgw1157bfW6sTP2qqoqunXrxhVXXMHQoUMZPXo0a9euBeCqq65ixowZ1etfccUVjBw5koMOOoi//vWvAHz22Wd897vfZdCgQUyePJmSkpKkJYGHHnqIQw45hIMPPpif//znAFRVVfH973+/ev7tt98OwK233sqgQYMYMmQIU6ZMyfhnloqkCcHM7jOztWa2OMl6h5pZlZlNjpv3rJltMrMna6y7v5m9bmbLzez3Ztau/m+hbqWlMHMm9O8PZuHvzJlqUBZpDE3dZvfee+/xk5/8hCVLltCnTx+uv/56ysvLeeedd3j++edZsmTJV7bZvHkz48aN45133mH06NHcd999te7b3XnjjTe46aabqpPLHXfcQe/evVmyZAlXX301b7/9dsL4KioquOqqq5g7dy5vv/02r776Kk8++STz589n/fr1LFq0iMWLF3PmmWcCcOONN7JgwQIWLlzIr371qwZ+OvWTSgnhAWBiohXMLA+4AXiuxqKbgO/XsskNwK3ufiDwKXBuCnHUS2kprFgBu3aFv0oGIo2jqdvsvva1r1FSUlL9fNasWRQXF1NcXMzSpUtrTQh77bUXxxxzDAAjRoxgxYoVte775JNP/so6r7zyCqeddhoAQ4cOZfDgwQnje/311znyyCMpLCwkPz+fM844g3nz5nHggQfy/vvvc8kllzBnzhy6du0KwODBg5kyZQplZWX1vrCsoZImBHefB2xMstrFwGPA2hrbvghsjZ9noV/UkcCj0awHgZNSjFdEclRdbXON1WbXsWPH6sfLli3jtttu489//jMLFy5k4sSJtfbHb9dud2VEXl4eVVVVte67ffv2Sdepr549e7Jw4ULGjh3LnXfeyb/9278BMGfOHC644ALefPNNRo4cyc6dOzP6uqlocBuCmfUBJgF3pbhJT2CTu8c+5QqgT0PjEJHsymab3ZYtW+jcuTNdunRhzZo1zJkzJ+OvMWbMGB555BEAFi1aVGsJJN5hhx3G3Llz2bBhA1VVVcyePZtx48axbt063J3vfe97XHvttbz11lvs3LmTiooKjjzySG688UbWr19PZc36tyaQiV5GM4DL3X1XY1zAYmZTgakA/dQ9SCRnxapjM9nLKFXFxcUMGjSIAQMG0L9/f8aMGZPx17j44os588wzGTRoUPUUq+6pTd++fbnuuusYP3487s4JJ5zAcccdx1tvvcW5556Lu2Nm3HDDDVRVVXHGGWewdetWdu3axWWXXUbnzp0z/h6SMXdPvpJZEfCkux9cy7IPgFgmKAQqganu/kS0fDxwmbsfHz03YB3Q292rzGw0cI27fztZHCUlJa4b5Ig0naVLlzJw4MBsh5ETqqqqqKqqokOHDixbtoyjjz6aZcuW0bZtbvXer+07M7P57l5SxybVGvxO3L16FCUze4CQOJ5IsL6b2VxgMjAbOAv4Q0PjEBFpTNu2beOoo46iqqoKd+fXv/51ziWDhkr6bsxsFjAeKDSzCmAakA/g7ncn2fYvwACgU7Ttue4+B7gcmG1m/wm8DfymIW9CRKSxdevWjfnz52c7jEaVNCG4++mp7szdz67xfGwd6/0TGJnqfkVEpPG16CuVRUQkdUoIIiICKCGIiEhECUFEctaECRO+cpHZjBkzuPDCCxNu16lTJwA++ugjJk+eXOs648ePJ1k39hkzZuxxgdixxx7Lpk2bUgk9oWuuuYabb765wfvJNCUEEclZp59+OrNnz95j3uzZszn99NT6uuy77748+uijyVesQ82E8PTTT9OtW7d67y/XKSGISM6aPHkyTz31VPXNcFasWMFHH33E2LFjq68LKC4u5pBDDuEPf/jq5UwrVqzg4IPD9bTbt2/ntNNOY+DAgUyaNInt27dXr3fhhRdWD509bdo0AG6//XY++ugjJkyYwIQJEwAoKipi/fr1ANxyyy0cfPDBHHzwwdVDZ69YsYKBAwdy/vnnM3jwYI4++ug9Xqc2CxYsYNSoUQwZMoRJkybx6aefVr9+bDjs2KB6L7/8cvUNgoYPH87WrVsT7TptLeuqChFpND/+MWT6RmDDhkF0LK1Vjx49GDlyJM888wwnnngis2fP5pRTTsHM6NChA48//jhdunRh/fr1jBo1iu985zt13lf4rrvuoqCggKVLl7Jw4UKKi4url02fPp0ePXqwc+dOjjrqKBYuXMgll1zCLbfcwty5cyksLNxjX/Pnz+f+++/n9ddfx9057LDDGDduHN27d2fZsmXMmjWLe+65h1NOOYXHHnss4f0NzjzzTO644w7GjRvHL37xC375y18yY8YMrr/+ej744APat29fXU118803c+eddzJmzBi2bdtGhw4d0vi0k1MJQURyWny1UXx1kbvz85//nCFDhvDNb36T1atX88knn9S5n3nz5lUfmIcMGcKQIUOqlz3yyCMUFxczfPhw3n333aQD173yyitMmjSJjh070qlTJ04++WT+8pe/ALD//vszbNgwIPEQ2xDuz7Bp0ybGjRsHwFlnncW8efOqYywtLeWhhx6qviJ6zJgxXHrppdx+++1s2rQp41dKq4QgIilJdCbfmE488UR+8pOf8NZbb1FZWcmIESMAKCsrY926dcyfP5/8/HyKiopqHfI6mQ8++ICbb76ZN998k+7du3P22WfXaz8xsaGzIQyfnazKqC5PPfUU8+bN409/+hPTp09n0aJFXHHFFRx33HE8/fTTjBkzhjlz5jBgwIB6x1qTSggiktM6derEhAkTOOecc/ZoTN68eTN77703+fn5zJ07l5W13UA9zje+8Q0efvhhABYvXszChQuBMHR2x44d6dq1K5988gnPPPNM9TadO3eutZ5+7NixPPHEE1RWVvLZZ5/x+OOPM3ZsrQMzJNS1a1e6d+9eXbr43e9+x7hx49i1axcffvghEyZM4IYbbmDz5s1s27aNf/zjHxxyyCFcfvnlHHroobz33ntpv2YiKiGISM47/fTTmTRp0h49jkpLSznhhBM45JBDKCkpSXqmfOGFF/KDH/yAgQMHMnDgwOqSxtChQxk+fDgDBgxgv/3222Po7KlTpzJx4kT23Xdf5s6dWz2/uLiYs88+m5Ejwwg85513HsOHD09YPVSXBx98kAsuuIDKykoOOOAA7r//fnbu3MmUKVPYvHkz7s4ll1xCt27duPrqq5k7dy5t2rRh8ODB1Xd/y5SUhr/OFRr+WqRpafjr5qchw1+rykhERAAlBBERiSghiEhCzalaubVr6HelhCAiderQoQMbNmxQUmgG3J0NGzY06GK1VtfLqKwsOzcBF2mO+vbtS0VFBevWrct2KJKCDh060Ldv33pv36oSQlkZTJ0KsbGqVq4Mz0FJQaQ2+fn57L///slXlBahVVUZXXnl7mQQU1kZ5ouItHZJE4KZ3Wdma81scZL1DjWzKjObHDfvLDNbFk1nxc1/yczeN7MF0bR3w95GalatSm++iEhrkkoJ4QFgYqIVzCwPuAF4Lm5eD2AacBgwEphmZt3jNit192HRtDbdwOujX7/05ouItCZJE4K7zwM2JlntYuAxIP7A/m3geXff6O6fAs+TJLE0tunToaBgz3kFBWG+iEhr1+A2BDPrA0wC7qqxqA/wYdzzimhezP1RddHVVtcA5hlWWgozZ0L//mAW/s6cqQZlERHITC+jGcDl7r4rjeN6qbuvNrPOhJLF94Hf1raimU0FpgL0y0DdTmmpEoCISG0y0cuoBJhtZiuAycD/mNlJwGpgv7j1+kbzcPfY363Aw4Q2hlq5+0x3L3H3kl69emUgXBERqU2DSwjuXt1J2cweAJ509yeiRuX/imtIPhr4mZm1Bbq5+3ozyweOB15oaBwiItIwSROCmc0CxgOFZlZB6DmUD+Dud9e1nbtvNLPrgDejWddG8zoCc6JkkEdIBvc06F2IiEiD6X4IIiItnO6HICIiaVFCEBERQAlBREQiSggiIgIoIYiISEQJQUREACUEERGJKCGIiAighCAiIhElBBERAZQQREQkooQgIiKAEoKIiESUEEREBFBCEBGRiBKCiIgASggiIhJRQhAREUAJQUREIiklBDO7z8zWmtniJOsdamZVZjY5bt5ZZrYsms6Kmz/CzBaZ2XIzu93MrP5vQ0REGirVEsIDwMREK5hZHnAD8FzcvB7ANOAwYCQwzcy6R4vvAs4Hvh5NCfcvIiKNK6WE4O7zgI1JVrsYeAxYGzfv28Dz7r7R3T8Fngcmmtk+QBd3/5u7O/Bb4KS0oxcRkYzJSBuCmfUBJhHO+uP1AT6Me14RzesTPa45X0REsiRTjcozgMvdfVeG9lfNzKaaWbmZla9bty7TuxcRkUjbDO2nBJgdtQsXAseaWRWwGhgft15f4KVoft8a81fXtmN3nwnMBCgpKfEMxSsiIjVkpITg7vu7e5G7FwGPAv/u7k8Ac4Cjzax71Jh8NDDH3dcAW8xsVNS76EzgD5mIRURE6ielEoKZzSKc6ReaWQWh51A+gLvfXdd27r7RzK4D3oxmXevuscbpfyf0XtoLeCaaREQkSyx08mkeSkpKvLy8PNthiIg0K2Y2391Lkq2nK5VFRARQQhARkYgSgoiIAEoIIiISUUIQERFACUFERCKtPiGUlUFREbRpE/6WlWU7IhGR7MjU0BXNUlkZTJ0KlZXh+cqV4TlAaWn24hIRyYZWXUK48srdySCmsjLMFxFpbVp1Qli1Kr35IiItWatOCP36pTdfRKQla9UJYfp0KCjYc15BQZgvItLatOqEUFoKM2dC//5gFv7OnKkGZRFpnVp1LyMIB38lABGRVl5CEBGR3ZQQREQEUEIQEZGIEoKIiABKCCIiEkmaEMzsPjNba2aL61h+opktNLMFZlZuZkfELbvBzBZH06lx8x8wsw+ibRaY2bDMvB0REamvVEoIDwATEyx/ERjq7sOAc4B7AczsOKAYGAYcBlxmZl3itvsPdx8WTQvqE7yIiGRO0oTg7vOAjQmWb3N3j552BGKPBwHz3L3K3T8DFpI4sYiISBZlpA3BzCaZ2XvAU4RSAsA7wEQzKzCzQmACsF/cZtOjqqZbzax9JuIQEZH6y0hCcPfH3X0AcBJwXTTvOeBp4K/ALOA1YGe0yc+AAcChQA/g8rr2bWZTo7aJ8nXr1mUiXBERqUVGexlF1UsHRCUC3H161EbwLcCAv0fz13jwBXA/MDLBPme6e4m7l/Tq1SuT4YqISJwGJwQzO9DMLHpcDLQHNphZnpn1jOYPAYYAz0XP94n+GqFUUWsPJhERaTpJB7czs1nAeKDQzCqAaUA+gLvfDXwXONPMdgDbgVPd3c0sH/hLlCu2AFPcvSrabZmZ9SKUGhYAF2T0XYmISNpsdweh3FdSUuLl5eXZDkNEpFkxs/nuXpJsPV2pLCIigBKCiIhElBBERARQQhARkYgSgoiIAEoIIiISUUJIQ1kZFBVBmzbhb1lZtiMSEcmcpBemSVBWBlOnQmVleL5yZXgOUFqavbhERDJFJYQUXXnl7mQQU1kZ5ouItARKCDXUVS20alXt69c1X0SkuVGVUZxE1UL9+oXnNfXr13TxiYg0JpUQ4iSqFpo+HQoK9lxWUBDmi4i0BEoIcRJVC5WWwsyZ0L8/mIW/M2eqQVlEWg5VGcVJVi1UWqoEICItl0oIcVQtJCKtmRJCHFULiUhrpiqjGlQtJCKtlUoIIiICKCEkpLGLRKQ1UUKoQ+witZUrwX33RWrxSUEJQ0RakqQJwczuM7O1Zra4juUnmtlCM1tgZuVmdkTcshvMbHE0nRo3f38ze93MlpvZ782sXWbeTuYkG7solYQhItKcpFJCeACYmGD5i8BQdx8GnAPcC2BmxwHFwDDgMOAyM+sSbXMDcKu7Hwh8Cpxbr+gbUbKxizTYnYi0NEkTgrvPAzYmWL7N3T162hGIPR4EzHP3Knf/DFgITDQzA44EHo3WexA4qZ7xN5q6xiiKzddgdyLS0mSkDcHMJpnZe8BThFICwDuEBFBgZoXABGA/oCewyd2rovUqgD4J9j01qooqX7duXSbCTUmyi9SSJQwRkeYmIwnB3R939wGEM/3ronnPAU8DfwVmAa8BO+ux75nuXuLuJb169cpEuClJdpGarmoWkZYmo72MouqlA6ISAe4+3d2Hufu3AAP+DmwAuplZ7KK4vsDqTMaRKaWlsGIF7NoV/sZfsKarmkWkpWlwQjCzA6N2AcysGGgPbDCzPDPrGc0fAgwBnovaG+YCk6NdnAX8oaFxZEOihAHqlioizUvSoSvMbBYwHig0swpgGpAP4O53A98FzjSzHcB24FR3dzPLB/4S5YotwJS4doPLgdlm9p/A28BvMvqucoDuwSwizY3t7iCU+0pKSry8vDzbYaSkqKj2obT79w+lCRGRpmJm8929JNl6ulK5kahbqog0N0oIjUTdUkWkuVFCaCTqlioizY0SQiNRt1QRaW6UEBpRsm6p8dRFVUSyTQmhCdV10NfIqZmhpCrSMEoITSTRQb8+I6e2lINfpt6HkqpIBrh7s5lGjBjhueyhh9z793c3C38femj3sv793cOhas8ptn5ty6D2fT30kHtBwZ7rFRTsuU5zkMn3kejzTfT6dX1fIi0JUO4pHGOzfpBPZ8rlhJDs4FbXQT92MKorIdS2r/oc/Br7vdfnwJrJ95Ho860r5paQVEVSoYTQxJId3BItr+3glGhf6R78GlNDDqzplowSSTe55FpSTYdKNpIuJYQmluwgnezAGf9Pnugg6Z5bB7OGxJJuySiRdBNTLiXVmhId8FWykfpQQmhiqRwYUz2zq2tfeXlh25493du123NZfn6YH9v3hRfu+Vrxz3v23HPddA8m6SSvZPtJpWQUe9/J3kfN95zofeVSUo2X7ICfq3E3N62tlKWEEGfBAve//71em6asPmdudf0oUzlQxieA2hJEOlPNONM9Q23IASqV5FLf95Hp76spJDvg53LJprnI1e++MSkhxDn8cPe99nK/4w73nTvrtYuUpHPWkU4VUl5e4oNEKlUvqR7A63uGmsr7SHYWn8n3UZ/vK1GpqqnOIpMd8FVCaLjW+BkqIcRZvdr9mGPCuz3ySPcVK+q1m4xK50eZ7CCRibPr2P6SJZ90GoJTKU3UTB6plD6SvYe6NLTk0xRnkfWpLqxvSbSh6zZXrbGUpYRQw65d7vfc496pk3vnzu4//rH7vfe6v/aa+6ZN9d5tvaXzo6xvD6ZMTvU5Q001rrraWepKTqnuK14mSj7x+2+sA2e61YUNLYnWd91Er5frCUUlBCWEah984H7sse4dOuz5Y+ja1f2gg9zHj3c/9VT3s85yP++8UG3wox+5X3ON+69+5T5rlvuzz7q/9JL73/4W2ieWL3ffti29ONL5UaZSvdTQM+t0DoSpHjRSLbmkc61AoilRW0hDSj41Y23sOuh04k4mEwk8nfag5lA331zizKRUE0KrvWPazp1hwLklS8K0ejWsWQMffwyffAJffAE7doTpiy9g69bk++zUCXr3ho4doapq92QG+fnQtm34W1AAW7bAu++GOGLy82HyZBgyBL78Mkw7doSf7LvvwiuvhO26dIHx42Ho0LDPtm1h0SKYMwc+/RR69oThw+Gdd2DdOigsDM/ffhvWrw/bm8Hmzal9VgUFe47UGhtuY9WqcH+H6dNrH7ivrrvG1ZToLnI1X+vYY+Hpp8PzHj3COhs3fjWOmrcwrYtZGHwwnVgh83fDq+szbdMmfP91xZ1MOts39LWa010CU/0NtxSp3jGt1SaEdO3YEQ48GzaEg+4XX8Dnn4dpy5aQRD7+OEyVlbsTQF5e+CfbsSMkhy+/hO3b4bPPQhL6+OM9k0K8vLywD7Pdk3tYPzY1tnbtoFev8J4rK0OyKy6Gf/3XEJ9ZOJDk5UHXriEZFRaGg/Wrr8Itt4TPqi4dOsB118EJJ+w5P7bP2GfYrt2eU15e4rjTTUapJJDY55+IWfoHmNpeO5aEr7yyYQfZdA7Sqayb6EDa0IQijSfVhJC0CAHcB6wFFtex/ERgIbAAKAeOiFt2I/AusBS4nd0J6CXg/WibBcDeqRRncvk6hEz48kv3LVvct293r6pKbZudO90//9x961b3jRvdP/44VIstXer+9tthWrjQffHiML32Wqjymj3bfeZM9ylTQp10fPG5bVv3cePcTzvNfehQ9zZtvlpt0r27e+/e7nvv7V5YGJ7XXK8xJ7PQuNqxo3u3bqHKr3Pn0EbUsWPq++ja1b2oyL2kxH3IkN3bduniPnq0e48e9YsvnYbeRNVCDa3eqG37utog6lM1qWskmgcyVWVkZt8AtgG/dfeDa1neCfjM3d3MhgCPuPsAMzscuAn4RrTqK8DP3P0lM3sJuMzd0zrdz2YJoSVLdNaXzhnmrl1w773wox+FklNMu3ZwwQUwevTuarhdu8JZfmxqEzfurntYvnNnKFXt3Bm2+fLLUNqIVaXFT23a7C6tANxzT+JqvoKCUI02aFCIdf363dOmTaE6raFntbESxT77wDHHwIsv7q7q2ro1vI9k2+/alX71RrJqtpqvHV8lmGjbNm1qL5Xm5YU4k+07mdZWjdOUMlZCiBJGEXWUEGqsNxpYGvd4PrAXUEAoPQz03SWEklReO35q6SWEXJRuF71cOUts6Jn1rl2htLZyZdOVempO++wTukhv2hTiicX12Wfua9eG+GLvNf7q7UTdUhvamSHZlOyK+bo+/0w39DaH3k5NiUz2MkqWEIBJwHvARmB03PybgU3AZmB63PyXgEWE6qKriaqSkk1KCE0v3QN8LvXxztRBIRe6/bZpE6qzan6+hYWpVdXV50rn+r6v+vRIS3b9RTrfXzrVZK1FkyaEuPW+AbwQPT4QeAroFE2vAWOjZX2iv52B54AzE+xzalS6KO/Xr18jf2xSU7pnbrlSQsikpur2Gzuw7723+09/6v7YY+6/+Y37zTe7X3ml+6WXul91lfv114er7qdPT+91r746JJBUv5/6XvCY7JqV2OvF/4ZSea1USwzpXk3fGmQlIUTr/hMoBP4DuDpu/i+A/1fL+mcDv0pl3yohZEcmh+RorpJ9Bg29oK6+n1GqB+22besuSbRr5z5jRuicEC/ZWXtDr+1oyIWBmfhMmvNJSrqaLCFEJYFY43QxsBow4FTgBaAtkA+8CJwQPS+M1s8HHgUuSCUOJYTmobXX32b6auNE0jkbrqx0nz/fferU0COrtnXbt3fv18991KgwzEvNHmiZ6HVU20E51VJWfNVWXb+zVJNLSx6qoqaMJQRgFrAG2AFUAOcCF8QO4sDlhK6lC6JqoSOi+XnArwldTpcAt0TzO0aNzQuj7W4D8lIJVglBmot0BvVr6OvUt778oYfCoI81SxJHHBGu2O/W7av7HTPG/dZb3efNC43bmRgZt7bPKFnpo7Z9x0oGqY7+W9eQKS3xJCajJYRcmZQQRL6qvgezZO09u3aFXk6PP+4+bZr78ce777vv7vXy8sJ1Kuef737TTe4PP+z+8svu//jH7lGFY7GlcsaeydJHsuHh03mtliDVhKArlUVaqfpeWfzxx1BeDm+8Aa+/Dm++Ga5kj9e1Kxx2GBx+eJgqKuCHP0w+lEhDr4quz76a05Ab9aWhK0QkoUwdCN3D8C2rV4dp5cqQJF57DRYvDss7dICDDgoH5JrJI15Dx02qz75aw5AbqSaENslWEJGWafr0cCVxvIKCMD8dZqFEMGgQfOtbcN558Otfw8KF4arvp5/ePVZTLBm0a1f7vvr1q3/s9d1XXeulun1LooQg0kqVloZhJfr3Dwf1/v1TH2YiVV26hGE7brsN/v53WL4cbr4Z9t33q+u2awcXX5y8Kqhm7BDij5dOYkslMZaVhVJJmzZh8MbCwvC4qCgsazFSaWjIlUmNyiItx403hsEFazYI9+4dehy98IL7jh2710/Wo6khvYQS9QpL1mupOTRAo0ZlEWkuduwI9/woL4dnn4VnnglVTD17wtlnw4EHwk9/WvsQ4ZkeAC/Ve2nEy/UGaDUqi0izVVkZbvj0+9/D//7v7vPxmhrjQJzqvTTipdMAnY1RXdWoLCLNVkEBTJoEs2eHxum6zltXrcr8a9dnn/EN0PHtDTXbGGKlj5Urw3tauTI8z5V2CCUALhOjAAAMZUlEQVQEEclpgwfvbjyuqUePcJvYTEq3d1F8A3SyA/6VV361KqqyMszPBUoIIpLzausJZBZuabv33uG2rldcEW5CtH175l8rPz+0Z5iFv7HHNXtmJTvg11X6aIySTn0oIYhIzquti+xvfxuulr7uOujcGf77v+Gb34Ru3WDcOJg2DV5+Of17j9f2WvffH+6mt2vX7jvr7doV2i/i6/+THfBz/ZoHNSqLSIuwdSvMmwcvvRSmt94KB+3eveF734PTToNRo/a8XWumJbv6u7YeTI3VWyqeGpVFpFXp3BmOOw5uuikMnbFhQ+ildPjh4YA7Zky4oGz4cDjxxDC20sMPh/t2N0R8I/K2bV+9Cju+jaEpLgZsCJUQRKTF27IF/vhHePVV+PDDMK1cCZs3w9e+Fur4p0wJbQXpqO2MPz8/XKG9cWPDu5VmqouqrkMQEUnAPSSJa68N1Uv77x8el5Z+dSiMujTmSKmZrF5SlZGISAJmoeqovByefDJ0Yf3+92HsWFiwILV9NEavoVgV1JQpTd9FVQlBRFo1s9D28MYb8JvfwPvvw4gRcNFFiYfqhtR6DSW6UK2m+OsY6tKYXVSVEERECAfsc84Jo7JedBHcfXe4h8ODD9Z9pXSykVLTvTK5tusYamrMLqpKCCIicbp3h9tvh/nzw6B6Z58drmtYvPir6ybrNZTulcnJzv7rc7+KdKSUEMzsPjNba2a1fCRgZiea2UIzW2Bm5WZ2RNyyG83sXTNbama3m4XmGjMbYWaLzGx5/HwRkVwwbBi88grce28YiXXYsDDi6pYte65XWhoakOtzoRrsWaWU6BqJpuiimmoJ4QFgYoLlLwJD3X0YcA5wL4CZHQ6MAYYABwOHAuOibe4Czge+Hk2J9i8i0uTatIFzzw3tCuecA7feGqqRHnootRv5JGtjqFmlVNtV1QUF4fVqJpvGkFJCcPd5wMYEy7f57v6rHYHYYwc6AO2A9kA+8ImZ7QN0cfe/Rdv9Fjipfm9BRKRxFRaGs/PXX4f99gu9kcaPhw8+SLxdsjaGutoM8vKyc+FaxtoQzGySmb0HPEUoJeDurwFzgTXRNMfdlwJ9gIq4zSuieSIiOevQQ+Fvf4N77oF33gm9kZ56qu71k7Ux1FWltGtX7VVQjS1jCcHdH3f3AYQz/esAzOxAYCDQl3DAP9LMxqazXzObGrVLlK/L9Di3IiJpatMGzjsvNDr37w/HHx/O9OsaAiNRG0OuDXaX8V5GUfXSAWZWCEwC/hZVKW0DngFGA6sJSSKmbzSvtv3NdPcSdy/p1atXpsMVEamXr30N/vpXOP98+K//gqOOgrffTm8fyaqUmlpGEoKZHRjXe6iY0F6wAVgFjDOztmaWT2hQXurua4AtZjYq2u5M4A+ZiEVEpKnstVeoAnrwQVi0KNyX4ZRT4L33Uts+1wa7S2ksIzObBYwHCoFPgGmEBmLc/W4zu5xwUN8BbAf+w91fMbM84H+AbxAamJ9190ujfZYQei/tRSg5XOxJgtFYRiKSqzZvDvdkuPXW0FB8wQUwY0b6A+Y1Bg1uJyKSBevWhZv23HEHnHRSuC90+/bZjUmD24mIZEGvXuFK5zvugCeeCAPoJRuOIlcoIYiINIIf/jAMlvfcc3DMMeGObrlOCUFEpJGcc064K9urr8KECfDxx9mOKDElBBGRRnTaaaHqaOnScE/npUuzHVHdlBBERBrZ8cfDyy/D55+Hezy//HK2I6qdEoKISBMoKQnDXvTuDUcfDY8+mu2IvkoJQUSkiRQVhaubDz0UzjgjNDjnEiUEEZEm1L17GBBv0CCYNCmUGnKFEoKISBPr2hWefRb22Sfcz3nJkmxHFCghiIhkQe/eocqoXbvQprBiRbYjUkIQEcmaAw6AOXPgs89Su+FOY1NCEBHJoiFD4IUXwr2ax4+Hf/4ze7EoIYiIZNmIEfDii7BtG4wbB8uXZycOJQQRkRwwfDj8+c+wfXtICunebCcTlBBERHLE0KEwd264Wc6oUWHE1Ka8Q4ESgohIDjnkEFiwAL71LbjkEjj5ZNi4sWleWwlBRCTHFBbCn/4U7sD21FOhOunddxv/dZUQRERykBlcemkYOnvgQNhvv8Z/zbaN/xIiIlJfhx4armpuCklLCGZ2n5mtNbPFdSw/0cwWmtkCMys3syOi+ROiebHpczM7KVr2gJl9ELdsWGbfloiIpCuVEsIDwK+A39ax/EXgj+7uZjYEeAQY4O5zgWEAZtYDWA7Ej+33H+6egwPAioi0TklLCO4+D6izjdvdt7lXd4zqCNTWSWoy8Iy7N5NbTYuItD4ZaVQ2s0lm9h7wFHBOLaucBsyqMW96VNV0q5m1z0QcIiJSfxlJCO7+uLsPAE4CrotfZmb7AIcAc+Jm/wwYABwK9AAur2vfZjY1apsoX7duXSbCFRGRWmS022lUvXSAmRXGzT4FeNzdd8Stt8aDL4D7gZEJ9jnT3UvcvaRXr16ZDFdEROI0OCGY2YFmZtHjYqA9sCFuldOpUV0UlRqItjsJqLUHk4iINJ2kvYzMbBYwHig0swpgGpAP4O53A98FzjSzHcB24NRYI7OZFQH7AS/X2G2ZmfUCDFgAXJCB9yIiIg1g3pQjJzWQma0DVqa4eiGwvhHDaYhcjS1X44LcjS1X44LcjS1X44Lcja2hcfV396R17s0qIaTDzMrdvSTbcdQmV2PL1bggd2PL1bggd2PL1bggd2Nrqrg0lpGIiABKCCIiEmnJCWFmtgNIIFdjy9W4IHdjy9W4IHdjy9W4IHdja5K4WmwbgoiIpKcllxBERCQNLTIhmNlEM3vfzJab2RVZjuUrw4ebWQ8ze97MlkV/u2chrv3MbK6ZLTGzd83sR7kQm5l1MLM3zOydKK5fRvP3N7PXo+/092bWrinjiosvz8zeNrMncyyuFWa2KDYMfTQv67+zKI5uZvaomb1nZkvNbHS2YzOzg2oMz7/FzH6c7bji4vtJ9PtfbGazov+LRv+ttbiEYGZ5wJ3AMcAg4HQzG5TFkB4AJtaYdwXwort/nTB8eDaSVhXwU3cfBIwCLoo+p2zH9gVwpLsPJQyfPtHMRgE3ALe6+4HAp8C5TRxXzI+ApXHPcyUugAnuPiyue2K2v8uY24Bno/HOhhI+v6zG5u7vR5/VMGAEUAk8nu24AMysD3AJUOLuBwN5hAFCG/+35u4tagJGA3Pinv8M+FmWYyoCFsc9fx/YJ3q8D/B+DnxufwC+lUuxAQXAW8BhhIty2tb2HTdhPH0JB4kjgScJV9pnPa7otVcAhTXmZf27BLoCHxC1V+ZSbHGxHA28mitxAX2ADwkDf7aNfmvfborfWosrIbD7w4ypiOblkn9x9zXR44+Bf8lmMNEQI8OB18mB2KJqmQXAWuB54B/AJnevilbJ1nc6A/h/wK7oec8ciQvCfUieM7P5ZjY1mpf17xLYH1gH3B9Vtd1rZh1zJLaY+OH5sx6Xu68GbgZWAWuAzcB8muC31hITQrPiId1nrauXmXUCHgN+7O5b4pdlKzZ33+mhKN+XMBLugKaOoSYzOx5Y6+7zsx1LHY5w92JCVelFZvaN+IVZ/J21BYqBu9x9OPAZNaphsvk/ENXDfwf435rLshVX1G5xIiGZ7ku48VjNaudG0RITwmrCgHoxfaN5ueSTuBFf9yGcCTc5M8snJIMyd/+/XIoNwN03AXMJxeNuZhYbjDEb3+kY4DtmtgKYTag2ui0H4gKqzypx97WEuvCR5MZ3WQFUuPvr0fNHCQkiF2KDkEDfcvdPoue5ENc3gQ/cfZ2H2wb8H+H31+i/tZaYEN4Evh61yLcjFAf/mOWYavojcFb0+CxC/X2TMjMDfgMsdfdbciU2M+tlZt2ix3sR2jWWEhLD5GzF5e4/c/e+7l5E+E392d1Lsx0XgJl1NLPOsceEOvHF5MDvzN0/Bj40s4OiWUcBS3IhtkjN4flzIa5VwCgzK4j+T2OfWeP/1rLVkNPIjTLHAn8n1D1fmeVYZhHqAXcQzpbOJdQ9vwgsA14AemQhriMIxeGFhCHIF0SfW1ZjA4YAb0dxLQZ+Ec0/AHgDWE4o3rfP4nc6HngyV+KKYngnmt6N/eaz/V3GxTcMKI++0yeA7rkQG6EqZgPQNW5e1uOK4vgl8F70P/A7wn1mGv23piuVRUQEaJlVRiIiUg9KCCIiAighiIhIRAlBREQAJQQREYkoIYiICKCEICIiESUEEREB4P8DNM97vNzebkkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd69e01e5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Mostramos otros graficos \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+ 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "#plt.tittle('Trainning and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "#plt.tittle('Trainning and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 0s 64us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3770985301335652, 0.385]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.evaluate(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
