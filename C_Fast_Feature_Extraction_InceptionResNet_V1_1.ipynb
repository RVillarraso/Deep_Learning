{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Entreno de un ConvNet Inception ResNetV1 preentrenado con Imagenet y\n",
    "entrenando conjunto de datos pequeño\n",
    "Conjunto de datos de 4 clases\n",
    "Utilizaremos un conjunto de datos reducido:\n",
    "- Conjunto de entrenamiento: 1.000 muestras x clase \n",
    "- Conjunto de validación: 300 muestras x clase\n",
    "- Conjunto de test: 300 muestras x clase\n",
    "El conjunto de datos: balanced_dataset\n",
    "contiene tres carpetas, train, validation y test, cada una con 4 clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 149, 149, 32) 896         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 147, 147, 32) 9248        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 145, 145, 64) 18496       conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 72, 72, 64)   0           conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 72, 72, 80)   5200        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 70, 70, 192)  138432      conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 35, 35, 256)  442624      conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 256)  1024        conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 35, 35, 32)   8224        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 35, 35, 32)   8224        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 35, 35, 32)   8224        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_43 (Merge)                (None, 35, 35, 96)   0           conv2d_136[0][0]                 \n",
      "                                                                 conv2d_138[0][0]                 \n",
      "                                                                 conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 35, 35, 256)  24832       merge_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 35, 35, 256)  0           conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_44 (Merge)                (None, 35, 35, 256)  0           activation_24[0][0]              \n",
      "                                                                 lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 256)  1024        merge_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 35, 35, 32)   8224        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 35, 35, 32)   8224        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 35, 35, 32)   8224        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_45 (Merge)                (None, 35, 35, 96)   0           conv2d_143[0][0]                 \n",
      "                                                                 conv2d_145[0][0]                 \n",
      "                                                                 conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 35, 35, 256)  24832       merge_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 35, 35, 256)  0           conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_46 (Merge)                (None, 35, 35, 256)  0           activation_25[0][0]              \n",
      "                                                                 lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 35, 35, 256)  1024        merge_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 35, 35, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 35, 35, 32)   8224        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 35, 35, 32)   8224        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 35, 35, 32)   8224        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_47 (Merge)                (None, 35, 35, 96)   0           conv2d_150[0][0]                 \n",
      "                                                                 conv2d_152[0][0]                 \n",
      "                                                                 conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 35, 35, 256)  24832       merge_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 35, 35, 256)  0           conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_48 (Merge)                (None, 35, 35, 256)  0           activation_26[0][0]              \n",
      "                                                                 lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 256)  1024        merge_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 256)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 35, 35, 32)   8224        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 35, 35, 32)   8224        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 35, 35, 32)   8224        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_49 (Merge)                (None, 35, 35, 96)   0           conv2d_157[0][0]                 \n",
      "                                                                 conv2d_159[0][0]                 \n",
      "                                                                 conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 35, 35, 256)  24832       merge_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 35, 35, 256)  0           conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_50 (Merge)                (None, 35, 35, 256)  0           activation_27[0][0]              \n",
      "                                                                 lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 256)  1024        merge_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 35, 35, 32)   8224        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 35, 35, 32)   8224        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 35, 35, 32)   8224        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 35, 35, 32)   9248        conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_51 (Merge)                (None, 35, 35, 96)   0           conv2d_164[0][0]                 \n",
      "                                                                 conv2d_166[0][0]                 \n",
      "                                                                 conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 35, 35, 256)  24832       merge_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 35, 35, 256)  0           conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_52 (Merge)                (None, 35, 35, 256)  0           activation_28[0][0]              \n",
      "                                                                 lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 35, 35, 256)  1024        merge_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 35, 35, 256)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 35, 35, 192)  49344       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 35, 35, 192)  331968      conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 17, 17, 256)  0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 17, 17, 384)  885120      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 17, 17, 256)  442624      conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_53 (Merge)                (None, 17, 17, 896)  0           max_pooling2d_5[0][0]            \n",
      "                                                                 conv2d_171[0][0]                 \n",
      "                                                                 conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 896)  3584        merge_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 896)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 17, 17, 128)  114816      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 17, 17, 128)  114816      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_54 (Merge)                (None, 17, 17, 256)  0           conv2d_175[0][0]                 \n",
      "                                                                 conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 17, 17, 896)  230272      merge_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 17, 17, 896)  0           conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_55 (Merge)                (None, 17, 17, 896)  0           activation_30[0][0]              \n",
      "                                                                 lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 896)  3584        merge_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 896)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 17, 17, 128)  114816      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 17, 17, 128)  114816      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_56 (Merge)                (None, 17, 17, 256)  0           conv2d_180[0][0]                 \n",
      "                                                                 conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 17, 17, 896)  230272      merge_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 17, 17, 896)  0           conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_57 (Merge)                (None, 17, 17, 896)  0           activation_31[0][0]              \n",
      "                                                                 lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 896)  3584        merge_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 896)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 17, 17, 128)  114816      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 17, 17, 128)  114816      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_58 (Merge)                (None, 17, 17, 256)  0           conv2d_185[0][0]                 \n",
      "                                                                 conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 17, 17, 896)  230272      merge_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 17, 17, 896)  0           conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_59 (Merge)                (None, 17, 17, 896)  0           activation_32[0][0]              \n",
      "                                                                 lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 896)  3584        merge_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 896)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 17, 17, 128)  114816      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 17, 17, 128)  114816      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_60 (Merge)                (None, 17, 17, 256)  0           conv2d_190[0][0]                 \n",
      "                                                                 conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 17, 17, 896)  230272      merge_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 17, 17, 896)  0           conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_61 (Merge)                (None, 17, 17, 896)  0           activation_33[0][0]              \n",
      "                                                                 lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 896)  3584        merge_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 896)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 17, 17, 128)  114816      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 17, 17, 128)  114816      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_62 (Merge)                (None, 17, 17, 256)  0           conv2d_195[0][0]                 \n",
      "                                                                 conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 17, 17, 896)  230272      merge_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 17, 17, 896)  0           conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_63 (Merge)                (None, 17, 17, 896)  0           activation_34[0][0]              \n",
      "                                                                 lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 896)  3584        merge_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 896)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 17, 17, 128)  114816      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 17, 17, 128)  114816      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_64 (Merge)                (None, 17, 17, 256)  0           conv2d_200[0][0]                 \n",
      "                                                                 conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 17, 17, 896)  230272      merge_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 17, 17, 896)  0           conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_65 (Merge)                (None, 17, 17, 896)  0           activation_35[0][0]              \n",
      "                                                                 lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 896)  3584        merge_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 896)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 17, 17, 128)  114816      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 17, 17, 128)  114816      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_66 (Merge)                (None, 17, 17, 256)  0           conv2d_205[0][0]                 \n",
      "                                                                 conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 17, 17, 896)  230272      merge_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 17, 17, 896)  0           conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_67 (Merge)                (None, 17, 17, 896)  0           activation_36[0][0]              \n",
      "                                                                 lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 896)  3584        merge_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 896)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 17, 17, 128)  114816      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 17, 17, 128)  114816      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_68 (Merge)                (None, 17, 17, 256)  0           conv2d_210[0][0]                 \n",
      "                                                                 conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 17, 17, 896)  230272      merge_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 17, 17, 896)  0           conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_69 (Merge)                (None, 17, 17, 896)  0           activation_37[0][0]              \n",
      "                                                                 lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 896)  3584        merge_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 896)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 17, 17, 128)  114816      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 17, 17, 128)  114816      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_70 (Merge)                (None, 17, 17, 256)  0           conv2d_215[0][0]                 \n",
      "                                                                 conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 17, 17, 896)  230272      merge_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 17, 17, 896)  0           conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_71 (Merge)                (None, 17, 17, 896)  0           activation_38[0][0]              \n",
      "                                                                 lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 896)  3584        merge_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 896)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 17, 17, 128)  114816      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 17, 17, 128)  114816      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 17, 17, 128)  114816      conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_72 (Merge)                (None, 17, 17, 256)  0           conv2d_220[0][0]                 \n",
      "                                                                 conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 17, 17, 896)  230272      merge_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 17, 17, 896)  0           conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_73 (Merge)                (None, 17, 17, 896)  0           activation_39[0][0]              \n",
      "                                                                 lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 896)  3584        merge_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 896)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 17, 17, 256)  229632      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 17, 17, 256)  229632      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 17, 17, 256)  229632      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 17, 17, 256)  590080      conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 8, 8, 896)    0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 8, 8, 384)    885120      conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 8, 8, 256)    590080      conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 8, 8, 256)    590080      conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_74 (Merge)                (None, 8, 8, 1792)   0           max_pooling2d_6[0][0]            \n",
      "                                                                 conv2d_228[0][0]                 \n",
      "                                                                 conv2d_230[0][0]                 \n",
      "                                                                 conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 1792)   7168        merge_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 1792)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 8, 8, 192)    344256      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 8, 8, 192)    110784      conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 8, 8, 128)    229504      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 8, 8, 192)    110784      conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_75 (Merge)                (None, 8, 8, 320)    0           conv2d_234[0][0]                 \n",
      "                                                                 conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 8, 8, 1792)   575232      merge_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 8, 8, 1792)   0           conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_76 (Merge)                (None, 8, 8, 1792)   0           activation_41[0][0]              \n",
      "                                                                 lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 1792)   7168        merge_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 1792)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 8, 8, 192)    344256      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 8, 8, 192)    110784      conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 8, 8, 128)    229504      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 8, 8, 192)    110784      conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_77 (Merge)                (None, 8, 8, 320)    0           conv2d_239[0][0]                 \n",
      "                                                                 conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 8, 8, 1792)   575232      merge_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 8, 8, 1792)   0           conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_78 (Merge)                (None, 8, 8, 1792)   0           activation_42[0][0]              \n",
      "                                                                 lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 1792)   7168        merge_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 1792)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 8, 8, 192)    344256      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 8, 8, 192)    110784      conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 8, 8, 128)    229504      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 8, 8, 192)    110784      conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_79 (Merge)                (None, 8, 8, 320)    0           conv2d_244[0][0]                 \n",
      "                                                                 conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 8, 8, 1792)   575232      merge_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 8, 8, 1792)   0           conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_80 (Merge)                (None, 8, 8, 1792)   0           activation_43[0][0]              \n",
      "                                                                 lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 1792)   7168        merge_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 1792)   0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 8, 8, 192)    344256      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 8, 8, 192)    110784      conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 8, 8, 128)    229504      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 8, 8, 192)    110784      conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_81 (Merge)                (None, 8, 8, 320)    0           conv2d_249[0][0]                 \n",
      "                                                                 conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 8, 8, 1792)   575232      merge_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 8, 8, 1792)   0           conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_82 (Merge)                (None, 8, 8, 1792)   0           activation_44[0][0]              \n",
      "                                                                 lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 1792)   7168        merge_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 1792)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 8, 8, 192)    344256      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 8, 8, 192)    110784      conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 8, 8, 128)    229504      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 8, 8, 192)    110784      conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_83 (Merge)                (None, 8, 8, 320)    0           conv2d_254[0][0]                 \n",
      "                                                                 conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 8, 8, 1792)   575232      merge_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 8, 8, 1792)   0           conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "merge_84 (Merge)                (None, 8, 8, 1792)   0           activation_45[0][0]              \n",
      "                                                                 lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 1792)   7168        merge_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 1792)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 5, 5, 896)    0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 1, 1, 1792)   0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 5, 5, 128)    114816      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1, 1, 1792)   0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 1, 1, 768)    2458368     conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1792)         0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 768)          0           conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1001)         1794793     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1001)         769769      flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,028,930\n",
      "Trainable params: 24,984,642\n",
      "Non-trainable params: 44,288\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##########CREATE MODEL INCEPTIONResNet V1#######################################\n",
    "from keras.layers import Input, merge, Dropout, Dense, Lambda, Flatten, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import MaxPooling2D, Convolution2D, AveragePooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\"\"\"\n",
    "Implementation of Inception-Residual Network v1 [Inception Network v4 Paper](http://arxiv.org/pdf/1602.07261v1.pdf) in Keras.\n",
    "\n",
    "Some additional details:\n",
    "[1] Each of the A, B and C blocks have a 'scale_residual' parameter.\n",
    "    The scale residual parameter is according to the paper. It is however turned OFF by default.\n",
    "\n",
    "    Simply setting 'scale=True' in the create_inception_resnet_v1() method will add scaling.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def inception_resnet_stem(input):\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (tf) or 3 x 299 x 299 (th)\n",
    "    c = Convolution2D(32, 3, 3, activation='relu', subsample=(2, 2))(input)\n",
    "    c = Convolution2D(32, 3, 3, activation='relu', )(c)\n",
    "    c = Convolution2D(64, 3, 3, activation='relu', )(c)\n",
    "    c = MaxPooling2D((3, 3), strides=(2, 2))(c)\n",
    "    c = Convolution2D(80, 1, 1, activation='relu', border_mode='same')(c)\n",
    "    c = Convolution2D(192, 3, 3, activation='relu')(c)\n",
    "    c = Convolution2D(256, 3, 3, activation='relu', subsample=(2,2), border_mode='same')(c)\n",
    "    b = BatchNormalization(axis=channel_axis)(c)\n",
    "    b = Activation('relu')(b)\n",
    "    return b\n",
    "\n",
    "def inception_resnet_A(input, scale_residual=True):\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    # Input is relu activation\n",
    "    init = input\n",
    "\n",
    "    ir1 = Convolution2D(32, 1, 1, activation='relu', border_mode='same')(input)\n",
    "\n",
    "    ir2 = Convolution2D(32, 1, 1, activation='relu', border_mode='same')(input)\n",
    "    ir2 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(ir2)\n",
    "\n",
    "    ir3 = Convolution2D(32, 1, 1, activation='relu', border_mode='same')(input)\n",
    "    ir3 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(ir3)\n",
    "    ir3 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(ir3)\n",
    "\n",
    "    ir_merge = merge([ir1, ir2, ir3], concat_axis=channel_axis, mode='concat')\n",
    "\n",
    "    ir_conv = Convolution2D(256, 1, 1, activation='linear', border_mode='same')(ir_merge)\n",
    "    if scale_residual: ir_conv = Lambda(lambda x: x * 0.1)(ir_conv)\n",
    "\n",
    "    out = merge([init, ir_conv], mode='sum')\n",
    "    out = BatchNormalization(axis=channel_axis)(out)\n",
    "    out = Activation(\"relu\")(out)\n",
    "    return out\n",
    "\n",
    "def inception_resnet_B(input, scale_residual=True):\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    # Input is relu activation\n",
    "    init = input\n",
    "\n",
    "    ir1 = Convolution2D(128, 1, 1, activation='relu', border_mode='same')(input)\n",
    "\n",
    "    ir2 = Convolution2D(128, 1, 1, activation='relu', border_mode='same')(input)\n",
    "    ir2 = Convolution2D(128, 1, 7, activation='relu', border_mode='same')(ir2)\n",
    "    ir2 = Convolution2D(128, 7, 1, activation='relu', border_mode='same')(ir2)\n",
    "\n",
    "    ir_merge = merge([ir1, ir2], mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "    ir_conv = Convolution2D(896, 1, 1, activation='linear', border_mode='same')(ir_merge)\n",
    "    if scale_residual: ir_conv = Lambda(lambda x: x * 0.1)(ir_conv)\n",
    "\n",
    "    out = merge([init, ir_conv], mode='sum')\n",
    "    out = BatchNormalization(axis=channel_axis)(out)\n",
    "    out = Activation(\"relu\")(out)\n",
    "    return out\n",
    "\n",
    "def inception_resnet_C(input, scale_residual=True):\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    # Input is relu activation\n",
    "    init = input\n",
    "\n",
    "    ir1 = Convolution2D(128, 1, 1, activation='relu', border_mode='same')(input)\n",
    "\n",
    "    ir2 = Convolution2D(192, 1, 1, activation='relu', border_mode='same')(input)\n",
    "    ir2 = Convolution2D(192, 1, 3, activation='relu', border_mode='same')(ir2)\n",
    "    ir2 = Convolution2D(192, 3, 1, activation='relu', border_mode='same')(ir2)\n",
    "\n",
    "    ir_merge = merge([ir1, ir2], mode='concat', concat_axis=channel_axis)\n",
    "\n",
    "    ir_conv = Convolution2D(1792, 1, 1, activation='linear', border_mode='same')(ir_merge)\n",
    "    if scale_residual: ir_conv = Lambda(lambda x: x * 0.1)(ir_conv)\n",
    "\n",
    "    out = merge([init, ir_conv], mode='sum')\n",
    "    out = BatchNormalization(axis=channel_axis)(out)\n",
    "    out = Activation(\"relu\")(out)\n",
    "    return out\n",
    "\n",
    "def reduction_A(input, k=192, l=224, m=256, n=384):\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    r1 = MaxPooling2D((3,3), strides=(2,2))(input)\n",
    "\n",
    "    r2 = Convolution2D(n, 3, 3, activation='relu', subsample=(2,2))(input)\n",
    "\n",
    "    r3 = Convolution2D(k, 1, 1, activation='relu', border_mode='same')(input)\n",
    "    r3 = Convolution2D(l, 3, 3, activation='relu', border_mode='same')(r3)\n",
    "    r3 = Convolution2D(m, 3, 3, activation='relu', subsample=(2,2))(r3)\n",
    "\n",
    "    m = merge([r1, r2, r3], mode='concat', concat_axis=channel_axis)\n",
    "    m = BatchNormalization(axis=channel_axis)(m)\n",
    "    m = Activation('relu')(m)\n",
    "    return m\n",
    "\n",
    "\n",
    "def reduction_resnet_B(input):\n",
    "    if K.image_dim_ordering() == \"th\":\n",
    "        channel_axis = 1\n",
    "    else:\n",
    "        channel_axis = -1\n",
    "\n",
    "    r1 = MaxPooling2D((3,3), strides=(2,2), border_mode='valid')(input)\n",
    "\n",
    "    r2 = Convolution2D(256, 1, 1, activation='relu', border_mode='same')(input)\n",
    "    r2 = Convolution2D(384, 3, 3, activation='relu', subsample=(2,2))(r2)\n",
    "\n",
    "    r3 = Convolution2D(256, 1, 1, activation='relu', border_mode='same')(input)\n",
    "    r3 = Convolution2D(256, 3, 3, activation='relu', subsample=(2, 2))(r3)\n",
    "\n",
    "    r4 = Convolution2D(256, 1, 1, activation='relu', border_mode='same')(input)\n",
    "    r4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(r4)\n",
    "    r4 = Convolution2D(256, 3, 3, activation='relu', subsample=(2, 2))(r4)\n",
    "\n",
    "    m = merge([r1, r2, r3, r4], concat_axis=channel_axis, mode='concat')\n",
    "    m = BatchNormalization(axis=channel_axis)(m)\n",
    "    m = Activation('relu')(m)\n",
    "    return m\n",
    "\n",
    "def create_inception_resnet_v1(nb_classes=1001, scale=True):\n",
    "    '''\n",
    "    Creates a inception resnet v1 network\n",
    "\n",
    "    :param nb_classes: number of classes.txt\n",
    "    :param scale: flag to add scaling of activations\n",
    "    :return: Keras Model with 1 input (299x299x3) input shape and 2 outputs (final_output, auxiliary_output)\n",
    "    '''\n",
    "\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        init = Input((3, 299, 299))\n",
    "    else:\n",
    "        init = Input((299, 299, 3))\n",
    "\n",
    "    # Input Shape is 299 x 299 x 3 (tf) or 3 x 299 x 299 (th)\n",
    "    x = inception_resnet_stem(init)\n",
    "\n",
    "    # 5 x Inception Resnet A\n",
    "    for i in range(5):\n",
    "        x = inception_resnet_A(x, scale_residual=scale)\n",
    "\n",
    "    # Reduction A - From Inception v4\n",
    "    x = reduction_A(x, k=192, l=192, m=256, n=384)\n",
    "\n",
    "    # 10 x Inception Resnet B\n",
    "    for i in range(10):\n",
    "        x = inception_resnet_B(x, scale_residual=scale)\n",
    "\n",
    "    # Auxiliary tower\n",
    "    aux_out = AveragePooling2D((5, 5), strides=(3, 3))(x)\n",
    "    aux_out = Convolution2D(128, 1, 1, border_mode='same', activation='relu')(aux_out)\n",
    "    aux_out = Convolution2D(768, 5, 5, activation='relu')(aux_out)\n",
    "    aux_out = Flatten()(aux_out)\n",
    "    aux_out = Dense(nb_classes, activation='softmax')(aux_out)\n",
    "\n",
    "    # Reduction Resnet B\n",
    "    x = reduction_resnet_B(x)\n",
    "\n",
    "    # 5 x Inception Resnet C\n",
    "    for i in range(5):\n",
    "        x = inception_resnet_C(x, scale_residual=scale)\n",
    "\n",
    "    # Average Pooling\n",
    "    x = AveragePooling2D((8,8))(x)\n",
    "\n",
    "    # Dropout\n",
    "    x = Dropout(0.8)(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Output\n",
    "    out = Dense(output_dim=nb_classes, activation='softmax')(x)\n",
    "    model = Model(init, output=[out, aux_out], name='Inception-Resnet-v1')\n",
    "    #model = Model(init, output=[x, aux_out], name='Inception-Resnet-v1')\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    import  matplotlib.pyplot  as  plt\n",
    "\n",
    "    inception_resnet_v1 = create_inception_resnet_v1()\n",
    "    #plt.savefig(os.path.join(PATH_TO_DF,  \"Inception ResNet-v1.png\"),  bbox_inches='tight') \n",
    "    #plot(inception_resnet_v1, to_file=\"Inception ResNet-v1.png\", show_shapes=True)\n",
    "    inception_resnet_v1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from os import walk, getcwd\n",
    "# Retorna todos los archivos de un directorio dado\n",
    "def ls(ruta):  \n",
    "    return next(walk(ruta))[2]\n",
    "\n",
    "height_image = 299\n",
    "width_image = 299\n",
    "channels_image = 3\n",
    "nb_clases = 4\n",
    "batch_size = 2\n",
    "class_mode = 'categorical'\n",
    "nb_train = 4000        # 1000 x 4 clases\n",
    "nb_validation = 1200   #  300 x 4 clases\n",
    "nb_test = 1200\n",
    "\n",
    "base_dir = 'balanced_dataset'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 4 classes.\n",
      "Found 1200 images belonging to 4 classes.\n",
      "Found 1200 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#Extracción de características del modelo Preentrenado y nuestro dataset\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#Tamaño de salida de la última capa convoluciónal del modelo preentrenado\n",
    "#lo vemos en el conv_base.summary()\n",
    "out_x = 2\n",
    "out_y = 2\n",
    "conv_len = 1001\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, out_x, out_x, conv_len))\n",
    "    labels = to_categorical(np.zeros(shape=(sample_count)),nb_clases) #INDICAR NUMERO DE CLASES\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size = (height_image, width_image),\n",
    "        batch_size = batch_size,\n",
    "        #classes = 4,\n",
    "        class_mode = 'categorical')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = inception_resnet_v1.predict(inputs_batch) ##Asociamos al modelo preentrenado\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "#Train: 1000 muestras x clase, con 4 clases, 1000 x 4 = 4000\n",
    "train_features, train_labels = extract_features(train_dir, nb_train)\n",
    "#validation 500 muestras x clase con 4 clases, 300 x 4 = 1200\n",
    "validation_features, validation_labels = extract_features(validation_dir, nb_validation) \n",
    "#test 500 muestras x clase con 4 clases, 300 x 4 = 1200\n",
    "test_features, test_labels = extract_features(test_dir, nb_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 4004)\n",
      "(1200, 4004)\n",
      "(1200, 4004)\n"
     ]
    }
   ],
   "source": [
    "#Las características extraídas están como muetras en forma (muestra, 4, 4, 512).-->(muestras, out_x, out_y, conv_len)\n",
    "#Debemos aplanarlas (muestras, 8192) para alimentar un clasificador densamente conectado 4x4x512 = 8192 si entrada 150x150\n",
    "#Debemos aplanarlas (muestras, 25088) para alimentar un clasificador densamente conectado 7x7x512 = 25088 si entrada 224x224\n",
    "\n",
    "\n",
    "train_features = np.reshape(train_features, (nb_train, out_x * out_y * conv_len))\n",
    "validation_features = np.reshape(validation_features, (nb_validation, out_x * out_y * conv_len))\n",
    "test_features = np.reshape(test_features, (nb_test, out_x * out_y * conv_len))\n",
    "print(train_features.shape)\n",
    "print(validation_features.shape)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 256)               1025280   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 1,026,308\n",
      "Trainable params: 1,026,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Definimos un clasificador densamente conectado capacitado con los datos y etiquetas obtenidas antes\n",
    "#Aplicamos capa de abandono Dropout y función de activación \"sigmoid\" al final\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "top_model = models.Sequential()\n",
    "top_model.add(layers.Dense(256, activation = 'relu', input_dim = out_x * out_y * conv_len))\n",
    "top_model.add(layers.Dropout(0.5))\n",
    "top_model.add(layers.Dense(nb_clases, activation = 'sigmoid'))  #INDICAR NUMERO DE CLASES\n",
    "\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1200 samples\n",
      "Epoch 1/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3864 - acc: 0.2382 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 2/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3863 - acc: 0.2513 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 3/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3864 - acc: 0.2447 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 4/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3863 - acc: 0.2467 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 5/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3864 - acc: 0.2505 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 6/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3866 - acc: 0.2370 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 7/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3862 - acc: 0.2575 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 8/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3864 - acc: 0.2518 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 9/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3866 - acc: 0.2547 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 10/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3866 - acc: 0.2390 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 11/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3865 - acc: 0.2550 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 12/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3866 - acc: 0.2540 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 13/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3865 - acc: 0.2485 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 14/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3865 - acc: 0.2502 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 15/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3868 - acc: 0.2518 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 16/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3868 - acc: 0.2563 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 17/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3863 - acc: 0.2545 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 18/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3869 - acc: 0.2400 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 19/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3868 - acc: 0.2452 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 20/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3872 - acc: 0.2532 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 21/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3859 - acc: 0.2485 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 22/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3864 - acc: 0.2560 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 23/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3874 - acc: 0.2435 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 24/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3874 - acc: 0.2387 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 25/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3867 - acc: 0.2535 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 26/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3876 - acc: 0.2462 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 27/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3866 - acc: 0.2475 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 28/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3874 - acc: 0.2447 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 29/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3878 - acc: 0.2405 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 30/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3866 - acc: 0.2538 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 31/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3878 - acc: 0.2420 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 32/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3873 - acc: 0.2407 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 33/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3867 - acc: 0.2467 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 34/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3864 - acc: 0.2567 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 35/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3880 - acc: 0.2502 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 36/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3874 - acc: 0.2435 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 37/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3867 - acc: 0.2577 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 38/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3860 - acc: 0.2620 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 39/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3883 - acc: 0.2505 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 40/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3870 - acc: 0.2427 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 41/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3872 - acc: 0.2485 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 42/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3866 - acc: 0.2455 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 43/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3879 - acc: 0.2443 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 44/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3872 - acc: 0.2527 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 45/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3876 - acc: 0.2520 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 46/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3872 - acc: 0.2515 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 47/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3874 - acc: 0.2502 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 48/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3866 - acc: 0.2625 - val_loss: 1.3864 - val_acc: 0.2500\n",
      "Epoch 49/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3896 - acc: 0.2382 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 50/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3872 - acc: 0.2492 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 51/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3886 - acc: 0.2462 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 52/80\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 1.3879 - acc: 0.2465 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 53/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3865 - acc: 0.2603 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 54/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3868 - acc: 0.2513 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 55/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3874 - acc: 0.2470 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 56/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3889 - acc: 0.2522 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 57/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3875 - acc: 0.2545 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 58/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3888 - acc: 0.2482 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 59/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3876 - acc: 0.2585 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 60/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3888 - acc: 0.2560 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 61/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3879 - acc: 0.2585 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 62/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3895 - acc: 0.2452 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 63/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3883 - acc: 0.2477 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 64/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3882 - acc: 0.2525 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 65/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3870 - acc: 0.2617 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 66/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3892 - acc: 0.2513 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 67/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3900 - acc: 0.2443 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 68/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3890 - acc: 0.2470 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 69/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3896 - acc: 0.2398 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 70/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3889 - acc: 0.2440 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 71/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3899 - acc: 0.2470 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 72/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3901 - acc: 0.2402 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 73/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3895 - acc: 0.2485 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 74/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3878 - acc: 0.2532 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 75/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3886 - acc: 0.2470 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 76/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3889 - acc: 0.2445 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 77/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3872 - acc: 0.2543 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 78/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3882 - acc: 0.2412 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 79/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3903 - acc: 0.2457 - val_loss: 1.3863 - val_acc: 0.2500\n",
      "Epoch 80/80\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 1.3893 - acc: 0.2472 - val_loss: 1.3863 - val_acc: 0.2500\n"
     ]
    }
   ],
   "source": [
    "#Para la compilación usaremos el optimizador RMSprop ya que termina la red con una sola\n",
    "#unidad sigmoidea, cómo función de pérdida se utiliza la entropia cruzada binaria\n",
    "\n",
    "top_model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = optimizers.RMSprop(lr=2e-5), \n",
    "              metrics = ['acc'])\n",
    "\n",
    "epochs = 80\n",
    "\n",
    "history = top_model.fit(\n",
    "    train_features,\n",
    "    train_labels,  \n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs, \n",
    "    verbose = 1, \n",
    "    validation_data = (validation_features, validation_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
